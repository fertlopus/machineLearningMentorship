{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import random\n",
    "import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузим тексте и просто удалим лишние символы в тексте чтобы продемонстрировать работу GRU и LSTM ячеек:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Ванильный препроцессинг:\n",
    "def load_and_vanilla_preprocess(txt_path):\n",
    "    with open(txt_path, encoding='utf-8') as txt_file:\n",
    "        text = txt_file.read().lower()\n",
    "    text = re.sub('[^a-z ]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    txt_file.close()\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'preface supposing that truth is a woman what then is there not ground for suspecting that all philos'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = load_and_vanilla_preprocess('./data/nietzsche.txt')\n",
    "text[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сформируем туже самую кодировку на уровне символов как делали до этого момента:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Создаем индексы под символы\n",
    "INDEX_TO_CHAR = sorted(list(set(text)))\n",
    "# Кодировщик для символа в индекс:\n",
    "CHAR_TO_INDEX = {c: i for i, c in enumerate(INDEX_TO_CHAR)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "print(CHAR_TO_INDEX)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Создадим кастомный датасет для работы:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество предложений (сэмплов):  193075\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 40 # берем кусочки текста максимум до 40 символов\n",
    "STEP = 3\n",
    "SENTENCES = []\n",
    "NEXT_CHARS = []\n",
    "\n",
    "# Проитерируемся по тексту и сформируем кусочки предложение (сэмплов)\n",
    "for i in range(0, len(text) - MAX_LEN, STEP):\n",
    "    SENTENCES.append(text[i: i + MAX_LEN])  # Формируем наши X\n",
    "    NEXT_CHARS.append(text[i + MAX_LEN])    # Формируем Y\n",
    "\n",
    "print(\"Количество предложений (сэмплов): \", len(SENTENCES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['preface supposing that truth is a woman ',\n 'face supposing that truth is a woman wha']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCES[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация...\n",
      "torch.Size([193075, 40]) torch.Size([193075])\n",
      "tensor([[16, 18,  5,  6,  1,  3,  5,  0, 19, 21, 16, 16, 15, 19,  9, 14,  7,  0,\n",
      "         20,  8,  1, 20,  0, 20, 18, 21, 20,  8,  0,  9, 19,  0,  1,  0, 23, 15,\n",
      "         13,  1, 14,  0]]) tensor(23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Векторизация...\")\n",
    "\n",
    "# Необходимо теперь нам это все превратить в тензоры для того чтобы подать в алгоритм рекуррентной нейронной сети\n",
    "X = torch.zeros((len(SENTENCES), MAX_LEN), dtype=int)\n",
    "Y = torch.zeros((len(SENTENCES)), dtype=int)\n",
    "\n",
    "# Пробегаемся по нашим кусочкам предложений и кодируем под сформированные символы\n",
    "for i, sentence in enumerate(SENTENCES):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t] = CHAR_TO_INDEX[char]\n",
    "    Y[i] = CHAR_TO_INDEX[NEXT_CHARS[i]]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print(X[0:1], Y[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Теперь уже сформируем датасет, который будем уже передавать в нейронную сеть:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Строим класс RNN который будет принимать различную указанную вариацию рекуррентной ячейки - GRU / LSTM/ SimpleRNN\n",
    "class RnnFlex(torch.nn.Module):\n",
    "                        # тип     размер словаря  размер эмб       скрытые слои   классы\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = torch.nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = torch.nn.Linear(num_hiddens, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X)\n",
    "        _, state = self.hidden(out)  # приходят все выходы и последний выход (между LSTM  и GRU выход немного разный)\n",
    "        predictions = self.output(state[0])\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = RnnFlex(torch.nn.GRU, len(CHAR_TO_INDEX), 64, 128, len(CHAR_TO_INDEX))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0895,  0.0958,  0.0262,  0.0139,  0.1866, -0.0922, -0.1018, -0.1026,\n         -0.0376,  0.1924,  0.0942,  0.1496,  0.2639, -0.0695,  0.1569, -0.0483,\n         -0.0315, -0.1166,  0.0543, -0.2714,  0.0421,  0.0222,  0.1019,  0.0220,\n         -0.0871,  0.1240,  0.0551]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X[0:1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Output shape: torch.Size([10, 40, 128])\n",
      "Second output shape: torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "# Размерность возвращаемая GRU\n",
    "embedding = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
    "rnn = torch.nn.GRU(28, 128, batch_first=True)\n",
    "o, s = rnn(embedding(X[0:10]))\n",
    "print(\"First Output shape: {}\\nSecond output shape: {}\".format(o.shape, s.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [14], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m rnn \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mLSTM(\u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m128\u001B[39m)\n\u001B[0;32m      4\u001B[0m o, s \u001B[38;5;241m=\u001B[39m rnn(embedding(X[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m1\u001B[39m]))\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFirst Output shape: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSecond output shape: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(o\u001B[38;5;241m.\u001B[39mshape, \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Размерность возвращаемая GRU\n",
    "embedding = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
    "rnn = torch.nn.LSTM(28, 128)\n",
    "o, s = rnn(embedding(X[0:1]))\n",
    "\n",
    "print(\"First Output shape: {}\\nSecond output shape: {}\".format(o.shape, s.shape))\n",
    "\n",
    "# print(\"First Output shape: {}\\nSecond output shape: {} and {}\".format(o.shape,  s[0].shape, s[1].shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Напишем 2 функции\n",
    "\n",
    "1-ая отвечает за генерацию текста."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    softmaxed = torch.softmax(preds, 0)\n",
    "    print(\"Softmaxed: {}\".format(softmaxed))\n",
    "    print(\"Softmaxed sum: {}\".format(softmaxed.sum()))\n",
    "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
    "    return probas.argmax()\n",
    "\n",
    "\n",
    "def generate_text():\n",
    "    # Берем случайный индекс нашего текста\n",
    "    start_index = random.randint(0, len(text) - MAX_LEN - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index:start_index +MAX_LEN]\n",
    "    generated += sentence\n",
    "\n",
    "    for i in range(MAX_LEN):\n",
    "        x_pred = torch.zeros((1, MAX_LEN), dtype=int)\n",
    "        for t, char in enumerate(generated[-MAX_LEN:]):\n",
    "            x_pred[0, t] = CHAR_TO_INDEX[char]\n",
    "\n",
    "        preds = model(x_pred)[0]\n",
    "        next_char = INDEX_TO_CHAR[sample(preds)]\n",
    "        generated = generated + next_char\n",
    "\n",
    "    print(generated[:MAX_LEN] + ' <------ | ------> ' + generated[MAX_LEN: ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmaxed: tensor([0.2387, 0.0494, 0.0029, 0.0059, 0.0058, 0.1193, 0.0028, 0.0052, 0.2522,\n",
      "        0.0857, 0.0011, 0.0015, 0.0168, 0.0054, 0.0112, 0.0723, 0.0054, 0.0008,\n",
      "        0.0170, 0.0248, 0.0266, 0.0148, 0.0038, 0.0021, 0.0008, 0.0271, 0.0006],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.1746e-01, 6.5274e-02, 1.1369e-03, 2.5414e-03, 4.0701e-03, 4.7272e-01,\n",
      "        1.8442e-03, 2.8910e-03, 5.2706e-03, 1.0523e-01, 5.7465e-04, 1.0486e-03,\n",
      "        1.0600e-02, 6.3467e-03, 4.9265e-03, 2.0271e-02, 5.7891e-03, 6.9149e-04,\n",
      "        1.3502e-02, 1.5619e-02, 1.1209e-02, 8.6090e-03, 2.2783e-03, 1.6080e-03,\n",
      "        5.0933e-04, 1.7544e-02, 4.3842e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.1202e-01, 2.3460e-02, 2.3874e-03, 2.2088e-02, 2.9661e-02, 2.9653e-02,\n",
      "        5.6716e-03, 1.1574e-02, 1.6474e-03, 1.8753e-02, 5.9918e-04, 1.2861e-03,\n",
      "        2.2944e-02, 1.5676e-02, 4.6127e-02, 8.4931e-03, 7.4795e-03, 5.5761e-04,\n",
      "        1.0966e-01, 7.2802e-02, 3.1140e-02, 6.3747e-03, 7.4712e-03, 2.8414e-03,\n",
      "        1.3824e-03, 7.8253e-03, 4.2385e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.0037, 0.1298, 0.0477, 0.0351, 0.0156, 0.0419, 0.0324, 0.0116, 0.0322,\n",
      "        0.0989, 0.0018, 0.0042, 0.0193, 0.0439, 0.0304, 0.0639, 0.0507, 0.0014,\n",
      "        0.0238, 0.0773, 0.1474, 0.0153, 0.0090, 0.0537, 0.0018, 0.0058, 0.0012],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0080, 0.0261, 0.0112, 0.0381, 0.0111, 0.0221, 0.0222, 0.0168, 0.0121,\n",
      "        0.0139, 0.0018, 0.0026, 0.0297, 0.0285, 0.3368, 0.0664, 0.0115, 0.0014,\n",
      "        0.0503, 0.1094, 0.1411, 0.0086, 0.0130, 0.0075, 0.0024, 0.0059, 0.0016],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0180, 0.0138, 0.0079, 0.0482, 0.0144, 0.0178, 0.0131, 0.0279, 0.0074,\n",
      "        0.0115, 0.0014, 0.0020, 0.0409, 0.0235, 0.3496, 0.0302, 0.0072, 0.0010,\n",
      "        0.0396, 0.1390, 0.1525, 0.0068, 0.0119, 0.0046, 0.0018, 0.0069, 0.0010],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.6404e-01, 2.3431e-02, 1.7603e-03, 9.5248e-03, 6.5780e-03, 8.4106e-02,\n",
      "        3.3679e-03, 5.3145e-03, 1.1359e-02, 5.9722e-02, 3.2261e-04, 8.9779e-04,\n",
      "        1.2752e-02, 4.8144e-03, 1.3561e-02, 3.2829e-02, 5.8801e-03, 4.2080e-04,\n",
      "        1.2525e-02, 3.7024e-02, 8.0633e-02, 1.3447e-02, 3.1507e-03, 2.4749e-03,\n",
      "        5.0781e-04, 9.2658e-03, 2.9214e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0033, 0.1437, 0.0425, 0.0299, 0.0127, 0.0466, 0.0328, 0.0106, 0.0417,\n",
      "        0.0997, 0.0018, 0.0038, 0.0171, 0.0415, 0.0294, 0.0834, 0.0528, 0.0013,\n",
      "        0.0214, 0.0538, 0.1407, 0.0177, 0.0075, 0.0567, 0.0016, 0.0051, 0.0011],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0182, 0.0909, 0.0065, 0.0048, 0.0029, 0.1239, 0.0081, 0.0023, 0.2567,\n",
      "        0.1555, 0.0031, 0.0044, 0.0182, 0.0096, 0.0135, 0.1605, 0.0147, 0.0020,\n",
      "        0.0227, 0.0116, 0.0181, 0.0285, 0.0033, 0.0058, 0.0023, 0.0090, 0.0027],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0780, 0.1502, 0.0024, 0.0038, 0.0050, 0.3571, 0.0039, 0.0029, 0.0156,\n",
      "        0.1908, 0.0017, 0.0025, 0.0165, 0.0095, 0.0072, 0.0550, 0.0114, 0.0016,\n",
      "        0.0168, 0.0136, 0.0125, 0.0180, 0.0038, 0.0037, 0.0014, 0.0133, 0.0017],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.0888, 0.0199, 0.0082, 0.0424, 0.0436, 0.0191, 0.0054, 0.0183, 0.0058,\n",
      "        0.0370, 0.0021, 0.0040, 0.1368, 0.0124, 0.1538, 0.0168, 0.0114, 0.0022,\n",
      "        0.0855, 0.0836, 0.1524, 0.0096, 0.0144, 0.0055, 0.0029, 0.0152, 0.0028],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.2826, 0.0138, 0.0031, 0.0384, 0.2273, 0.0639, 0.0043, 0.0742, 0.0033,\n",
      "        0.0269, 0.0013, 0.0033, 0.0271, 0.0053, 0.0167, 0.0242, 0.0034, 0.0009,\n",
      "        0.0076, 0.0418, 0.0874, 0.0081, 0.0079, 0.0047, 0.0018, 0.0198, 0.0009],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.4340, 0.0318, 0.0024, 0.0098, 0.0182, 0.1452, 0.0031, 0.0085, 0.0105,\n",
      "        0.0864, 0.0008, 0.0019, 0.0273, 0.0085, 0.0120, 0.0264, 0.0073, 0.0011,\n",
      "        0.0342, 0.0341, 0.0462, 0.0133, 0.0047, 0.0029, 0.0009, 0.0277, 0.0009],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3946e-01, 2.8591e-02, 2.1698e-03, 1.2272e-02, 7.6165e-03, 7.4821e-02,\n",
      "        3.6904e-03, 3.6912e-03, 8.8723e-03, 7.9270e-02, 2.8701e-04, 8.5413e-04,\n",
      "        1.0186e-02, 5.7040e-03, 8.2106e-03, 3.4683e-02, 7.4395e-03, 4.6335e-04,\n",
      "        1.5462e-02, 3.4373e-02, 9.0805e-02, 1.4319e-02, 2.4581e-03, 3.6263e-03,\n",
      "        4.5371e-04, 9.8956e-03, 3.3057e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.2202, 0.0728, 0.0038, 0.0080, 0.0050, 0.1282, 0.0033, 0.0033, 0.1374,\n",
      "        0.1417, 0.0007, 0.0009, 0.0180, 0.0083, 0.0099, 0.0867, 0.0093, 0.0007,\n",
      "        0.0288, 0.0278, 0.0309, 0.0207, 0.0022, 0.0029, 0.0004, 0.0275, 0.0005],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0672, 0.0130, 0.0070, 0.0294, 0.0271, 0.0192, 0.0049, 0.0119, 0.0054,\n",
      "        0.0342, 0.0011, 0.0019, 0.1475, 0.0111, 0.2388, 0.0164, 0.0090, 0.0011,\n",
      "        0.1174, 0.0698, 0.1307, 0.0085, 0.0087, 0.0044, 0.0014, 0.0119, 0.0011],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.2685, 0.0512, 0.0031, 0.0116, 0.0267, 0.2611, 0.0037, 0.0097, 0.0065,\n",
      "        0.1072, 0.0009, 0.0014, 0.0207, 0.0106, 0.0115, 0.0328, 0.0085, 0.0007,\n",
      "        0.0168, 0.0543, 0.0492, 0.0130, 0.0039, 0.0032, 0.0009, 0.0218, 0.0006],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([0.3846, 0.0270, 0.0031, 0.0305, 0.0427, 0.0304, 0.0076, 0.0130, 0.0019,\n",
      "        0.0214, 0.0007, 0.0014, 0.0339, 0.0185, 0.0693, 0.0111, 0.0104, 0.0006,\n",
      "        0.1222, 0.0902, 0.0464, 0.0091, 0.0093, 0.0038, 0.0017, 0.0085, 0.0005],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.1137, 0.0550, 0.0090, 0.0277, 0.0175, 0.0943, 0.0098, 0.0128, 0.0388,\n",
      "        0.1166, 0.0008, 0.0019, 0.0411, 0.0171, 0.0346, 0.0652, 0.0166, 0.0008,\n",
      "        0.0498, 0.0846, 0.1352, 0.0239, 0.0073, 0.0071, 0.0011, 0.0170, 0.0007],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0884, 0.0503, 0.0050, 0.0144, 0.0188, 0.2277, 0.0085, 0.0114, 0.0102,\n",
      "        0.0917, 0.0016, 0.0026, 0.0607, 0.0208, 0.0694, 0.0460, 0.0162, 0.0013,\n",
      "        0.0673, 0.0564, 0.0727, 0.0233, 0.0072, 0.0051, 0.0012, 0.0203, 0.0014],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0436, 0.0475, 0.0098, 0.0229, 0.0201, 0.1306, 0.0103, 0.0222, 0.0111,\n",
      "        0.0518, 0.0016, 0.0033, 0.0914, 0.0264, 0.0690, 0.0273, 0.0235, 0.0018,\n",
      "        0.0954, 0.1277, 0.1152, 0.0155, 0.0101, 0.0075, 0.0019, 0.0108, 0.0017],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([4.8290e-01, 3.0802e-02, 2.1328e-03, 1.0688e-02, 7.7383e-03, 1.0435e-01,\n",
      "        3.6150e-03, 4.7704e-03, 1.2816e-02, 7.7513e-02, 3.5127e-04, 9.1159e-04,\n",
      "        1.4115e-02, 5.8910e-03, 1.1434e-02, 3.6462e-02, 8.3728e-03, 4.3928e-04,\n",
      "        1.6917e-02, 3.6383e-02, 9.8089e-02, 1.6217e-02, 3.0693e-03, 3.2078e-03,\n",
      "        5.0019e-04, 9.9547e-03, 3.6355e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0578, 0.0847, 0.0067, 0.0085, 0.0044, 0.2203, 0.0065, 0.0042, 0.0365,\n",
      "        0.1196, 0.0012, 0.0023, 0.0429, 0.0244, 0.0205, 0.0638, 0.0324, 0.0015,\n",
      "        0.1041, 0.0497, 0.0446, 0.0304, 0.0053, 0.0040, 0.0012, 0.0215, 0.0012],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0932, 0.1077, 0.0035, 0.0080, 0.0108, 0.3411, 0.0045, 0.0062, 0.0145,\n",
      "        0.1378, 0.0011, 0.0014, 0.0156, 0.0173, 0.0090, 0.0642, 0.0141, 0.0009,\n",
      "        0.0255, 0.0465, 0.0377, 0.0151, 0.0035, 0.0038, 0.0010, 0.0153, 0.0007],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([0.1021, 0.1272, 0.0033, 0.0086, 0.0117, 0.3188, 0.0045, 0.0064, 0.0143,\n",
      "        0.1390, 0.0010, 0.0013, 0.0136, 0.0165, 0.0078, 0.0648, 0.0130, 0.0008,\n",
      "        0.0192, 0.0459, 0.0410, 0.0164, 0.0033, 0.0042, 0.0009, 0.0138, 0.0007],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.0021, 0.1763, 0.0433, 0.0283, 0.0114, 0.0407, 0.0308, 0.0089, 0.0482,\n",
      "        0.0951, 0.0022, 0.0040, 0.0139, 0.0408, 0.0267, 0.0968, 0.0536, 0.0015,\n",
      "        0.0209, 0.0476, 0.1220, 0.0161, 0.0075, 0.0529, 0.0019, 0.0051, 0.0015],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0143, 0.0987, 0.0074, 0.0052, 0.0032, 0.1157, 0.0085, 0.0024, 0.2591,\n",
      "        0.1516, 0.0037, 0.0048, 0.0167, 0.0102, 0.0129, 0.1652, 0.0157, 0.0022,\n",
      "        0.0206, 0.0114, 0.0178, 0.0281, 0.0035, 0.0062, 0.0027, 0.0090, 0.0030],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([0.1416, 0.0579, 0.0052, 0.0378, 0.1459, 0.1039, 0.0092, 0.0493, 0.0213,\n",
      "        0.0642, 0.0027, 0.0051, 0.0253, 0.0092, 0.0160, 0.1068, 0.0075, 0.0016,\n",
      "        0.0114, 0.0326, 0.0825, 0.0225, 0.0096, 0.0105, 0.0030, 0.0156, 0.0018],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.2331, 0.0349, 0.0036, 0.0400, 0.1384, 0.1132, 0.0074, 0.0712, 0.0061,\n",
      "        0.0424, 0.0013, 0.0037, 0.0189, 0.0082, 0.0121, 0.0510, 0.0050, 0.0009,\n",
      "        0.0083, 0.0444, 0.1044, 0.0138, 0.0087, 0.0092, 0.0019, 0.0167, 0.0010],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.8433e-01, 2.0383e-02, 1.0457e-03, 6.0981e-03, 8.9815e-03, 1.0832e-01,\n",
      "        2.3160e-03, 5.5979e-03, 3.8980e-03, 4.6815e-02, 3.8963e-04, 1.1065e-03,\n",
      "        1.0441e-02, 4.5017e-03, 4.8336e-03, 1.8575e-02, 3.0877e-03, 3.9852e-04,\n",
      "        1.1195e-02, 1.3449e-02, 1.8468e-02, 1.0677e-02, 2.8564e-03, 1.8709e-03,\n",
      "        5.3173e-04, 9.5206e-03, 3.1371e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([0.0039, 0.1450, 0.0446, 0.0347, 0.0149, 0.0469, 0.0318, 0.0118, 0.0345,\n",
      "        0.1044, 0.0020, 0.0041, 0.0166, 0.0449, 0.0269, 0.0745, 0.0475, 0.0015,\n",
      "        0.0194, 0.0567, 0.1434, 0.0160, 0.0084, 0.0573, 0.0018, 0.0055, 0.0012],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0234, 0.0541, 0.0035, 0.0026, 0.0021, 0.0772, 0.0038, 0.0015, 0.5400,\n",
      "        0.0540, 0.0012, 0.0013, 0.0072, 0.0043, 0.0067, 0.1456, 0.0058, 0.0007,\n",
      "        0.0133, 0.0075, 0.0120, 0.0149, 0.0020, 0.0026, 0.0007, 0.0111, 0.0007],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.1079, 0.0974, 0.0013, 0.0020, 0.0034, 0.5330, 0.0024, 0.0022, 0.0103,\n",
      "        0.1149, 0.0008, 0.0013, 0.0089, 0.0069, 0.0045, 0.0325, 0.0072, 0.0009,\n",
      "        0.0127, 0.0111, 0.0085, 0.0113, 0.0024, 0.0022, 0.0006, 0.0125, 0.0006],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([0.1129, 0.0175, 0.0075, 0.0364, 0.0406, 0.0221, 0.0053, 0.0178, 0.0048,\n",
      "        0.0330, 0.0017, 0.0031, 0.1177, 0.0132, 0.1518, 0.0142, 0.0105, 0.0017,\n",
      "        0.0948, 0.0866, 0.1614, 0.0089, 0.0122, 0.0052, 0.0021, 0.0148, 0.0021],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.2479, 0.0299, 0.0056, 0.0160, 0.0354, 0.1343, 0.0055, 0.0186, 0.0118,\n",
      "        0.1079, 0.0015, 0.0026, 0.0646, 0.0081, 0.0101, 0.0434, 0.0098, 0.0015,\n",
      "        0.0121, 0.0478, 0.0511, 0.0142, 0.0080, 0.0050, 0.0011, 0.1046, 0.0018],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.1525, 0.0122, 0.0065, 0.0332, 0.0445, 0.0239, 0.0051, 0.0196, 0.0043,\n",
      "        0.0320, 0.0016, 0.0029, 0.1536, 0.0096, 0.1317, 0.0122, 0.0086, 0.0017,\n",
      "        0.0689, 0.0798, 0.1429, 0.0096, 0.0119, 0.0050, 0.0021, 0.0221, 0.0018],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.2153, 0.0260, 0.0056, 0.0201, 0.0438, 0.1478, 0.0079, 0.0205, 0.0049,\n",
      "        0.0631, 0.0021, 0.0038, 0.0705, 0.0152, 0.0568, 0.0209, 0.0121, 0.0021,\n",
      "        0.0437, 0.0635, 0.0850, 0.0186, 0.0087, 0.0048, 0.0018, 0.0335, 0.0019],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([0.0054, 0.1169, 0.0435, 0.0367, 0.0206, 0.0539, 0.0291, 0.0141, 0.0329,\n",
      "        0.0967, 0.0024, 0.0047, 0.0193, 0.0412, 0.0269, 0.0704, 0.0445, 0.0018,\n",
      "        0.0183, 0.0680, 0.1656, 0.0165, 0.0098, 0.0496, 0.0021, 0.0076, 0.0015],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.0338, 0.0238, 0.0116, 0.0132, 0.0117, 0.0379, 0.1776, 0.0090, 0.0112,\n",
      "        0.0217, 0.0023, 0.0068, 0.0222, 0.0535, 0.1536, 0.0347, 0.0287, 0.0035,\n",
      "        0.1384, 0.0299, 0.0491, 0.0806, 0.0121, 0.0216, 0.0046, 0.0051, 0.0019],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.3111, 0.0230, 0.0035, 0.0299, 0.1162, 0.1130, 0.0098, 0.0771, 0.0065,\n",
      "        0.0287, 0.0013, 0.0039, 0.0188, 0.0095, 0.0181, 0.0308, 0.0055, 0.0010,\n",
      "        0.0138, 0.0458, 0.0837, 0.0151, 0.0092, 0.0068, 0.0020, 0.0149, 0.0009],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "e the spirit has seen this problem in it <------ | ------> he iis whangstarecbusprr wnnd thalab one\n"
     ]
    }
   ],
   "source": [
    "generate_text()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   Time 62.885    Train Loss: 1.963\n",
      "Softmaxed: tensor([1.2259e-01, 1.3220e-03, 1.6164e-02, 2.5765e-02, 1.5682e-02, 2.3278e-03,\n",
      "        5.8478e-03, 1.1352e-02, 2.6812e-03, 6.7338e-03, 3.0472e-04, 2.7508e-03,\n",
      "        7.5778e-02, 1.4629e-02, 3.8778e-01, 2.3327e-03, 1.6488e-02, 3.4658e-04,\n",
      "        7.0934e-02, 1.5389e-01, 4.2336e-02, 6.1115e-03, 6.4255e-03, 2.3435e-03,\n",
      "        1.3139e-03, 5.5472e-03, 2.2531e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.2815e-02, 3.3710e-03, 1.7154e-03, 1.7865e-02, 8.1111e-01, 5.9134e-03,\n",
      "        2.9292e-03, 6.9384e-03, 1.9094e-04, 6.9736e-03, 1.7013e-03, 5.5703e-03,\n",
      "        4.4078e-03, 1.5250e-03, 2.1062e-03, 1.8107e-02, 4.1664e-04, 7.5076e-04,\n",
      "        3.4838e-04, 1.0930e-02, 2.0007e-02, 6.8586e-04, 4.7228e-03, 2.0842e-03,\n",
      "        4.2728e-04, 6.2601e-03, 1.2584e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.4099e-01, 3.8085e-03, 1.5470e-04, 8.4100e-04, 8.1303e-04, 1.0843e-02,\n",
      "        6.0161e-04, 4.7991e-04, 7.6641e-05, 1.4207e-02, 6.6760e-05, 2.5063e-04,\n",
      "        1.2267e-03, 9.6040e-04, 4.8177e-04, 7.1756e-03, 2.2365e-04, 1.0722e-04,\n",
      "        8.4224e-04, 5.4398e-03, 1.2612e-03, 4.3990e-03, 5.2315e-04, 6.0337e-04,\n",
      "        7.6385e-05, 3.5147e-03, 2.7681e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.1788e-05, 1.1426e-01, 4.2142e-02, 6.0097e-02, 3.2816e-02, 4.3079e-02,\n",
      "        3.0794e-02, 1.7477e-02, 2.7826e-02, 8.7055e-02, 5.3205e-03, 4.1355e-03,\n",
      "        2.4012e-02, 5.9199e-02, 2.6412e-02, 6.1164e-02, 5.0422e-02, 2.1982e-03,\n",
      "        2.0915e-02, 6.9182e-02, 1.2892e-01, 1.6036e-02, 1.2136e-02, 6.2127e-02,\n",
      "        1.8251e-04, 1.8966e-03, 1.5395e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8104e-03, 3.5899e-01, 8.8384e-04, 2.2733e-04, 5.6990e-05, 2.0855e-01,\n",
      "        1.5650e-03, 8.4223e-05, 2.5503e-03, 4.8089e-02, 1.4267e-04, 7.2616e-05,\n",
      "        8.6697e-04, 1.5738e-03, 1.0480e-03, 2.4247e-01, 7.2357e-03, 1.5966e-04,\n",
      "        3.2354e-03, 3.0865e-03, 5.8089e-04, 9.9301e-02, 2.8660e-04, 9.7758e-04,\n",
      "        1.1693e-04, 1.5976e-02, 6.2801e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.3079e-02, 1.7241e-02, 8.6774e-03, 8.3330e-03, 2.2327e-02, 1.1681e-02,\n",
      "        1.2063e-02, 5.1998e-03, 2.8737e-03, 6.0391e-03, 5.1842e-04, 3.4613e-03,\n",
      "        2.9388e-02, 3.0686e-02, 1.0108e-01, 6.2109e-02, 1.1354e-02, 3.1451e-04,\n",
      "        3.3546e-01, 1.2327e-01, 4.4620e-02, 8.2536e-02, 1.2630e-02, 4.0386e-02,\n",
      "        6.1732e-04, 3.6513e-03, 4.1559e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8954e-02, 2.0673e-01, 4.9064e-03, 5.2866e-03, 2.3192e-02, 4.2072e-01,\n",
      "        3.8819e-03, 3.6637e-03, 1.7170e-02, 7.3865e-02, 1.3788e-03, 3.7172e-03,\n",
      "        2.5584e-02, 1.0136e-02, 1.2722e-02, 2.2318e-02, 5.8868e-03, 3.7004e-04,\n",
      "        1.2422e-02, 2.4272e-02, 5.8606e-02, 1.5004e-02, 1.5750e-03, 3.0649e-03,\n",
      "        1.3497e-04, 1.4222e-02, 2.1368e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.2442e-02, 4.0710e-01, 1.0924e-03, 5.0559e-04, 5.7707e-04, 2.2664e-01,\n",
      "        6.0674e-04, 3.2941e-04, 1.3128e-03, 6.2933e-02, 1.2471e-04, 9.5250e-05,\n",
      "        4.0426e-03, 5.8384e-03, 9.8910e-04, 9.7822e-02, 1.2844e-02, 8.3248e-05,\n",
      "        1.5023e-03, 3.0077e-02, 3.1261e-03, 1.7318e-02, 3.7154e-04, 1.2788e-03,\n",
      "        1.5119e-05, 3.0873e-02, 6.5626e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5554e-03, 1.5903e-03, 1.7189e-02, 2.1189e-02, 4.6862e-02, 7.1582e-04,\n",
      "        4.2335e-03, 1.3302e-02, 4.7242e-04, 1.3957e-02, 2.6481e-04, 3.4496e-03,\n",
      "        4.6395e-02, 8.2759e-03, 5.8913e-01, 1.0290e-03, 5.4485e-03, 1.4193e-04,\n",
      "        3.2083e-02, 3.5053e-02, 1.2156e-01, 4.9095e-03, 6.0759e-03, 1.5816e-03,\n",
      "        9.4376e-05, 2.3187e-02, 2.6025e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.0667e-01, 1.6595e-02, 1.2427e-03, 9.0914e-02, 1.1772e-01, 6.1258e-02,\n",
      "        6.0390e-03, 5.0889e-02, 8.8642e-04, 7.8896e-02, 1.1639e-03, 1.1109e-02,\n",
      "        1.9892e-02, 1.6522e-03, 9.3402e-03, 9.6509e-03, 7.8869e-04, 2.9529e-04,\n",
      "        9.6007e-04, 9.4398e-02, 9.0469e-02, 3.6924e-03, 3.1353e-03, 1.2598e-03,\n",
      "        2.0332e-04, 2.0759e-02, 1.2019e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1367e-02, 4.6162e-02, 6.7110e-04, 4.0168e-03, 4.8004e-04, 6.7578e-01,\n",
      "        1.3903e-03, 8.2675e-04, 1.0511e-02, 7.2793e-02, 9.3344e-05, 1.1258e-03,\n",
      "        1.0957e-02, 1.8038e-03, 1.0168e-03, 3.8135e-02, 5.4959e-04, 1.1552e-04,\n",
      "        9.1315e-03, 9.2899e-03, 6.3187e-02, 2.2731e-02, 4.0946e-04, 7.1443e-04,\n",
      "        1.3834e-05, 1.6608e-02, 1.1742e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.1905e-01, 6.4301e-03, 5.7447e-04, 4.7444e-03, 5.5986e-02, 4.0323e-03,\n",
      "        1.6657e-03, 1.3485e-03, 3.0341e-05, 3.9808e-03, 3.5670e-05, 1.7982e-04,\n",
      "        1.4287e-02, 5.7015e-03, 1.7481e-02, 1.0989e-03, 9.5907e-04, 2.0851e-04,\n",
      "        2.7757e-02, 1.1626e-01, 5.2284e-03, 7.8770e-04, 7.7863e-03, 9.1538e-04,\n",
      "        2.8884e-04, 3.1634e-03, 2.3920e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.4576e-05, 1.5096e-01, 2.7167e-02, 4.3715e-02, 2.2863e-02, 3.5005e-02,\n",
      "        3.7531e-02, 8.2618e-03, 3.9173e-02, 9.2246e-02, 3.8292e-03, 2.6633e-03,\n",
      "        1.5940e-02, 2.7776e-02, 2.3073e-02, 1.4557e-01, 2.8511e-02, 8.9493e-04,\n",
      "        1.3410e-02, 5.2300e-02, 1.4887e-01, 1.7181e-02, 7.2990e-03, 5.3610e-02,\n",
      "        8.2367e-05, 1.9434e-03, 6.7088e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.9573e-03, 3.5616e-01, 7.1009e-04, 1.6640e-04, 6.1761e-05, 2.2760e-01,\n",
      "        1.2975e-03, 1.6085e-04, 7.5696e-04, 2.2602e-01, 2.0067e-04, 7.3857e-05,\n",
      "        5.4063e-03, 2.4679e-03, 1.4622e-03, 1.0888e-01, 5.9229e-03, 1.4006e-04,\n",
      "        5.3395e-03, 2.1519e-03, 9.9133e-04, 4.0696e-02, 5.3119e-04, 2.0981e-03,\n",
      "        1.3228e-04, 7.5741e-03, 3.1249e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([0.0810, 0.0102, 0.0103, 0.0068, 0.0318, 0.0149, 0.0179, 0.0074, 0.0023,\n",
      "        0.0111, 0.0011, 0.0047, 0.0210, 0.0849, 0.0396, 0.0440, 0.0140, 0.0006,\n",
      "        0.1222, 0.0673, 0.0454, 0.0946, 0.0355, 0.2269, 0.0014, 0.0028, 0.0006],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.5476e-01, 5.3071e-02, 7.2979e-04, 3.5709e-03, 2.8408e-03, 1.9576e-01,\n",
      "        5.4475e-04, 1.0819e-03, 1.9637e-02, 4.9910e-02, 3.0211e-04, 2.0170e-03,\n",
      "        2.3062e-02, 3.7612e-03, 1.7070e-02, 1.2574e-02, 1.8328e-03, 1.5035e-04,\n",
      "        1.4627e-02, 1.7734e-02, 1.1257e-02, 9.8067e-03, 3.8357e-04, 1.4178e-03,\n",
      "        9.5842e-05, 1.9322e-03, 6.4186e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.9016e-05, 1.2096e-01, 4.8403e-02, 4.8526e-02, 3.8139e-02, 3.5915e-02,\n",
      "        2.2728e-02, 1.8318e-02, 5.1621e-02, 6.6393e-02, 6.8260e-03, 5.1279e-03,\n",
      "        3.2352e-02, 4.8084e-02, 2.1566e-02, 7.4892e-02, 3.9424e-02, 1.7876e-03,\n",
      "        1.5839e-02, 3.9019e-02, 1.7850e-01, 1.6859e-02, 7.3057e-03, 5.9141e-02,\n",
      "        1.3907e-04, 1.9523e-03, 1.3153e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.2350e-04, 9.7042e-02, 1.2025e-03, 9.9576e-04, 8.6041e-05, 1.6461e-01,\n",
      "        1.7159e-03, 1.5429e-04, 8.1169e-02, 4.3989e-02, 2.3927e-04, 3.4713e-04,\n",
      "        9.6807e-02, 1.1735e-03, 2.9966e-03, 1.3545e-01, 1.7569e-02, 2.9835e-04,\n",
      "        2.9442e-01, 3.3931e-03, 7.1384e-03, 4.3846e-02, 6.2739e-04, 1.0134e-03,\n",
      "        3.7208e-04, 2.8641e-03, 5.9500e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0003, 0.0109, 0.0052, 0.0507, 0.0209, 0.0257, 0.0178, 0.0064, 0.0012,\n",
      "        0.0086, 0.0004, 0.0025, 0.1680, 0.0227, 0.1740, 0.0275, 0.0125, 0.0007,\n",
      "        0.2603, 0.1022, 0.0520, 0.0019, 0.0228, 0.0020, 0.0013, 0.0007, 0.0007],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.0181e-02, 4.7515e-02, 2.1663e-03, 2.0609e-02, 8.3928e-03, 2.8387e-01,\n",
      "        5.0995e-03, 1.0304e-02, 1.1454e-02, 3.1824e-01, 1.0522e-03, 8.5669e-03,\n",
      "        3.3840e-02, 5.3626e-03, 1.0996e-02, 2.4233e-02, 4.6369e-03, 3.0065e-04,\n",
      "        7.5851e-03, 6.5330e-02, 2.4628e-02, 6.5467e-02, 2.2331e-03, 1.0586e-03,\n",
      "        9.4468e-05, 6.7032e-03, 7.6785e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.6221e-01, 1.1878e-02, 8.1107e-04, 9.1199e-03, 1.9125e-03, 3.7389e-02,\n",
      "        1.9321e-03, 4.9581e-04, 2.2614e-04, 3.0176e-02, 7.1498e-05, 4.8675e-04,\n",
      "        2.2585e-03, 1.8119e-02, 3.9016e-03, 2.1562e-02, 7.4529e-03, 8.6785e-05,\n",
      "        3.2939e-03, 1.4887e-01, 2.4762e-02, 6.8477e-03, 1.6701e-03, 1.3549e-03,\n",
      "        2.9208e-05, 3.0082e-03, 6.7604e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.4434e-02, 1.1068e-01, 7.7128e-04, 1.1431e-03, 2.5072e-04, 1.7397e-01,\n",
      "        9.3896e-04, 1.7136e-04, 9.7583e-02, 2.7913e-01, 7.8616e-05, 2.8163e-04,\n",
      "        2.5812e-02, 2.5603e-03, 2.1904e-03, 7.2269e-02, 2.3723e-03, 1.0674e-04,\n",
      "        6.0947e-02, 2.1611e-02, 4.3029e-03, 4.8826e-02, 2.9219e-04, 5.7602e-04,\n",
      "        7.9086e-06, 3.8653e-02, 3.8874e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.1146e-03, 3.0988e-02, 7.1365e-03, 9.5307e-02, 1.1166e-02, 2.3866e-02,\n",
      "        1.3462e-02, 7.3080e-03, 1.3748e-03, 8.9998e-03, 1.3283e-04, 1.6066e-03,\n",
      "        1.3232e-02, 2.9086e-02, 2.1079e-01, 4.0992e-01, 2.9223e-03, 3.3586e-04,\n",
      "        1.9036e-02, 3.6465e-02, 4.8400e-02, 3.6507e-03, 1.5446e-02, 1.6872e-03,\n",
      "        1.4403e-04, 2.2240e-03, 1.2060e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.1786e-03, 1.0451e-03, 2.1257e-03, 3.0566e-03, 8.9425e-03, 1.0855e-03,\n",
      "        1.4127e-02, 2.7249e-03, 1.0046e-04, 1.8881e-03, 9.7751e-05, 2.3039e-03,\n",
      "        1.1713e-02, 8.9157e-03, 8.3061e-01, 6.5960e-04, 6.4973e-03, 9.3981e-05,\n",
      "        1.3908e-02, 2.0476e-02, 6.6032e-03, 5.2273e-02, 2.2843e-03, 2.5953e-03,\n",
      "        1.3965e-04, 4.5923e-04, 9.4551e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.8996e-01, 9.1502e-03, 1.7908e-04, 1.5564e-02, 1.1479e-02, 2.8858e-02,\n",
      "        9.6654e-04, 4.7427e-03, 2.8569e-04, 1.2610e-02, 7.1881e-05, 8.2941e-04,\n",
      "        2.5472e-03, 8.0517e-04, 2.0247e-03, 2.6993e-03, 3.5126e-04, 2.4650e-05,\n",
      "        2.5309e-04, 1.9136e-01, 2.0945e-02, 9.1272e-04, 3.6808e-04, 3.1109e-04,\n",
      "        8.8128e-06, 2.6793e-03, 1.5213e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.4992e-01, 6.1381e-03, 2.8774e-04, 2.7316e-03, 3.1556e-04, 9.6350e-02,\n",
      "        6.5466e-04, 1.9120e-04, 1.7450e-03, 2.4801e-02, 1.8553e-05, 3.4767e-04,\n",
      "        2.2300e-03, 2.4602e-03, 5.0116e-04, 1.9302e-02, 2.7507e-03, 1.8503e-05,\n",
      "        7.6039e-04, 3.5931e-02, 4.0230e-02, 6.6387e-03, 1.5059e-04, 8.9073e-04,\n",
      "        1.6391e-06, 4.6176e-03, 1.4624e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.4119e-05, 2.2447e-01, 2.7555e-02, 2.8836e-02, 1.2665e-02, 2.2307e-02,\n",
      "        2.6609e-02, 7.0837e-03, 4.0157e-02, 9.6523e-02, 2.9138e-03, 1.7968e-03,\n",
      "        2.3322e-02, 2.0245e-02, 1.8454e-02, 2.1302e-01, 2.3765e-02, 1.2936e-03,\n",
      "        1.8261e-02, 2.3835e-02, 8.9015e-02, 1.7339e-02, 6.5173e-03, 5.1250e-02,\n",
      "        7.8922e-05, 2.5442e-03, 7.3939e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1006e-01, 1.0220e-03, 1.5602e-02, 2.4339e-02, 1.5027e-02, 1.7670e-03,\n",
      "        7.0449e-03, 1.1282e-02, 2.4949e-03, 5.4604e-03, 2.9990e-04, 2.9212e-03,\n",
      "        6.5133e-02, 1.3513e-02, 4.5469e-01, 2.0832e-03, 1.4240e-02, 3.7781e-04,\n",
      "        6.7639e-02, 1.2714e-01, 3.8512e-02, 4.7415e-03, 6.3804e-03, 2.1973e-03,\n",
      "        1.3650e-03, 4.4076e-03, 2.6130e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.9241e-02, 2.7841e-03, 1.6618e-03, 1.7588e-02, 8.1172e-01, 5.1512e-03,\n",
      "        3.0392e-03, 7.2295e-03, 1.9071e-04, 6.2760e-03, 1.6782e-03, 5.8564e-03,\n",
      "        4.2459e-03, 1.4466e-03, 2.1549e-03, 1.4265e-02, 4.1920e-04, 7.4940e-04,\n",
      "        3.2647e-04, 1.0897e-02, 1.9051e-02, 6.1049e-04, 4.6325e-03, 2.0912e-03,\n",
      "        4.3969e-04, 6.1302e-03, 1.2812e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.4959e-01, 3.0728e-03, 1.4550e-04, 7.7727e-04, 8.1624e-04, 8.9185e-03,\n",
      "        5.6734e-04, 4.3583e-04, 7.0020e-05, 1.1598e-02, 6.3353e-05, 2.4354e-04,\n",
      "        1.0775e-03, 8.7010e-04, 4.3925e-04, 5.9483e-03, 2.0076e-04, 1.0179e-04,\n",
      "        7.3026e-04, 5.0005e-03, 1.1250e-03, 3.6731e-03, 4.9513e-04, 5.6340e-04,\n",
      "        7.3479e-05, 3.3774e-03, 2.7424e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3520e-05, 1.1388e-01, 4.1860e-02, 6.0160e-02, 3.3304e-02, 4.3574e-02,\n",
      "        3.0911e-02, 1.7635e-02, 2.8302e-02, 8.6952e-02, 5.3690e-03, 4.1859e-03,\n",
      "        2.4304e-02, 5.9175e-02, 2.6503e-02, 6.1051e-02, 4.9905e-02, 2.2181e-03,\n",
      "        2.1032e-02, 6.9355e-02, 1.2723e-01, 1.6076e-02, 1.2256e-02, 6.2470e-02,\n",
      "        1.8525e-04, 1.9109e-03, 1.5737e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.6083e-04, 1.5953e-02, 1.5550e-04, 7.4579e-05, 6.6863e-06, 8.5753e-03,\n",
      "        6.9119e-04, 3.0020e-05, 8.1292e-01, 9.4544e-03, 7.8703e-05, 1.7503e-04,\n",
      "        7.5741e-04, 2.0762e-04, 2.2576e-04, 1.2307e-01, 2.4272e-04, 4.4568e-05,\n",
      "        1.2756e-02, 3.0316e-04, 8.8414e-04, 1.0226e-02, 4.9410e-05, 2.4591e-04,\n",
      "        3.1883e-05, 2.0581e-03, 2.0412e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.3774e-03, 1.3349e-01, 7.7232e-05, 4.0037e-05, 2.7315e-05, 7.3250e-01,\n",
      "        1.8114e-04, 4.2043e-05, 8.6966e-04, 7.0652e-02, 9.7400e-05, 1.1335e-04,\n",
      "        1.1453e-03, 1.0877e-03, 4.3872e-04, 3.4435e-02, 2.8426e-04, 7.2457e-05,\n",
      "        5.1085e-03, 4.5668e-04, 6.6041e-04, 1.0361e-02, 5.2672e-05, 3.8334e-04,\n",
      "        2.1235e-05, 4.0087e-03, 1.5960e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.3793e-01, 1.4194e-02, 1.4991e-03, 5.2702e-03, 3.7583e-03, 2.9357e-02,\n",
      "        1.9855e-03, 2.8224e-03, 2.0146e-03, 3.6065e-02, 7.5188e-04, 2.2406e-03,\n",
      "        1.3007e-02, 3.4382e-02, 1.7890e-02, 2.3211e-03, 4.2915e-03, 9.4951e-04,\n",
      "        9.5366e-02, 5.8766e-02, 9.8596e-03, 1.1640e-03, 4.8622e-03, 3.3775e-03,\n",
      "        3.7506e-04, 1.5150e-02, 3.4664e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.2033e-02, 2.5149e-02, 1.4881e-03, 3.3466e-03, 4.4763e-03, 7.3642e-01,\n",
      "        1.3376e-03, 4.2299e-03, 6.0420e-03, 4.5944e-02, 1.0721e-03, 2.6435e-03,\n",
      "        3.7558e-03, 1.7324e-02, 2.4922e-03, 8.6086e-03, 2.8483e-03, 5.8675e-04,\n",
      "        5.6478e-03, 2.3022e-02, 2.5697e-03, 4.4135e-03, 1.5367e-03, 1.0494e-03,\n",
      "        1.6909e-04, 4.1492e-02, 2.9923e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.4055e-01, 1.1603e-02, 1.5446e-03, 1.0576e-02, 3.5493e-02, 1.1142e-02,\n",
      "        6.5415e-03, 7.4539e-03, 1.9453e-04, 4.4858e-03, 6.7471e-04, 9.7680e-04,\n",
      "        6.0093e-03, 1.6714e-02, 1.5355e-02, 1.2948e-03, 3.7957e-03, 1.8571e-03,\n",
      "        1.5160e-02, 7.8066e-02, 4.4889e-03, 9.7012e-04, 1.3672e-02, 4.4208e-03,\n",
      "        1.5487e-03, 5.0758e-03, 3.3435e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0438e-04, 1.3460e-01, 3.1312e-02, 5.6801e-02, 3.0640e-02, 4.1479e-02,\n",
      "        4.5030e-02, 1.7953e-02, 3.5140e-02, 8.1032e-02, 6.1291e-03, 3.7320e-03,\n",
      "        2.2197e-02, 5.6830e-02, 2.4499e-02, 7.3335e-02, 5.2626e-02, 2.5409e-03,\n",
      "        2.3552e-02, 8.4593e-02, 7.6466e-02, 1.6307e-02, 1.2382e-02, 6.8023e-02,\n",
      "        2.5714e-04, 2.2659e-03, 1.7290e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.8013e-04, 1.1429e-03, 9.8115e-03, 2.8723e-03, 6.4955e-03, 2.1646e-03,\n",
      "        5.6178e-01, 1.6861e-03, 1.5067e-03, 9.1255e-04, 5.1941e-04, 2.2665e-03,\n",
      "        1.3999e-02, 1.1019e-02, 1.1912e-01, 3.7387e-03, 2.9319e-02, 4.6922e-04,\n",
      "        1.0430e-01, 2.7574e-03, 1.7597e-02, 6.9322e-02, 8.0489e-03, 2.6355e-02,\n",
      "        1.4049e-03, 4.2011e-04, 1.9379e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.4488e-01, 1.4864e-03, 1.9333e-04, 1.4436e-03, 6.8001e-04, 1.0013e-02,\n",
      "        2.7951e-03, 1.6264e-04, 3.3913e-04, 2.6371e-03, 8.6742e-05, 4.2734e-04,\n",
      "        3.4400e-03, 1.4188e-03, 1.0602e-03, 3.3280e-03, 5.8397e-04, 9.0449e-05,\n",
      "        1.0714e-02, 1.6501e-03, 8.3208e-03, 2.6788e-03, 4.2368e-04, 6.5819e-04,\n",
      "        7.4554e-05, 3.8997e-04, 2.8758e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997019767761\n",
      "Softmaxed: tensor([4.2866e-05, 9.6927e-02, 3.6097e-02, 4.4825e-02, 1.9321e-02, 5.6006e-02,\n",
      "        2.9268e-02, 1.7066e-02, 4.4913e-02, 6.8084e-02, 7.8596e-03, 5.8332e-03,\n",
      "        2.5337e-02, 5.8029e-02, 1.8966e-02, 4.1249e-02, 4.2578e-02, 1.4429e-03,\n",
      "        1.9794e-02, 3.2309e-02, 2.6263e-01, 1.2262e-02, 1.0517e-02, 4.6873e-02,\n",
      "        1.2639e-04, 1.4852e-03, 1.5759e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "led and very handy workmen who require a <------ | ------> nd mormance how pidytions and there of s\n",
      "Epoch 1   Time 62.602    Train Loss: 1.685\n",
      "Softmaxed: tensor([0.0019, 0.0033, 0.0306, 0.0159, 0.0147, 0.0043, 0.0034, 0.0085, 0.0008,\n",
      "        0.2747, 0.0004, 0.0052, 0.0263, 0.0182, 0.0937, 0.0113, 0.0285, 0.0003,\n",
      "        0.2074, 0.0235, 0.1313, 0.0234, 0.0201, 0.0018, 0.0003, 0.0490, 0.0009],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.4508e-03, 8.2306e-02, 3.0831e-03, 7.3845e-03, 2.5044e-02, 2.0025e-01,\n",
      "        1.3720e-03, 5.7375e-03, 1.3465e-03, 4.3898e-01, 2.2599e-04, 5.1897e-03,\n",
      "        4.9417e-03, 9.5802e-03, 1.0830e-02, 2.8984e-02, 1.5576e-03, 1.6830e-04,\n",
      "        2.0681e-03, 2.0190e-02, 4.6284e-02, 3.8994e-03, 1.5761e-03, 9.8221e-04,\n",
      "        5.1680e-05, 8.8402e-02, 1.1620e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.3888e-03, 4.5384e-02, 7.4895e-03, 2.3884e-02, 2.1298e-02, 7.7192e-02,\n",
      "        4.0020e-02, 2.6680e-02, 7.3011e-04, 4.0589e-03, 9.5436e-05, 1.3747e-03,\n",
      "        2.0667e-02, 9.0072e-03, 2.0828e-01, 1.0751e-01, 1.3301e-03, 2.2391e-04,\n",
      "        6.6597e-03, 1.4525e-01, 2.1326e-01, 3.5819e-03, 2.0948e-02, 1.1509e-03,\n",
      "        3.7061e-04, 2.4644e-03, 6.7013e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.2942e-02, 3.1649e-03, 1.4478e-03, 4.1226e-03, 1.4063e-01, 1.3395e-03,\n",
      "        1.3216e-02, 7.8526e-03, 6.5444e-05, 1.2776e-03, 4.0595e-05, 4.6556e-04,\n",
      "        6.0227e-03, 9.4749e-03, 2.1407e-01, 2.6786e-04, 1.7654e-03, 3.8352e-04,\n",
      "        7.5102e-03, 4.7157e-01, 1.0303e-02, 8.2008e-04, 3.7014e-02, 1.2185e-03,\n",
      "        9.2209e-04, 1.9936e-03, 1.0631e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.4296e-01, 2.0967e-04, 3.4087e-05, 5.8315e-04, 4.1352e-05, 7.7796e-04,\n",
      "        2.8376e-04, 1.0706e-05, 1.2315e-04, 5.0212e-04, 9.0169e-07, 2.2312e-05,\n",
      "        1.2189e-04, 4.6815e-04, 3.2733e-04, 3.7780e-04, 2.9802e-04, 1.9343e-06,\n",
      "        6.7042e-05, 3.8319e-02, 1.3981e-02, 1.6302e-04, 1.8822e-05, 5.3561e-05,\n",
      "        6.9387e-07, 2.5455e-04, 2.5530e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([1.6212e-05, 2.2359e-01, 4.2930e-02, 2.2057e-02, 2.4069e-02, 1.7104e-02,\n",
      "        3.2085e-02, 6.0455e-03, 5.5131e-02, 9.0374e-02, 2.1440e-03, 1.1621e-03,\n",
      "        1.7159e-02, 2.0713e-02, 2.0073e-02, 1.5388e-01, 1.7513e-02, 8.2387e-04,\n",
      "        1.7279e-02, 4.9054e-02, 1.2000e-01, 9.0806e-03, 4.7799e-03, 4.9043e-02,\n",
      "        4.4263e-05, 3.8002e-03, 4.2607e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1794e-01, 4.3258e-04, 2.0130e-02, 2.0001e-02, 1.0127e-02, 4.7801e-04,\n",
      "        4.8317e-03, 1.3374e-02, 1.2480e-03, 2.5199e-03, 9.4676e-05, 8.4924e-04,\n",
      "        7.4958e-02, 8.6001e-03, 5.2392e-01, 8.0269e-04, 1.2459e-02, 2.3085e-04,\n",
      "        4.4994e-02, 1.0215e-01, 3.0989e-02, 2.5638e-03, 1.6698e-03, 2.0077e-03,\n",
      "        5.4526e-04, 1.9664e-03, 1.0998e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.2497e-01, 3.4805e-03, 5.7938e-04, 1.6408e-02, 8.3000e-04, 1.3939e-02,\n",
      "        2.8814e-03, 2.8599e-04, 1.1309e-03, 3.7889e-03, 5.2581e-05, 1.2528e-03,\n",
      "        9.5839e-04, 5.6609e-03, 6.1451e-04, 7.4582e-03, 7.0862e-03, 2.1533e-04,\n",
      "        4.1628e-04, 5.2721e-02, 5.1386e-02, 1.5615e-03, 4.4520e-04, 9.8827e-04,\n",
      "        2.0531e-05, 8.3020e-04, 3.3487e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.7406e-05, 1.7359e-01, 3.3372e-02, 2.2394e-02, 2.0811e-02, 5.9299e-02,\n",
      "        2.7194e-02, 1.7499e-02, 5.1819e-02, 1.3379e-01, 3.7948e-03, 5.5030e-03,\n",
      "        1.4649e-02, 4.1461e-02, 1.6461e-02, 5.4601e-02, 3.3518e-02, 1.1498e-03,\n",
      "        2.2936e-02, 5.0421e-02, 1.4709e-01, 1.4896e-02, 5.8677e-03, 4.4392e-02,\n",
      "        6.6221e-05, 3.3598e-03, 4.9552e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1163e-03, 1.8610e-02, 7.6008e-05, 1.9686e-05, 1.7605e-06, 1.0703e-02,\n",
      "        4.1842e-04, 1.3737e-05, 7.1490e-01, 1.0873e-02, 2.8231e-05, 1.2183e-04,\n",
      "        6.5718e-04, 1.5953e-04, 1.2349e-04, 2.1244e-01, 7.9665e-05, 2.6014e-05,\n",
      "        2.1052e-02, 2.5844e-04, 4.0041e-04, 5.8687e-03, 1.8160e-05, 2.5292e-04,\n",
      "        1.0888e-05, 1.7635e-03, 1.4303e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5189e-03, 1.2064e-01, 2.2382e-05, 4.9161e-06, 3.9610e-06, 7.7025e-01,\n",
      "        4.0563e-05, 1.2295e-05, 3.3570e-04, 6.6645e-02, 3.0485e-05, 3.5309e-05,\n",
      "        3.1942e-04, 4.5347e-04, 1.7425e-04, 2.7589e-02, 3.2161e-05, 1.1885e-05,\n",
      "        4.0512e-03, 2.0845e-04, 4.1750e-04, 5.1281e-03, 8.6645e-06, 1.8011e-04,\n",
      "        7.0215e-06, 1.8777e-03, 4.3908e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.8965e-01, 4.4815e-03, 4.6065e-04, 6.4412e-04, 5.5204e-04, 1.6229e-02,\n",
      "        7.1143e-04, 9.6775e-04, 1.2109e-03, 4.5017e-02, 2.1441e-04, 1.2012e-03,\n",
      "        5.3461e-03, 4.3528e-02, 1.0973e-02, 1.3767e-03, 2.0207e-03, 1.7053e-04,\n",
      "        8.0883e-02, 4.1354e-02, 3.7039e-03, 4.1264e-04, 1.3096e-03, 1.6087e-03,\n",
      "        1.3966e-04, 4.5740e-02, 9.8947e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.2592e-05, 4.2840e-02, 4.8529e-02, 6.5929e-02, 7.0863e-02, 4.1112e-02,\n",
      "        4.7730e-02, 4.2888e-02, 5.6952e-02, 5.1956e-02, 3.4457e-03, 5.4605e-03,\n",
      "        2.7156e-02, 7.8057e-02, 2.0423e-02, 4.4701e-02, 7.2579e-02, 2.4002e-03,\n",
      "        4.0367e-02, 1.1203e-01, 3.3108e-02, 1.3051e-02, 1.3763e-02, 6.2816e-02,\n",
      "        1.4969e-04, 1.5637e-03, 6.7242e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4871e-02, 9.7769e-02, 2.7258e-03, 3.6577e-02, 6.5327e-05, 1.9198e-01,\n",
      "        5.8216e-03, 7.3070e-04, 2.2036e-02, 6.4328e-02, 4.8938e-04, 2.6898e-03,\n",
      "        6.5818e-03, 7.4155e-03, 3.0799e-03, 2.0585e-01, 8.0078e-02, 7.9076e-04,\n",
      "        2.9529e-03, 3.4375e-03, 6.8821e-02, 1.5651e-01, 2.7566e-04, 2.2180e-03,\n",
      "        2.5553e-04, 1.1551e-02, 9.1475e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.3830e-03, 4.9635e-02, 4.8342e-03, 7.2054e-02, 7.6525e-03, 1.3463e-01,\n",
      "        1.6597e-02, 6.1048e-03, 2.8527e-04, 1.4632e-02, 7.7937e-04, 1.9050e-03,\n",
      "        1.8428e-01, 6.9656e-02, 2.2369e-01, 9.9584e-03, 2.1059e-02, 1.5404e-02,\n",
      "        8.4163e-02, 1.1035e-02, 2.6675e-02, 5.0796e-03, 1.9227e-02, 3.9249e-03,\n",
      "        7.9600e-03, 2.2110e-03, 1.7967e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0593e-02, 2.0733e-04, 1.5194e-02, 3.4499e-02, 4.1680e-02, 3.3780e-04,\n",
      "        6.8007e-03, 4.7508e-03, 1.9263e-03, 5.1448e-03, 8.2083e-04, 2.2216e-02,\n",
      "        1.1654e-01, 2.9654e-02, 1.6874e-01, 1.0247e-04, 5.5849e-02, 1.3285e-03,\n",
      "        1.9492e-01, 7.2903e-02, 1.8770e-01, 7.9218e-03, 1.3457e-02, 3.1705e-03,\n",
      "        1.0263e-03, 1.6899e-03, 8.1751e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.5922e-01, 3.7864e-03, 5.0733e-04, 6.4939e-02, 4.7864e-02, 1.3720e-02,\n",
      "        5.9785e-03, 1.4870e-02, 7.1846e-04, 2.0646e-02, 5.1710e-04, 5.1455e-03,\n",
      "        9.9313e-03, 8.9471e-04, 2.2580e-03, 3.0273e-03, 5.6449e-04, 3.0024e-04,\n",
      "        5.9264e-04, 9.9003e-02, 3.4777e-02, 1.7941e-03, 1.3938e-03, 8.7685e-04,\n",
      "        1.8408e-04, 6.4207e-03, 7.2633e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.4372e-05, 1.4182e-01, 4.3625e-02, 5.5804e-02, 2.5893e-02, 3.3100e-02,\n",
      "        5.1467e-02, 1.2985e-02, 5.0177e-02, 8.7107e-02, 2.3747e-03, 2.0904e-03,\n",
      "        1.9005e-02, 3.5512e-02, 1.8648e-02, 1.0202e-01, 2.8754e-02, 1.6499e-03,\n",
      "        1.3186e-02, 6.8430e-02, 1.1998e-01, 1.0450e-02, 7.1492e-03, 6.5169e-02,\n",
      "        6.9318e-05, 3.4093e-03, 1.0668e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3425e-03, 3.2179e-01, 3.9099e-04, 6.1870e-05, 8.9474e-06, 2.6386e-01,\n",
      "        6.0084e-04, 6.7189e-05, 2.3516e-04, 2.0037e-01, 4.9754e-05, 8.7010e-06,\n",
      "        2.3235e-03, 1.1571e-03, 5.2903e-04, 1.6994e-01, 2.3708e-03, 5.4775e-05,\n",
      "        2.9960e-03, 8.3268e-04, 4.6396e-04, 2.4666e-02, 1.7265e-04, 1.7950e-03,\n",
      "        5.2375e-05, 3.8487e-03, 9.4220e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.6057e-02, 6.1741e-03, 1.2663e-02, 3.8380e-03, 1.7732e-02, 1.2402e-02,\n",
      "        8.5674e-03, 7.9246e-03, 1.0171e-03, 8.6479e-03, 4.6236e-04, 1.9054e-03,\n",
      "        1.6711e-02, 6.1841e-02, 4.1383e-02, 2.7305e-02, 1.4496e-02, 2.3377e-04,\n",
      "        8.7662e-02, 3.1865e-02, 4.6182e-02, 5.1974e-02, 3.9780e-02, 4.5934e-01,\n",
      "        1.2561e-03, 2.2310e-03, 3.4907e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.5812e-01, 4.6299e-02, 3.4349e-04, 1.7171e-03, 2.1111e-03, 1.5348e-01,\n",
      "        3.3439e-04, 1.0695e-03, 7.4586e-03, 3.2147e-02, 1.2352e-04, 9.4251e-04,\n",
      "        1.5727e-02, 3.4077e-03, 2.8222e-02, 7.3683e-03, 8.1720e-04, 7.3456e-05,\n",
      "        7.5673e-03, 2.4083e-02, 4.1741e-03, 2.3370e-03, 2.9431e-04, 8.6219e-04,\n",
      "        7.1817e-05, 8.2428e-04, 2.9410e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1753e-05, 1.0157e-01, 6.0456e-02, 4.9449e-02, 4.7620e-02, 3.1753e-02,\n",
      "        2.5910e-02, 1.8274e-02, 8.2972e-02, 7.1466e-02, 4.4573e-03, 4.6518e-03,\n",
      "        2.4342e-02, 4.3387e-02, 1.4210e-02, 6.9566e-02, 3.4933e-02, 1.5250e-03,\n",
      "        1.3226e-02, 4.5389e-02, 1.7768e-01, 1.4276e-02, 6.1231e-03, 5.4059e-02,\n",
      "        8.8584e-05, 2.5350e-03, 7.0698e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.0666e-03, 1.9207e-02, 8.5973e-05, 2.3723e-05, 2.0015e-06, 1.0312e-02,\n",
      "        4.3522e-04, 1.1546e-05, 6.2741e-01, 1.2147e-02, 2.9037e-05, 9.6622e-05,\n",
      "        5.7874e-04, 1.5142e-04, 1.2653e-04, 3.0063e-01, 6.7031e-05, 2.6022e-05,\n",
      "        1.7956e-02, 1.9951e-04, 4.2954e-04, 6.2295e-03, 1.9862e-05, 2.4305e-04,\n",
      "        1.1510e-05, 2.4895e-03, 1.5548e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8443e-03, 1.4282e-01, 2.6290e-05, 6.1662e-06, 4.8545e-06, 7.3650e-01,\n",
      "        4.6135e-05, 1.1913e-05, 3.4464e-04, 6.7595e-02, 3.2350e-05, 3.3654e-05,\n",
      "        3.3481e-04, 5.6811e-04, 2.2856e-04, 3.6230e-02, 3.5824e-05, 1.4496e-05,\n",
      "        5.1184e-03, 2.5532e-04, 4.6107e-04, 5.2630e-03, 1.0734e-05, 2.0699e-04,\n",
      "        9.1678e-06, 1.9971e-03, 5.1437e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.1863e-01, 5.4342e-03, 6.1344e-04, 8.8636e-04, 6.4913e-04, 1.7439e-02,\n",
      "        8.9395e-04, 1.1979e-03, 1.3340e-03, 5.0457e-02, 2.6535e-04, 1.4809e-03,\n",
      "        6.7605e-03, 5.8374e-02, 1.4434e-02, 1.6104e-03, 2.7933e-03, 2.1404e-04,\n",
      "        1.0409e-01, 4.7307e-02, 4.7364e-03, 5.4511e-04, 1.7755e-03, 2.1301e-03,\n",
      "        1.8723e-04, 5.5640e-02, 1.1915e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.6727e-01, 1.4279e-04, 1.6453e-04, 1.1140e-03, 3.4797e-04, 2.9522e-03,\n",
      "        2.4165e-04, 3.8519e-04, 1.8497e-04, 6.2450e-04, 1.6193e-05, 4.6104e-04,\n",
      "        7.9784e-04, 3.5944e-03, 1.8511e-04, 3.4627e-04, 8.2686e-04, 2.7448e-05,\n",
      "        1.4446e-03, 1.6190e-02, 1.8013e-03, 9.9430e-05, 3.4357e-04, 1.5863e-04,\n",
      "        1.5635e-05, 2.2740e-04, 3.8424e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([4.8311e-05, 8.4578e-02, 4.4167e-02, 4.7080e-02, 4.8368e-02, 3.8764e-02,\n",
      "        4.7117e-02, 2.3696e-02, 8.6775e-02, 7.2469e-02, 3.5041e-03, 4.8246e-03,\n",
      "        1.6039e-02, 5.3643e-02, 2.4633e-02, 5.9067e-02, 4.8060e-02, 1.7581e-03,\n",
      "        2.7936e-02, 1.0846e-01, 6.9675e-02, 9.8400e-03, 1.4056e-02, 6.2701e-02,\n",
      "        1.0377e-04, 2.5308e-03, 1.0425e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.2560e-05, 1.2235e-01, 1.1420e-04, 6.4594e-05, 5.5519e-05, 7.2083e-01,\n",
      "        1.1982e-04, 1.6152e-04, 5.7553e-04, 4.7523e-02, 7.6864e-05, 1.8165e-05,\n",
      "        1.7255e-03, 2.7658e-04, 2.3734e-04, 6.1923e-02, 1.4842e-04, 7.9660e-05,\n",
      "        6.7005e-04, 9.3729e-05, 7.1978e-05, 3.7917e-02, 1.2886e-04, 1.5460e-04,\n",
      "        8.1588e-05, 4.5662e-03, 8.0906e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0017, 0.2285, 0.0118, 0.0561, 0.0141, 0.0200, 0.0497, 0.0694, 0.0005,\n",
      "        0.0171, 0.0046, 0.0023, 0.1175, 0.0538, 0.0494, 0.0080, 0.0605, 0.0169,\n",
      "        0.0222, 0.0912, 0.0481, 0.0067, 0.0311, 0.0106, 0.0044, 0.0030, 0.0008],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0016, 0.0008, 0.0325, 0.0484, 0.1465, 0.0004, 0.0016, 0.0301, 0.0026,\n",
      "        0.0103, 0.0024, 0.0149, 0.2585, 0.0086, 0.0240, 0.0003, 0.0359, 0.0008,\n",
      "        0.0899, 0.1774, 0.0887, 0.0128, 0.0034, 0.0034, 0.0005, 0.0027, 0.0008],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.4353e-03, 5.9910e-02, 3.3480e-03, 3.9733e-03, 8.4771e-03, 4.5114e-01,\n",
      "        1.1674e-03, 4.3220e-03, 9.8141e-02, 8.9334e-02, 8.8513e-04, 6.6180e-03,\n",
      "        7.9621e-02, 1.6839e-03, 2.0346e-02, 6.2799e-02, 2.2190e-03, 8.8229e-04,\n",
      "        1.8066e-02, 2.9523e-02, 9.6730e-03, 3.1525e-02, 1.0245e-03, 9.1129e-04,\n",
      "        4.5840e-04, 5.1867e-03, 3.3161e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.2766e-02, 7.4840e-02, 2.5724e-04, 4.2494e-03, 5.7961e-03, 5.1368e-01,\n",
      "        1.1708e-03, 4.3026e-04, 1.8050e-04, 7.4541e-02, 2.6312e-04, 1.4357e-04,\n",
      "        9.0064e-04, 6.8723e-04, 2.2054e-04, 1.9816e-01, 8.6072e-05, 2.3325e-04,\n",
      "        2.5398e-03, 5.4930e-03, 3.3118e-03, 5.3722e-03, 5.0334e-04, 9.9442e-04,\n",
      "        1.0978e-04, 1.2989e-02, 8.4592e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.5536e-02, 1.6042e-02, 3.9504e-03, 3.0650e-02, 6.7158e-02, 3.4248e-03,\n",
      "        4.9489e-03, 2.8141e-03, 9.4649e-05, 1.8726e-03, 4.8075e-04, 6.0299e-04,\n",
      "        1.0933e-02, 1.1763e-02, 5.9060e-02, 2.0394e-03, 3.6120e-03, 2.0093e-03,\n",
      "        3.8397e-01, 2.9231e-01, 2.2369e-02, 1.2370e-03, 1.1954e-02, 1.3109e-02,\n",
      "        4.1948e-03, 3.0701e-03, 7.9644e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.5667e-05, 1.5008e-01, 3.4556e-02, 3.8425e-02, 2.1778e-02, 3.2941e-02,\n",
      "        4.3059e-02, 7.2860e-03, 5.0678e-02, 1.0460e-01, 2.9725e-03, 1.4690e-03,\n",
      "        8.6780e-03, 2.3134e-02, 1.4900e-02, 1.0493e-01, 2.6897e-02, 1.6318e-03,\n",
      "        1.3244e-02, 9.5433e-02, 1.2092e-01, 1.4689e-02, 7.9111e-03, 7.6213e-02,\n",
      "        1.3098e-04, 3.3152e-03, 1.0150e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5580e-03, 3.2896e-01, 4.4244e-04, 7.2867e-05, 9.7935e-06, 2.1056e-01,\n",
      "        5.4962e-04, 6.8743e-05, 1.7378e-04, 2.3043e-01, 5.9820e-05, 7.8087e-06,\n",
      "        2.1418e-03, 1.4397e-03, 5.7359e-04, 1.8303e-01, 2.6799e-03, 5.6459e-05,\n",
      "        3.7434e-03, 1.2387e-03, 4.8394e-04, 2.3887e-02, 1.9599e-04, 1.9970e-03,\n",
      "        5.2617e-05, 5.5710e-03, 1.3180e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.0597e-03, 6.3813e-04, 9.7538e-03, 5.1599e-03, 4.0354e-02, 8.4890e-04,\n",
      "        4.2333e-03, 1.1322e-02, 2.6689e-04, 1.3765e-02, 2.5303e-04, 1.7220e-02,\n",
      "        2.6407e-03, 6.9811e-02, 6.8053e-02, 2.2649e-04, 7.5944e-02, 2.3281e-04,\n",
      "        3.4626e-02, 3.1409e-01, 4.7076e-02, 2.3782e-03, 2.3777e-01, 8.1227e-03,\n",
      "        6.4781e-04, 2.5120e-02, 3.9255e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4226e-03, 9.0191e-03, 1.5998e-04, 1.8327e-04, 9.0477e-05, 8.8982e-01,\n",
      "        4.9245e-04, 5.6382e-04, 2.3346e-04, 7.2091e-02, 4.8316e-05, 5.0813e-04,\n",
      "        2.1336e-03, 4.6515e-04, 1.1322e-03, 7.6064e-03, 6.4906e-04, 4.8807e-05,\n",
      "        9.1858e-04, 2.7804e-03, 6.7010e-04, 1.0346e-03, 1.0009e-04, 2.5215e-04,\n",
      "        9.7553e-06, 6.5451e-03, 2.3063e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.4711e-01, 7.8809e-04, 1.2581e-04, 2.4555e-04, 4.1904e-03, 1.3853e-03,\n",
      "        4.2525e-04, 1.0585e-04, 1.3255e-05, 1.0701e-03, 1.9096e-05, 8.1080e-05,\n",
      "        3.5515e-03, 1.0016e-03, 4.9977e-03, 1.4633e-04, 1.5372e-04, 5.9052e-05,\n",
      "        1.1801e-02, 1.8787e-02, 7.1440e-04, 1.0078e-04, 4.5056e-04, 2.8732e-04,\n",
      "        7.4030e-05, 2.3042e-03, 1.3820e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8839e-05, 1.1294e-01, 5.5706e-02, 2.9280e-02, 3.4095e-02, 3.5463e-02,\n",
      "        5.2860e-02, 1.3717e-02, 5.6192e-02, 6.8083e-02, 2.3540e-03, 2.8988e-03,\n",
      "        9.9497e-03, 2.7208e-02, 3.5669e-02, 8.7746e-02, 3.7470e-02, 9.7205e-04,\n",
      "        2.3804e-02, 7.5963e-02, 1.3793e-01, 1.4695e-02, 7.0749e-03, 7.3558e-02,\n",
      "        6.4275e-05, 4.2143e-03, 6.0063e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([7.1563e-04, 4.3274e-02, 1.4523e-03, 2.4128e-04, 1.6360e-04, 5.3895e-01,\n",
      "        4.5752e-04, 5.2123e-04, 9.3062e-04, 3.3864e-02, 6.7508e-04, 1.1773e-04,\n",
      "        3.3631e-02, 3.0053e-04, 2.9214e-03, 1.0928e-01, 6.8188e-04, 7.8395e-05,\n",
      "        1.8719e-02, 6.3817e-04, 1.2952e-03, 7.9622e-02, 2.0271e-04, 5.5888e-04,\n",
      "        1.4132e-04, 1.3047e-01, 8.8138e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "ruth to escape let others capture it aga <------ | ------> ries as the sean how they reagne have be\n",
      "Epoch 2   Time 63.664    Train Loss: 1.565\n",
      "Softmaxed: tensor([3.6684e-01, 6.4692e-02, 2.4152e-03, 1.0763e-01, 6.8625e-03, 8.2069e-02,\n",
      "        1.1616e-02, 7.3420e-03, 1.2300e-03, 5.6122e-02, 1.0401e-03, 1.2119e-03,\n",
      "        8.2695e-02, 4.0728e-03, 5.3962e-02, 7.1980e-03, 6.2622e-03, 1.5288e-03,\n",
      "        6.7547e-03, 1.4224e-02, 7.9314e-02, 1.9743e-03, 3.1704e-03, 1.6707e-02,\n",
      "        7.2501e-04, 1.2253e-02, 8.9677e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.1957e-04, 1.0721e-03, 4.5114e-03, 7.7848e-03, 2.1555e-02, 1.3369e-03,\n",
      "        7.6859e-03, 1.0483e-01, 2.6615e-04, 1.7959e-04, 1.2154e-04, 6.5898e-03,\n",
      "        9.3961e-03, 1.6980e-02, 7.6211e-01, 5.3679e-04, 1.4205e-03, 1.0950e-04,\n",
      "        1.5170e-02, 5.0422e-03, 1.1021e-02, 3.1356e-04, 1.8533e-02, 6.0046e-04,\n",
      "        4.6202e-04, 3.2135e-05, 1.6276e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.3202e-02, 3.7037e-02, 2.6085e-03, 2.1263e-03, 6.7503e-03, 4.4826e-02,\n",
      "        2.8621e-03, 2.2223e-02, 4.3842e-01, 4.8557e-02, 3.4523e-04, 5.4222e-03,\n",
      "        1.2851e-02, 8.4287e-03, 1.8447e-01, 6.8516e-03, 1.4537e-03, 6.0622e-04,\n",
      "        2.0158e-02, 7.0399e-02, 1.3075e-02, 9.1449e-03, 1.0320e-03, 1.2392e-03,\n",
      "        4.2347e-04, 3.1510e-03, 2.3403e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3359e-01, 1.3224e-02, 2.4901e-03, 4.6098e-03, 4.8276e-04, 5.2918e-02,\n",
      "        2.2503e-02, 8.7262e-04, 2.4418e-03, 6.7639e-02, 2.3080e-04, 6.1072e-04,\n",
      "        1.6921e-02, 1.7953e-03, 2.9919e-03, 2.2886e-01, 3.0503e-04, 3.7590e-04,\n",
      "        7.7269e-02, 5.5468e-04, 2.1611e-01, 1.4558e-01, 7.1344e-04, 1.3749e-03,\n",
      "        2.0290e-04, 4.8785e-03, 4.6102e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.5091e-02, 1.6515e-03, 7.2648e-03, 8.1024e-03, 2.9919e-03, 7.9062e-03,\n",
      "        2.6606e-03, 2.8405e-03, 3.5071e-04, 1.0260e-02, 3.7845e-04, 1.0039e-03,\n",
      "        1.3585e-01, 3.2137e-02, 1.5320e-02, 6.1501e-03, 1.2124e-02, 4.6672e-04,\n",
      "        3.8176e-01, 1.1498e-03, 1.0988e-02, 3.0976e-01, 3.0009e-03, 9.2941e-03,\n",
      "        4.6354e-04, 8.3646e-04, 1.9294e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1379e-02, 5.1907e-03, 2.1800e-02, 8.1649e-02, 1.0680e-02, 4.0172e-03,\n",
      "        1.1859e-03, 1.2725e-02, 1.4401e-03, 3.7048e-03, 1.7568e-04, 1.1801e-03,\n",
      "        2.4746e-01, 1.0587e-02, 7.3792e-02, 6.9487e-04, 4.1967e-03, 3.5107e-04,\n",
      "        2.7641e-01, 2.2787e-02, 2.0580e-01, 1.0192e-03, 5.5347e-04, 4.1168e-04,\n",
      "        1.9860e-04, 1.5131e-04, 4.5590e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.9027e-01, 5.9327e-03, 4.4437e-03, 1.6804e-02, 1.7786e-03, 1.2271e-01,\n",
      "        5.0459e-03, 1.0794e-03, 2.1960e-02, 3.3937e-02, 7.5159e-05, 1.7766e-03,\n",
      "        2.8012e-02, 2.2153e-02, 2.4822e-02, 2.4223e-03, 9.2237e-03, 1.5525e-04,\n",
      "        2.1687e-03, 1.7043e-02, 4.6324e-01, 1.8735e-02, 2.1349e-04, 9.9296e-04,\n",
      "        2.4440e-05, 4.8526e-03, 1.3260e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.7625e-02, 9.6761e-03, 7.9110e-05, 4.6992e-05, 3.8543e-04, 1.7949e-01,\n",
      "        7.8249e-04, 2.7779e-05, 1.5487e-05, 2.3895e-02, 2.8885e-06, 9.9711e-06,\n",
      "        2.9112e-03, 1.3006e-04, 1.5468e-04, 1.2296e-02, 1.6956e-05, 6.0591e-06,\n",
      "        1.0033e-04, 2.2890e-03, 1.4606e-04, 2.9511e-03, 1.4816e-04, 1.3920e-04,\n",
      "        2.3520e-06, 7.2666e-01, 1.1549e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9146e-01, 1.2554e-04, 4.2959e-05, 2.1713e-04, 6.5023e-05, 5.3428e-04,\n",
      "        1.6458e-04, 5.7309e-05, 2.9611e-06, 2.3517e-04, 1.0636e-06, 7.1961e-06,\n",
      "        1.3557e-04, 1.0251e-03, 4.8610e-04, 1.9694e-04, 1.0761e-04, 1.6197e-06,\n",
      "        3.1047e-05, 3.2558e-03, 1.2757e-03, 1.4043e-04, 7.0393e-05, 9.3388e-05,\n",
      "        4.2764e-06, 2.5519e-04, 9.2942e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.9655e-06, 1.6062e-01, 5.4244e-02, 2.8514e-02, 4.3930e-02, 2.4863e-02,\n",
      "        3.6960e-02, 2.7686e-02, 5.3308e-02, 7.2581e-02, 3.1960e-03, 4.9072e-03,\n",
      "        2.2658e-02, 4.4001e-02, 3.9274e-02, 5.0619e-02, 4.1714e-02, 1.5437e-03,\n",
      "        1.7694e-02, 5.8416e-02, 1.3195e-01, 9.8347e-03, 7.3067e-03, 6.1389e-02,\n",
      "        5.9763e-05, 2.6305e-03, 1.0240e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.0406e-04, 2.6632e-01, 2.9057e-04, 4.0183e-05, 4.6041e-06, 2.7999e-01,\n",
      "        4.0398e-04, 5.9721e-05, 1.5565e-04, 3.0088e-01, 3.1688e-05, 3.5078e-06,\n",
      "        1.4212e-03, 5.7567e-04, 3.2410e-04, 1.0724e-01, 1.7126e-03, 2.5784e-05,\n",
      "        3.3788e-03, 5.7247e-04, 4.2415e-04, 3.0638e-02, 1.1073e-04, 1.6479e-03,\n",
      "        2.0510e-05, 3.4210e-03, 4.6800e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.3999e-03, 1.1516e-03, 2.6505e-03, 7.4620e-03, 2.8698e-02, 3.0027e-03,\n",
      "        4.2165e-03, 7.9867e-02, 1.4636e-04, 2.5981e-04, 5.4798e-05, 1.7587e-03,\n",
      "        4.0454e-03, 2.8498e-01, 3.7261e-02, 6.6406e-04, 6.1865e-03, 1.7548e-04,\n",
      "        5.6378e-03, 5.0618e-01, 8.4138e-03, 9.5579e-05, 1.2845e-02, 1.1428e-03,\n",
      "        6.1849e-04, 3.8140e-05, 5.6145e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.5120e-01, 1.1323e-03, 1.1290e-03, 6.1114e-03, 2.5878e-02, 8.5955e-02,\n",
      "        2.9531e-03, 2.3914e-02, 1.8341e-02, 4.7282e-03, 1.0435e-03, 6.5829e-03,\n",
      "        2.0073e-03, 5.2021e-02, 1.5537e-03, 1.0401e-03, 2.3324e-03, 2.1787e-04,\n",
      "        2.7395e-03, 1.9884e-01, 6.5623e-03, 3.8924e-04, 1.9873e-03, 8.6969e-04,\n",
      "        1.7653e-04, 1.5648e-04, 1.4356e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.3334e-06, 7.6674e-02, 4.1348e-02, 4.2624e-02, 3.1682e-02, 6.6523e-02,\n",
      "        3.0187e-02, 5.2101e-02, 7.7728e-02, 9.5612e-02, 9.6447e-03, 7.8572e-03,\n",
      "        2.2871e-02, 7.2228e-02, 8.2891e-03, 5.9775e-02, 6.6324e-02, 2.2716e-03,\n",
      "        1.6571e-02, 8.8924e-02, 6.2397e-02, 1.4088e-02, 7.8131e-03, 4.1842e-02,\n",
      "        7.5632e-05, 4.4590e-03, 8.2006e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8745e-02, 8.4384e-02, 1.6400e-03, 2.7039e-02, 2.2478e-05, 1.7751e-01,\n",
      "        4.3283e-03, 6.4414e-04, 5.3883e-02, 8.0534e-02, 4.8194e-04, 3.8326e-03,\n",
      "        4.7190e-03, 4.0894e-03, 1.7272e-03, 1.7316e-01, 6.9757e-02, 5.7133e-04,\n",
      "        1.8480e-03, 1.9775e-03, 1.0616e-01, 1.4197e-01, 1.4299e-04, 3.4948e-03,\n",
      "        1.1588e-04, 3.7140e-02, 7.5563e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([0.0008, 0.0029, 0.0171, 0.1322, 0.0425, 0.0168, 0.0651, 0.0754, 0.0011,\n",
      "        0.0006, 0.0004, 0.0193, 0.0320, 0.2023, 0.2039, 0.0105, 0.0149, 0.0018,\n",
      "        0.0115, 0.0585, 0.0413, 0.0012, 0.0431, 0.0014, 0.0023, 0.0003, 0.0007],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.1371e-03, 5.0682e-02, 4.3047e-02, 6.2096e-03, 1.7657e-03, 3.4653e-01,\n",
      "        1.1358e-02, 5.8119e-04, 5.1475e-04, 6.8029e-02, 9.7286e-04, 3.9444e-04,\n",
      "        5.9966e-03, 4.4353e-02, 5.6882e-03, 1.2201e-02, 3.4326e-01, 4.0395e-04,\n",
      "        3.3182e-03, 2.7728e-02, 7.5512e-03, 1.2220e-02, 2.2853e-03, 7.0004e-04,\n",
      "        1.3805e-04, 7.8073e-04, 1.5400e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.3412e-01, 4.2091e-03, 1.4892e-03, 3.1731e-03, 3.5273e-02, 3.0365e-04,\n",
      "        1.6587e-03, 7.8199e-04, 2.7426e-05, 4.5289e-04, 1.0402e-04, 2.2293e-04,\n",
      "        2.5356e-02, 3.0279e-03, 1.3657e-01, 2.1771e-04, 7.7374e-04, 4.3328e-04,\n",
      "        8.1212e-03, 9.6055e-02, 4.5200e-02, 1.7394e-04, 1.0822e-03, 6.3014e-04,\n",
      "        2.7292e-04, 2.3236e-04, 2.8154e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.1741e-06, 1.4257e-01, 2.6221e-02, 4.3479e-02, 2.0911e-02, 3.0787e-02,\n",
      "        3.4252e-02, 1.2226e-02, 5.9353e-02, 7.5811e-02, 2.7802e-03, 3.4456e-03,\n",
      "        1.5949e-02, 4.0575e-02, 3.0156e-02, 7.5921e-02, 3.5378e-02, 1.4462e-03,\n",
      "        1.1709e-02, 4.9880e-02, 1.9620e-01, 1.8670e-02, 4.6042e-03, 6.4438e-02,\n",
      "        4.2992e-05, 3.1388e-03, 4.6951e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8512e-04, 1.3564e-01, 1.8420e-05, 5.8760e-04, 6.7557e-05, 1.6410e-01,\n",
      "        3.5844e-04, 5.2569e-04, 1.2290e-04, 1.8894e-02, 1.3819e-04, 4.1260e-05,\n",
      "        5.2430e-04, 2.0224e-05, 5.4687e-05, 6.7351e-01, 1.7831e-06, 4.1469e-05,\n",
      "        7.3395e-04, 2.2531e-05, 1.2642e-03, 1.6001e-03, 2.3795e-04, 4.3432e-04,\n",
      "        5.3727e-05, 8.0951e-04, 1.0019e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.4995e-02, 8.3775e-02, 3.4356e-03, 1.3162e-01, 1.2937e-02, 3.9075e-02,\n",
      "        2.0688e-02, 8.4908e-03, 9.3864e-05, 1.3062e-02, 3.6522e-03, 3.0981e-03,\n",
      "        1.2482e-02, 5.2243e-02, 2.2494e-02, 2.4243e-03, 1.9553e-02, 6.0208e-03,\n",
      "        8.6731e-03, 8.3292e-02, 1.7777e-01, 6.2788e-03, 9.7067e-02, 1.0238e-01,\n",
      "        2.1819e-02, 1.6058e-03, 9.6699e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.8077e-03, 3.2927e-02, 3.1241e-04, 6.5999e-03, 1.1737e-03, 5.8593e-01,\n",
      "        1.1756e-03, 2.2486e-03, 1.6739e-02, 9.7716e-02, 5.9936e-04, 2.3329e-02,\n",
      "        6.3544e-03, 1.1617e-03, 3.3960e-04, 4.9425e-02, 2.7043e-04, 4.9422e-04,\n",
      "        1.3013e-02, 9.2910e-03, 1.0180e-01, 3.7948e-02, 7.6037e-04, 1.9105e-03,\n",
      "        4.7358e-05, 3.4661e-03, 1.5365e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.0535e-02, 6.5742e-03, 6.7996e-04, 5.7498e-03, 1.3297e-02, 1.2415e-02,\n",
      "        3.1844e-03, 2.7605e-03, 7.2842e-06, 4.4637e-03, 4.4548e-05, 1.2494e-04,\n",
      "        4.8990e-03, 1.6054e-02, 1.0915e-02, 2.2306e-04, 1.2261e-02, 1.2241e-03,\n",
      "        6.1862e-03, 8.4374e-01, 1.7170e-03, 1.5378e-03, 5.7137e-03, 3.8803e-03,\n",
      "        1.3804e-03, 3.6945e-04, 6.3943e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.0060e-02, 6.7094e-04, 2.0660e-04, 5.7751e-03, 6.4432e-05, 3.1401e-03,\n",
      "        2.3757e-03, 5.0946e-05, 3.5832e-04, 3.7558e-03, 6.5481e-06, 1.3190e-04,\n",
      "        1.5039e-04, 3.6197e-03, 6.9663e-04, 1.1623e-03, 1.6022e-02, 2.3146e-05,\n",
      "        3.4547e-04, 8.6384e-01, 5.5916e-02, 5.8435e-04, 1.3285e-04, 6.1372e-04,\n",
      "        2.3162e-06, 2.8182e-04, 9.2149e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.6885e-02, 1.8704e-01, 2.9586e-04, 8.6738e-04, 8.0031e-05, 1.6633e-01,\n",
      "        3.0753e-04, 4.9196e-05, 1.0704e-02, 9.6715e-02, 1.9874e-05, 1.1419e-05,\n",
      "        8.6084e-02, 1.3637e-03, 1.4110e-03, 2.4886e-01, 5.4265e-03, 9.2894e-05,\n",
      "        8.9109e-02, 3.4675e-02, 2.1891e-03, 3.7346e-02, 1.9489e-04, 3.0291e-04,\n",
      "        2.8784e-05, 3.5772e-03, 2.4299e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1711e-03, 2.2627e-01, 3.4483e-04, 4.1119e-04, 1.4934e-04, 4.4163e-01,\n",
      "        1.6554e-03, 1.2529e-05, 2.7098e-05, 1.3347e-01, 1.9939e-05, 1.4122e-05,\n",
      "        1.1305e-03, 4.1499e-04, 2.9189e-04, 1.0178e-01, 2.3428e-04, 1.8465e-05,\n",
      "        3.8606e-04, 1.3426e-03, 2.5245e-03, 2.8724e-02, 3.3353e-04, 5.5220e-04,\n",
      "        7.8727e-06, 5.7064e-02, 2.5627e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.3323e-01, 4.3245e-02, 1.1366e-03, 3.1434e-02, 7.9755e-02, 6.0093e-03,\n",
      "        1.7485e-03, 2.0165e-03, 2.3306e-05, 1.6213e-03, 6.0674e-05, 2.8005e-04,\n",
      "        2.9912e-03, 3.7946e-03, 9.8979e-02, 4.8513e-04, 1.6863e-03, 2.9915e-04,\n",
      "        1.0941e-02, 3.3758e-01, 3.3267e-02, 2.4494e-03, 1.9422e-03, 1.5063e-03,\n",
      "        5.8032e-04, 2.8658e-03, 6.7075e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.6937e-01, 2.4652e-03, 1.8290e-04, 3.5945e-03, 1.5607e-04, 7.7420e-03,\n",
      "        1.6222e-03, 1.0512e-04, 6.6005e-04, 5.0875e-03, 4.6978e-06, 2.5684e-04,\n",
      "        1.5995e-04, 2.7663e-03, 8.5785e-04, 1.2129e-03, 5.0168e-03, 2.0548e-05,\n",
      "        2.6335e-04, 4.0074e-01, 9.5731e-02, 7.6718e-04, 5.7785e-05, 6.3211e-04,\n",
      "        2.6519e-06, 5.0866e-04, 1.3337e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.1668e-01, 1.4618e-02, 9.7619e-05, 4.7024e-04, 2.5705e-05, 1.2930e-01,\n",
      "        4.2663e-04, 5.2997e-05, 3.9534e-04, 1.0260e-01, 1.6185e-06, 2.4403e-05,\n",
      "        1.5642e-03, 3.0249e-03, 4.4323e-04, 1.1946e-02, 1.6482e-03, 4.6675e-06,\n",
      "        1.7607e-04, 7.7811e-03, 3.0767e-03, 2.4730e-03, 1.4452e-05, 1.6446e-04,\n",
      "        8.9910e-07, 2.9868e-03, 1.8312e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.5080e-06, 1.8724e-01, 3.4897e-02, 3.1812e-02, 1.9597e-02, 1.3645e-02,\n",
      "        5.4672e-02, 8.3876e-03, 3.6782e-02, 8.3171e-02, 2.3067e-03, 1.6173e-03,\n",
      "        1.4856e-02, 2.6348e-02, 2.6315e-02, 1.4202e-01, 2.2666e-02, 1.2293e-03,\n",
      "        1.5640e-02, 3.4782e-02, 1.5836e-01, 8.8428e-03, 6.5518e-03, 6.5497e-02,\n",
      "        3.2554e-05, 2.6859e-03, 3.9408e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.2625e-02, 8.6153e-02, 1.5092e-03, 2.6851e-02, 2.6986e-05, 1.2027e-01,\n",
      "        8.5909e-03, 4.7008e-04, 5.8037e-02, 6.0733e-02, 3.8321e-04, 2.7754e-03,\n",
      "        4.6456e-03, 4.5120e-03, 3.5738e-03, 2.3040e-01, 6.4088e-02, 5.4460e-04,\n",
      "        2.0005e-03, 1.5744e-03, 1.3785e-01, 1.1951e-01, 2.2094e-04, 3.8604e-03,\n",
      "        1.1657e-04, 2.8614e-02, 7.1882e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.5198e-01, 3.9335e-02, 1.2601e-03, 1.7876e-02, 3.4929e-04, 3.8703e-02,\n",
      "        2.5301e-03, 5.1447e-04, 9.5436e-03, 2.6220e-01, 2.3617e-04, 1.7765e-03,\n",
      "        1.7731e-03, 3.3131e-02, 4.1081e-04, 4.5614e-02, 1.8993e-02, 2.2872e-04,\n",
      "        6.0740e-04, 7.9253e-03, 3.4566e-02, 7.1969e-02, 3.0750e-04, 2.5134e-03,\n",
      "        2.9116e-05, 5.5586e-02, 4.6061e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.7660e-03, 6.6618e-03, 3.0488e-02, 3.1255e-02, 1.1605e-02, 1.2805e-02,\n",
      "        7.1306e-03, 1.8064e-02, 6.5606e-04, 1.3057e-02, 5.1885e-04, 3.1674e-03,\n",
      "        1.2636e-01, 1.0070e-01, 1.5726e-02, 1.3972e-02, 7.9744e-02, 1.1060e-03,\n",
      "        6.7611e-02, 5.6056e-03, 2.2425e-02, 3.9167e-01, 1.4235e-02, 1.5414e-02,\n",
      "        1.0456e-03, 1.9084e-03, 3.0652e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.5910e-03, 5.8078e-02, 1.9999e-03, 6.8024e-04, 1.5360e-04, 7.7719e-01,\n",
      "        3.7301e-04, 1.6679e-04, 1.8620e-04, 8.9416e-02, 1.3559e-04, 2.5646e-05,\n",
      "        2.0207e-03, 7.6416e-03, 7.0882e-04, 2.1754e-02, 1.1188e-02, 7.6562e-05,\n",
      "        8.5554e-04, 2.8771e-03, 8.0761e-04, 1.0481e-02, 3.1476e-04, 2.5947e-04,\n",
      "        3.6892e-05, 3.8992e-03, 8.1164e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0728e-03, 4.5271e-04, 1.3413e-02, 1.6949e-02, 2.5940e-02, 1.8614e-04,\n",
      "        1.5823e-03, 1.4616e-02, 1.4619e-04, 1.9342e-02, 2.1900e-04, 2.1958e-03,\n",
      "        6.4043e-02, 2.1061e-03, 3.9902e-01, 1.1916e-04, 1.5206e-03, 5.0144e-05,\n",
      "        3.3451e-02, 4.1184e-03, 3.7116e-01, 1.2883e-03, 1.9762e-03, 2.7697e-04,\n",
      "        5.9943e-05, 2.4293e-02, 4.0248e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.3100e-02, 1.1483e-02, 1.1636e-04, 6.4180e-04, 1.0572e-04, 3.0348e-01,\n",
      "        2.4393e-04, 1.1358e-04, 1.4368e-02, 5.8398e-01, 1.5342e-05, 5.7168e-04,\n",
      "        3.8171e-03, 2.9084e-04, 1.1539e-03, 7.6055e-03, 8.4168e-05, 4.5218e-05,\n",
      "        1.9015e-03, 1.0581e-02, 7.8410e-03, 1.5957e-02, 3.7772e-05, 1.1107e-04,\n",
      "        2.7588e-06, 1.2330e-02, 2.1580e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4321e-03, 3.2382e-02, 7.9342e-03, 6.1753e-02, 6.9793e-03, 3.5709e-02,\n",
      "        7.9955e-03, 2.2254e-03, 3.0480e-04, 3.3132e-03, 2.5575e-05, 5.3555e-04,\n",
      "        1.0057e-02, 6.6125e-03, 4.3314e-02, 6.8320e-01, 8.4262e-04, 2.0170e-04,\n",
      "        3.9952e-03, 1.9249e-02, 3.1902e-02, 1.1327e-03, 3.4829e-02, 4.8421e-04,\n",
      "        1.3725e-04, 7.0282e-04, 1.7484e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.1865e-03, 2.6276e-02, 2.1269e-04, 1.6391e-04, 7.7717e-05, 3.5977e-02,\n",
      "        3.8497e-04, 1.8733e-04, 2.8009e-03, 1.4235e-01, 9.5226e-06, 3.9821e-05,\n",
      "        1.5081e-03, 2.8336e-04, 6.2179e-04, 3.3072e-03, 1.7969e-04, 1.1408e-05,\n",
      "        8.3045e-04, 8.1955e-03, 1.4013e-03, 1.9489e-02, 6.6178e-05, 9.3654e-05,\n",
      "        2.2204e-06, 7.4632e-01, 2.7419e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.8850e-01, 5.3951e-05, 4.3451e-05, 1.6308e-04, 9.6932e-05, 1.8238e-04,\n",
      "        1.6014e-04, 1.0574e-05, 2.6527e-06, 3.6150e-04, 5.0043e-07, 6.4153e-06,\n",
      "        3.8000e-04, 1.8435e-03, 2.6335e-04, 4.3012e-04, 1.0899e-04, 2.0253e-06,\n",
      "        1.3412e-04, 4.3955e-03, 2.4689e-03, 2.1579e-04, 5.9105e-05, 2.6925e-05,\n",
      "        1.1376e-06, 8.2974e-05, 1.9109e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8262e-06, 2.0083e-01, 2.6798e-02, 3.0061e-02, 2.2332e-02, 2.0967e-02,\n",
      "        2.7689e-02, 8.2190e-03, 4.6611e-02, 9.6063e-02, 3.7815e-03, 2.2341e-03,\n",
      "        1.5588e-02, 3.7160e-02, 2.3512e-02, 1.2337e-01, 2.1150e-02, 1.5224e-03,\n",
      "        1.8257e-02, 4.5026e-02, 1.4782e-01, 1.0993e-02, 5.9590e-03, 6.1852e-02,\n",
      "        5.3334e-05, 2.0832e-03, 6.3665e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "ception cruel and hard without really be <------ | ------> igfously hir sime necespless ssomatity o\n",
      "Epoch 3   Time 62.978    Train Loss: 1.490\n",
      "Softmaxed: tensor([2.1452e-03, 1.7275e-05, 4.5065e-04, 3.0178e-04, 4.6733e-04, 1.9361e-04,\n",
      "        1.2729e-04, 4.5678e-04, 8.9926e-05, 9.3955e-04, 2.7270e-05, 3.8066e-03,\n",
      "        1.5161e-03, 3.4000e-03, 9.5806e-02, 1.7753e-05, 4.7603e-04, 1.3164e-06,\n",
      "        1.6674e-03, 1.1131e-02, 8.7241e-01, 3.4872e-04, 5.4301e-04, 4.9997e-04,\n",
      "        1.1482e-05, 3.0381e-03, 1.1444e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9010e-01, 2.7002e-05, 2.3340e-06, 1.6547e-05, 1.1681e-05, 2.7864e-03,\n",
      "        1.2520e-05, 7.5043e-06, 2.8582e-03, 7.4992e-04, 4.8880e-07, 1.8334e-04,\n",
      "        9.9433e-05, 4.5301e-05, 4.7355e-05, 4.2454e-05, 1.0492e-05, 1.2382e-06,\n",
      "        3.9110e-05, 1.5175e-03, 7.0699e-04, 6.2363e-04, 2.1171e-06, 2.7010e-05,\n",
      "        6.5851e-08, 7.9302e-05, 4.5078e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8526e-06, 7.7461e-02, 3.2030e-02, 2.1888e-02, 2.9269e-02, 3.7341e-02,\n",
      "        2.4062e-02, 6.5097e-03, 4.2681e-02, 1.6333e-01, 2.4412e-03, 3.1034e-03,\n",
      "        1.8773e-02, 4.0089e-02, 3.0113e-02, 4.1851e-02, 1.5427e-02, 4.0391e-04,\n",
      "        3.0940e-02, 5.1593e-02, 2.3942e-01, 1.1912e-02, 6.1424e-03, 5.6386e-02,\n",
      "        1.7149e-05, 1.6766e-02, 3.6971e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.7046e-04, 9.6734e-02, 9.1129e-06, 3.9643e-04, 2.8700e-05, 2.2082e-01,\n",
      "        1.1760e-04, 1.8632e-04, 1.0725e-04, 1.2177e-02, 7.8925e-05, 3.0121e-05,\n",
      "        4.0708e-04, 1.1539e-05, 1.9003e-05, 6.6473e-01, 6.3646e-07, 2.4259e-05,\n",
      "        5.5312e-04, 9.3913e-06, 7.6104e-04, 1.3917e-03, 9.3306e-05, 3.6348e-04,\n",
      "        3.0212e-05, 7.4397e-04, 4.4879e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2196e-01, 1.7426e-04, 2.4614e-03, 4.6078e-03, 6.1516e-04, 1.2800e-03,\n",
      "        1.6293e-03, 2.3259e-03, 2.1132e-04, 2.2088e-03, 1.4486e-04, 1.0333e-03,\n",
      "        3.4274e-03, 2.2357e-02, 4.1232e-03, 2.0797e-03, 1.0411e-03, 5.2291e-05,\n",
      "        1.7354e-02, 2.7141e-03, 5.6272e-01, 4.9076e-03, 2.0042e-03, 1.3779e-01,\n",
      "        3.0439e-04, 3.3588e-04, 1.3552e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.2824e-01, 1.0013e-03, 2.3502e-05, 2.1859e-05, 7.2881e-05, 7.6535e-03,\n",
      "        4.5862e-05, 1.0153e-05, 3.1592e-02, 4.1032e-03, 5.4528e-06, 1.4087e-04,\n",
      "        6.2592e-03, 1.7429e-03, 1.6819e-04, 1.8359e-03, 9.4503e-05, 1.6482e-05,\n",
      "        1.1705e-03, 1.3355e-02, 7.6254e-04, 6.9366e-04, 6.2431e-05, 6.0454e-04,\n",
      "        1.5280e-06, 3.1321e-04, 4.6383e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([2.2648e-06, 1.4610e-01, 7.7230e-02, 2.3257e-02, 5.3637e-02, 2.6600e-02,\n",
      "        3.7416e-02, 1.9969e-02, 3.5727e-02, 7.8760e-02, 2.9277e-03, 4.6919e-03,\n",
      "        2.9907e-02, 4.7632e-02, 2.7432e-02, 5.7205e-02, 3.1914e-02, 1.2757e-03,\n",
      "        3.3980e-02, 4.7532e-02, 1.5730e-01, 1.4110e-02, 7.3664e-03, 3.3218e-02,\n",
      "        4.3293e-05, 4.6962e-03, 6.2989e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.6210e-05, 9.3165e-02, 1.0029e-05, 2.5336e-04, 2.1996e-05, 1.7504e-01,\n",
      "        1.1268e-04, 1.8457e-04, 5.7419e-05, 9.5824e-03, 4.6533e-05, 1.3897e-05,\n",
      "        3.0497e-04, 8.1321e-06, 2.2171e-05, 7.1825e-01, 5.9986e-07, 2.0570e-05,\n",
      "        4.4436e-04, 4.1589e-06, 3.7132e-04, 1.3328e-03, 7.4679e-05, 2.2703e-04,\n",
      "        2.4519e-05, 3.5269e-04, 3.8203e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.8098e-03, 3.0777e-04, 6.8845e-03, 5.6438e-02, 1.2811e-03, 6.1999e-04,\n",
      "        1.9987e-03, 2.4975e-03, 3.2252e-04, 2.5081e-02, 4.1218e-04, 3.6245e-03,\n",
      "        6.2070e-03, 8.0873e-02, 1.4661e-02, 6.7839e-05, 1.8056e-02, 4.3906e-04,\n",
      "        3.0497e-02, 4.7713e-02, 6.4910e-01, 1.1848e-02, 5.5756e-03, 6.0799e-03,\n",
      "        2.1141e-04, 1.8577e-02, 8.1588e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4255e-02, 4.8615e-03, 1.6816e-04, 2.5979e-04, 2.2161e-05, 7.3541e-02,\n",
      "        1.9482e-04, 6.9561e-05, 2.8024e-02, 8.7376e-02, 2.1791e-05, 4.4386e-04,\n",
      "        1.5100e-03, 8.4096e-04, 2.8738e-04, 3.6152e-03, 1.2867e-04, 7.5733e-05,\n",
      "        3.7734e-03, 7.8244e-04, 2.0600e-03, 7.7455e-01, 1.8885e-05, 3.6754e-04,\n",
      "        3.0104e-06, 2.7417e-03, 1.0905e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4046e-01, 1.1998e-02, 1.9539e-03, 6.3974e-03, 7.5103e-02, 1.6471e-02,\n",
      "        7.7383e-03, 5.0306e-04, 2.0096e-04, 7.7724e-03, 1.3609e-04, 6.6088e-04,\n",
      "        2.0609e-01, 2.4663e-02, 2.4455e-02, 2.8481e-03, 2.5757e-03, 1.7089e-03,\n",
      "        2.7513e-01, 6.5083e-02, 9.7061e-03, 3.4150e-03, 8.8317e-03, 2.3344e-03,\n",
      "        8.9293e-04, 2.8389e-03, 3.9230e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.5495e-03, 5.4706e-03, 2.7883e-03, 9.2596e-04, 7.9695e-03, 2.3413e-02,\n",
      "        8.8943e-02, 9.2315e-05, 5.6836e-05, 4.8624e-02, 3.7405e-05, 4.3121e-04,\n",
      "        1.7364e-01, 1.0452e-03, 1.8727e-03, 7.3251e-02, 1.4734e-03, 1.2516e-04,\n",
      "        2.2173e-03, 4.6040e-02, 3.5242e-02, 2.3448e-02, 8.4411e-02, 6.9406e-03,\n",
      "        1.2622e-04, 3.6449e-01, 3.7502e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.6546e-02, 9.5722e-03, 1.2090e-04, 1.0159e-04, 1.8238e-04, 4.6017e-01,\n",
      "        2.4487e-03, 4.0879e-05, 1.9777e-05, 6.7465e-02, 1.7700e-05, 2.0788e-05,\n",
      "        2.2346e-03, 2.7547e-04, 1.0940e-04, 6.1947e-02, 3.9098e-05, 1.6064e-05,\n",
      "        6.7476e-05, 8.5023e-03, 6.1071e-04, 5.7907e-03, 1.0608e-03, 1.4474e-03,\n",
      "        1.8555e-05, 3.5112e-01, 5.3259e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.9241e-01, 2.1492e-04, 2.8464e-05, 4.8213e-04, 1.2127e-05, 4.8220e-04,\n",
      "        1.3259e-04, 3.7491e-05, 4.4493e-06, 4.7960e-04, 1.3802e-06, 8.9352e-06,\n",
      "        7.3617e-05, 1.0284e-03, 2.0115e-04, 3.2711e-04, 7.6152e-05, 2.2497e-06,\n",
      "        3.2638e-05, 2.0645e-03, 1.4363e-03, 2.1272e-04, 2.4156e-05, 1.0042e-04,\n",
      "        3.2972e-06, 1.1643e-04, 8.1355e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.6818e-06, 1.6638e-01, 4.5624e-02, 1.8183e-02, 4.4070e-02, 1.9643e-02,\n",
      "        2.0517e-02, 1.9959e-02, 2.3130e-02, 8.5778e-02, 1.7824e-03, 2.9030e-03,\n",
      "        2.1797e-02, 5.1137e-02, 3.5772e-02, 4.7987e-02, 3.1516e-02, 1.3135e-03,\n",
      "        3.3921e-02, 6.8924e-02, 1.9302e-01, 1.1562e-02, 5.6115e-03, 4.6313e-02,\n",
      "        4.1462e-05, 3.0488e-03, 6.4877e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.8474e-01, 3.4526e-04, 1.3669e-02, 3.5085e-02, 7.0897e-03, 2.1528e-04,\n",
      "        8.6740e-03, 1.4008e-02, 8.9425e-04, 2.4775e-03, 4.1704e-05, 5.5453e-04,\n",
      "        6.5118e-02, 1.0849e-02, 4.3014e-01, 3.6454e-04, 1.4854e-02, 3.2841e-04,\n",
      "        3.5546e-02, 1.2773e-01, 3.6223e-02, 3.7715e-03, 1.5659e-03, 2.8402e-03,\n",
      "        3.5653e-04, 2.4174e-03, 9.0360e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.7244e-03, 3.0980e-02, 5.9802e-03, 4.8287e-03, 1.5439e-02, 6.4232e-01,\n",
      "        2.8539e-03, 1.5549e-03, 1.0736e-03, 6.0090e-02, 3.0781e-04, 5.6714e-03,\n",
      "        8.1712e-03, 2.0618e-02, 5.9074e-03, 6.1501e-02, 3.3330e-03, 7.4583e-04,\n",
      "        8.8744e-03, 6.4190e-03, 9.8580e-02, 1.5000e-03, 1.8128e-03, 3.6476e-03,\n",
      "        1.1134e-04, 5.7483e-03, 2.0846e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9171e-01, 4.2319e-04, 1.5409e-05, 2.3051e-05, 2.2929e-04, 1.4243e-04,\n",
      "        1.8871e-04, 4.6462e-05, 3.2429e-06, 1.6136e-04, 3.4051e-06, 1.1781e-05,\n",
      "        3.2398e-04, 2.0059e-04, 1.8130e-04, 1.1708e-04, 3.2217e-05, 3.7260e-05,\n",
      "        1.6833e-05, 5.4813e-03, 1.4320e-04, 3.1764e-05, 1.3883e-04, 2.7499e-04,\n",
      "        9.3775e-06, 5.2054e-05, 1.2685e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([4.1582e-06, 1.2060e-01, 2.8560e-02, 2.5079e-02, 4.5529e-02, 2.4415e-02,\n",
      "        2.3818e-02, 9.4761e-03, 2.0215e-02, 7.9511e-02, 1.1241e-03, 1.7680e-03,\n",
      "        1.7150e-02, 6.6691e-02, 4.1668e-02, 5.0478e-02, 3.2215e-02, 1.2682e-03,\n",
      "        3.9982e-02, 1.4546e-01, 1.5158e-01, 1.0268e-02, 8.5201e-03, 5.1108e-02,\n",
      "        4.7268e-05, 3.4356e-03, 3.3977e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.6017e-02, 1.1232e-01, 1.1752e-03, 3.5394e-02, 1.4751e-05, 1.4618e-01,\n",
      "        5.2320e-03, 5.2449e-04, 5.0107e-02, 7.3939e-02, 2.3229e-04, 3.5742e-03,\n",
      "        3.8160e-03, 4.9127e-03, 2.5137e-03, 2.0981e-01, 7.7791e-02, 8.0492e-04,\n",
      "        2.0302e-03, 1.9410e-03, 1.1559e-01, 9.5340e-02, 1.4522e-04, 4.1243e-03,\n",
      "        9.5680e-05, 2.6307e-02, 6.2540e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1621e-02, 2.3191e-02, 2.5121e-03, 9.6154e-02, 4.2942e-03, 1.6285e-01,\n",
      "        1.5726e-02, 5.6497e-03, 2.5368e-04, 5.0739e-03, 2.8501e-04, 1.1240e-03,\n",
      "        1.6339e-01, 2.9248e-02, 3.1219e-01, 4.6624e-03, 7.7361e-03, 1.7259e-02,\n",
      "        6.6144e-02, 6.4186e-03, 2.4580e-02, 3.2549e-03, 2.2096e-02, 3.1631e-03,\n",
      "        9.5890e-03, 1.4594e-03, 7.0818e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.9158e-02, 2.9595e-03, 2.8845e-04, 3.9552e-02, 2.3236e-02, 8.8759e-03,\n",
      "        2.2530e-02, 6.2389e-03, 8.2888e-04, 4.8652e-03, 7.6623e-04, 2.3062e-02,\n",
      "        1.3475e-02, 4.0641e-04, 8.7166e-04, 6.8213e-03, 4.2605e-04, 1.0709e-03,\n",
      "        3.9677e-04, 5.5874e-01, 2.2025e-01, 1.5782e-02, 6.9560e-03, 1.5300e-03,\n",
      "        1.7179e-04, 5.9336e-04, 1.4352e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3338e-02, 2.8231e-02, 3.0770e-04, 5.7916e-03, 1.5819e-05, 6.0761e-01,\n",
      "        8.4160e-04, 7.1166e-05, 1.4473e-03, 2.2170e-01, 1.4868e-05, 1.5078e-04,\n",
      "        4.7439e-03, 6.1263e-03, 1.9825e-04, 1.9160e-02, 4.2319e-03, 8.2648e-05,\n",
      "        2.2774e-04, 5.6952e-03, 4.0521e-02, 1.6040e-02, 1.8359e-05, 6.2279e-04,\n",
      "        5.0782e-06, 2.7079e-03, 9.5687e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.6767e-03, 2.9570e-02, 1.2960e-01, 4.2354e-02, 7.3133e-02, 9.5433e-03,\n",
      "        5.0988e-02, 1.9207e-02, 7.1862e-04, 1.4170e-03, 3.6958e-05, 5.8157e-04,\n",
      "        5.7126e-03, 1.4069e-01, 9.2476e-02, 1.8678e-01, 6.9315e-03, 9.3824e-04,\n",
      "        1.2083e-02, 4.2420e-02, 6.1480e-02, 1.0539e-03, 7.5591e-02, 5.2920e-04,\n",
      "        8.4924e-04, 2.7196e-04, 8.3534e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.7807e-02, 1.6353e-01, 1.8841e-03, 8.4889e-05, 1.3579e-04, 6.4876e-01,\n",
      "        5.3995e-04, 1.0030e-04, 5.6002e-05, 9.2898e-02, 1.8848e-05, 4.7311e-06,\n",
      "        5.6797e-04, 5.8895e-03, 5.9937e-03, 2.2181e-02, 9.6132e-03, 9.3748e-06,\n",
      "        1.3535e-03, 9.0692e-03, 3.0213e-04, 3.5627e-03, 1.4404e-04, 8.5551e-05,\n",
      "        2.0934e-05, 5.3531e-03, 2.6273e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.2399e-04, 5.9887e-03, 2.2349e-03, 1.0767e-02, 2.6099e-02, 9.3193e-03,\n",
      "        4.4226e-03, 6.0576e-03, 8.3027e-05, 1.3010e-04, 1.6810e-05, 2.7915e-04,\n",
      "        6.5876e-03, 1.3461e-03, 7.2727e-01, 1.0216e-02, 1.8862e-04, 2.7450e-05,\n",
      "        2.9256e-03, 6.2892e-02, 1.1246e-01, 1.5796e-04, 8.7389e-03, 1.3666e-04,\n",
      "        1.0631e-04, 1.0531e-05, 7.1730e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.3389e-02, 4.0185e-02, 2.4938e-04, 2.2737e-02, 7.2972e-02, 1.6153e-01,\n",
      "        2.3199e-03, 2.8219e-01, 3.1177e-04, 2.3390e-02, 2.1525e-04, 3.6952e-03,\n",
      "        4.8620e-03, 4.6557e-04, 8.3606e-03, 3.9667e-03, 2.6156e-05, 6.7542e-05,\n",
      "        3.8741e-04, 1.2141e-01, 1.9038e-01, 1.6848e-03, 7.0421e-04, 2.8917e-04,\n",
      "        6.9120e-05, 4.0243e-03, 1.1746e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.9929e-01, 8.9818e-04, 3.3360e-05, 6.8140e-04, 2.8403e-05, 5.3113e-03,\n",
      "        8.8132e-04, 7.6484e-06, 1.1282e-04, 2.5605e-03, 1.9713e-06, 2.3128e-05,\n",
      "        2.0421e-03, 7.3881e-04, 1.0812e-04, 1.4916e-03, 1.9463e-04, 2.8687e-06,\n",
      "        2.4648e-05, 1.0079e-02, 7.4309e-02, 2.5258e-04, 8.3884e-06, 2.1911e-04,\n",
      "        3.2518e-07, 6.8943e-04, 6.5434e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([3.1963e-06, 2.6293e-01, 3.1418e-02, 1.6511e-02, 1.1401e-02, 8.2046e-03,\n",
      "        3.0376e-02, 4.2587e-03, 2.1359e-02, 8.0770e-02, 1.4533e-03, 5.0137e-04,\n",
      "        2.0632e-02, 2.4861e-02, 1.2682e-02, 2.0989e-01, 1.3731e-02, 1.7124e-03,\n",
      "        2.0737e-02, 3.5120e-02, 1.1436e-01, 8.7204e-03, 3.6318e-03, 5.9768e-02,\n",
      "        3.3464e-05, 4.8807e-03, 5.2957e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.4590e-04, 7.7008e-05, 9.2086e-03, 1.6674e-03, 9.2411e-04, 1.2719e-04,\n",
      "        8.1725e-01, 3.6863e-04, 1.7299e-04, 1.0103e-04, 8.6212e-05, 9.9593e-05,\n",
      "        1.9747e-03, 6.5188e-04, 7.7521e-02, 5.4380e-04, 1.1190e-02, 9.4897e-05,\n",
      "        3.9000e-02, 1.0743e-04, 8.8586e-03, 1.5080e-02, 6.2546e-03, 8.3217e-03,\n",
      "        1.4164e-04, 2.2788e-05, 1.0393e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4338e-01, 1.8130e-01, 1.9013e-03, 4.7230e-03, 1.1027e-01, 1.8900e-01,\n",
      "        1.1699e-03, 4.2454e-03, 1.9270e-02, 3.4760e-02, 5.0645e-04, 4.1295e-04,\n",
      "        1.5155e-02, 5.5600e-03, 1.5907e-01, 6.2014e-03, 1.7981e-03, 2.1726e-04,\n",
      "        5.4098e-02, 4.4642e-02, 1.4046e-02, 2.5985e-03, 1.6113e-03, 1.9969e-03,\n",
      "        1.7753e-04, 1.8364e-03, 5.2358e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.5617e-01, 9.0837e-03, 1.7995e-04, 3.7315e-03, 6.3402e-05, 4.6204e-02,\n",
      "        1.0465e-03, 3.2856e-05, 5.1313e-03, 2.7797e-02, 2.1664e-05, 8.3696e-04,\n",
      "        5.1852e-04, 5.2911e-03, 2.1315e-04, 6.4100e-03, 3.5332e-03, 2.5237e-05,\n",
      "        5.7743e-04, 1.0628e-03, 2.2782e-01, 2.6862e-03, 2.4559e-05, 4.8962e-04,\n",
      "        4.5424e-06, 1.0153e-03, 3.1789e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.1288e-02, 1.3727e-01, 3.0582e-05, 5.0567e-05, 1.8405e-05, 4.6455e-01,\n",
      "        1.3449e-04, 1.8959e-05, 2.5528e-03, 2.0854e-01, 5.1939e-06, 1.9785e-05,\n",
      "        3.1731e-02, 2.6684e-03, 2.2897e-04, 2.8977e-02, 2.4345e-04, 1.3442e-05,\n",
      "        2.3727e-02, 8.5622e-03, 1.5448e-04, 1.5710e-02, 1.3820e-05, 3.1020e-04,\n",
      "        4.8010e-06, 3.1748e-03, 3.7396e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.5353e-01, 5.9105e-04, 7.1537e-05, 1.5513e-03, 6.2451e-06, 1.2416e-02,\n",
      "        3.3367e-04, 1.6685e-05, 6.0220e-04, 1.0297e-02, 1.4879e-06, 2.7688e-05,\n",
      "        3.7506e-04, 1.2042e-03, 1.6062e-04, 2.2175e-03, 3.3729e-04, 2.5932e-06,\n",
      "        1.5929e-04, 8.8372e-04, 1.4327e-02, 3.6092e-04, 1.3913e-06, 4.4662e-05,\n",
      "        2.0594e-07, 4.7867e-04, 1.5443e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.6837e-06, 2.0160e-01, 3.5587e-02, 3.2777e-02, 3.0603e-02, 1.2230e-02,\n",
      "        2.7751e-02, 9.6432e-03, 2.3463e-02, 7.8101e-02, 2.2225e-03, 1.4304e-03,\n",
      "        2.4748e-02, 4.3417e-02, 2.6165e-02, 1.3252e-01, 2.2056e-02, 1.9600e-03,\n",
      "        2.7143e-02, 4.2284e-02, 1.6657e-01, 1.2308e-02, 4.9948e-03, 3.8410e-02,\n",
      "        3.8656e-05, 1.9388e-03, 3.1847e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2621e-05, 1.4455e-01, 1.6149e-05, 1.1928e-04, 9.8305e-06, 5.5283e-02,\n",
      "        2.4412e-04, 8.8493e-06, 5.0396e-02, 2.2774e-02, 1.5250e-05, 3.8131e-04,\n",
      "        2.7858e-02, 1.0171e-04, 2.3721e-04, 6.2388e-01, 1.0272e-04, 6.1420e-04,\n",
      "        4.0682e-02, 1.4349e-04, 2.4112e-03, 2.8287e-02, 5.7301e-05, 1.8219e-04,\n",
      "        2.5792e-05, 1.6014e-03, 3.3318e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.0600e-03, 3.0104e-04, 4.4442e-03, 1.3494e-02, 2.2080e-03, 2.3937e-04,\n",
      "        6.3951e-03, 9.9430e-04, 2.0496e-04, 6.3505e-03, 1.2406e-04, 4.3273e-03,\n",
      "        1.8058e-01, 1.6085e-02, 3.1946e-01, 1.1800e-04, 6.4400e-02, 4.4526e-04,\n",
      "        1.0856e-01, 1.2898e-01, 2.2415e-02, 1.0215e-01, 6.4809e-03, 2.4134e-03,\n",
      "        6.9039e-04, 1.6767e-03, 3.9736e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.8732e-01, 4.4264e-03, 4.8203e-04, 3.8903e-02, 2.1715e-02, 1.3402e-02,\n",
      "        1.5677e-02, 7.2407e-03, 9.0519e-04, 3.7392e-02, 9.8577e-04, 2.8757e-03,\n",
      "        3.3983e-03, 1.0588e-03, 7.4496e-03, 4.4361e-03, 3.8005e-04, 3.6014e-04,\n",
      "        4.2190e-04, 1.0441e-01, 3.3883e-02, 6.2142e-03, 7.4789e-04, 2.4513e-03,\n",
      "        2.4500e-04, 3.2045e-03, 1.6424e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4659e-06, 1.4606e-01, 4.3267e-02, 3.2028e-02, 1.4109e-02, 1.8718e-02,\n",
      "        2.8964e-02, 8.9851e-03, 2.2203e-02, 8.1142e-02, 2.2351e-03, 1.0978e-03,\n",
      "        1.5006e-02, 3.9535e-02, 2.6320e-02, 1.2904e-01, 3.0187e-02, 1.5546e-03,\n",
      "        3.5619e-02, 7.4271e-02, 1.6728e-01, 1.4623e-02, 5.9312e-03, 5.6660e-02,\n",
      "        4.0733e-05, 5.0626e-03, 6.1680e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.3247e-06, 1.7990e-01, 3.8476e-05, 7.1050e-06, 6.2911e-06, 1.4462e-01,\n",
      "        1.0008e-03, 9.5494e-05, 1.3792e-04, 3.5387e-01, 1.6153e-05, 8.3618e-05,\n",
      "        8.6034e-04, 1.4363e-05, 1.5143e-05, 2.9364e-01, 2.5734e-05, 3.3186e-05,\n",
      "        4.3164e-04, 5.7044e-05, 2.7714e-05, 1.7451e-02, 9.5161e-05, 4.0391e-04,\n",
      "        1.3227e-05, 7.1328e-03, 1.0854e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "cause of this very faith is stronger tha <------ | ------> t not natelly are sensimins ogsts can li\n",
      "Epoch 4   Time 62.499    Train Loss: 1.440\n",
      "Softmaxed: tensor([8.4329e-04, 8.4102e-04, 1.3438e-03, 5.3051e-04, 2.4293e-03, 1.5434e-03,\n",
      "        2.6312e-05, 4.3921e-04, 9.0189e-05, 3.8997e-03, 1.1896e-04, 1.3853e-04,\n",
      "        9.5923e-01, 2.2276e-04, 1.5261e-03, 2.9464e-03, 3.0958e-05, 9.0375e-05,\n",
      "        5.6121e-03, 3.0025e-03, 1.1279e-02, 1.3044e-03, 1.2477e-04, 5.4203e-05,\n",
      "        2.3515e-05, 2.2174e-03, 9.4852e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0449e-02, 2.5971e-03, 6.1004e-05, 4.4012e-05, 2.0178e-04, 6.8385e-01,\n",
      "        1.3815e-04, 1.2495e-05, 1.1097e-05, 4.8353e-02, 5.2463e-06, 1.9569e-05,\n",
      "        2.6806e-02, 1.3966e-04, 9.5172e-05, 9.1544e-03, 2.4740e-05, 1.0202e-05,\n",
      "        6.1793e-05, 2.3029e-03, 6.1091e-04, 1.0398e-02, 2.7532e-04, 1.7248e-04,\n",
      "        7.2128e-06, 2.0418e-01, 1.8267e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5999e-06, 8.4425e-02, 2.5062e-02, 3.3296e-02, 3.8010e-02, 6.8165e-02,\n",
      "        2.0475e-02, 1.9020e-02, 2.6627e-02, 1.1485e-01, 4.2875e-03, 3.5034e-03,\n",
      "        1.7193e-02, 6.4460e-02, 1.3353e-02, 2.2782e-02, 4.2899e-02, 1.0452e-03,\n",
      "        5.0743e-03, 8.6199e-02, 2.1428e-01, 1.8814e-02, 4.4470e-03, 6.4049e-02,\n",
      "        4.2380e-05, 7.5480e-03, 9.1288e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1693e-02, 7.3462e-02, 9.0140e-04, 4.2011e-02, 9.7881e-06, 1.7818e-01,\n",
      "        3.2739e-03, 4.7017e-04, 5.0452e-02, 7.1921e-02, 2.3585e-04, 5.3047e-03,\n",
      "        3.5920e-03, 4.3109e-03, 1.3709e-03, 2.0257e-01, 9.1487e-02, 8.2465e-04,\n",
      "        1.1295e-03, 1.3057e-03, 1.1081e-01, 1.1619e-01, 1.1030e-04, 5.5543e-03,\n",
      "        6.1216e-05, 2.2716e-02, 4.9072e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.0879e-03, 2.0752e-02, 2.1051e-03, 1.0734e-01, 2.9617e-03, 2.1210e-01,\n",
      "        1.2926e-02, 3.2580e-03, 1.9903e-04, 5.2143e-03, 2.3409e-04, 3.9451e-04,\n",
      "        1.4634e-01, 2.9976e-02, 2.3756e-01, 5.0279e-03, 7.5596e-03, 1.8205e-02,\n",
      "        1.0176e-01, 5.5913e-03, 1.6768e-02, 2.8153e-03, 3.7228e-02, 2.9415e-03,\n",
      "        1.3264e-02, 2.3252e-03, 6.7971e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4147e-05, 1.5512e-04, 3.6920e-04, 3.2945e-03, 9.6194e-05, 7.1436e-05,\n",
      "        5.3632e-04, 2.2540e-05, 1.9854e-06, 1.1251e-03, 1.9634e-05, 8.8414e-05,\n",
      "        4.8825e-04, 4.0360e-04, 1.4622e-05, 1.5310e-04, 5.9586e-03, 5.2960e-06,\n",
      "        6.7276e-05, 8.5119e-05, 4.6345e-04, 9.8606e-01, 2.9657e-04, 1.9718e-04,\n",
      "        3.6274e-06, 6.6833e-06, 1.0401e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.0971e-05, 1.5676e-01, 8.6392e-04, 8.4084e-03, 1.3781e-04, 5.5550e-01,\n",
      "        2.3301e-04, 6.3163e-04, 1.5430e-04, 2.2241e-01, 2.6409e-05, 2.7188e-05,\n",
      "        1.2130e-02, 3.2515e-03, 5.8626e-03, 7.7385e-03, 1.8287e-03, 5.7232e-05,\n",
      "        3.5760e-03, 9.8110e-03, 5.7839e-03, 3.0144e-04, 6.3646e-05, 1.0490e-04,\n",
      "        7.7745e-05, 4.1071e-03, 9.9848e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.7316e-02, 2.5527e-03, 2.3577e-03, 5.7370e-03, 2.9288e-02, 9.0231e-04,\n",
      "        2.0203e-03, 5.6242e-04, 1.7139e-05, 1.0195e-03, 2.6099e-05, 5.0183e-06,\n",
      "        7.9645e-03, 9.2622e-03, 6.3638e-01, 2.5574e-04, 6.0608e-04, 2.7888e-04,\n",
      "        1.7209e-01, 1.0609e-01, 3.1054e-03, 4.3478e-04, 4.0615e-04, 6.7350e-04,\n",
      "        5.5116e-04, 5.5127e-05, 5.1293e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.2891e-02, 7.9496e-04, 5.9110e-04, 4.0662e-01, 6.9933e-02, 5.9771e-03,\n",
      "        5.6211e-03, 2.4603e-03, 9.8710e-05, 2.5768e-03, 2.4449e-04, 4.2538e-05,\n",
      "        1.3558e-03, 2.1073e-04, 4.2695e-03, 5.8272e-04, 2.7385e-05, 1.5663e-04,\n",
      "        3.7250e-04, 1.8825e-02, 4.6279e-01, 4.4263e-04, 1.9836e-03, 5.7674e-04,\n",
      "        6.0279e-05, 4.5401e-04, 4.1523e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3139e-01, 5.7394e-02, 3.4537e-04, 4.3498e-04, 3.7215e-04, 1.1376e-01,\n",
      "        9.9463e-04, 4.6868e-05, 5.2957e-03, 3.3218e-02, 1.0711e-05, 2.0128e-05,\n",
      "        5.3420e-01, 8.3375e-04, 8.9610e-04, 1.2866e-02, 8.0183e-05, 1.2388e-04,\n",
      "        1.6906e-02, 7.5342e-02, 2.6800e-03, 6.4997e-03, 9.0090e-05, 4.6195e-04,\n",
      "        9.3409e-06, 5.6409e-03, 8.7313e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0469e-02, 3.0427e-04, 9.6519e-02, 1.7497e-02, 6.6469e-03, 5.0233e-05,\n",
      "        1.2520e-03, 3.9550e-02, 1.6574e-04, 3.2907e-02, 5.2077e-05, 1.5903e-03,\n",
      "        2.9679e-01, 2.3453e-02, 9.7932e-02, 5.3946e-04, 1.8077e-03, 1.9428e-04,\n",
      "        2.5135e-01, 2.4223e-03, 8.5413e-02, 1.3723e-02, 1.0457e-03, 2.5135e-04,\n",
      "        9.9431e-05, 1.7169e-02, 8.0282e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4345e-06, 5.2793e-02, 3.9881e-02, 5.3057e-02, 2.7171e-02, 1.0160e-02,\n",
      "        2.7340e-02, 6.0038e-03, 1.2982e-01, 2.1975e-01, 1.9093e-03, 1.5256e-03,\n",
      "        1.3170e-02, 2.3060e-02, 1.2499e-02, 4.7462e-02, 1.9490e-02, 1.9168e-03,\n",
      "        1.2645e-02, 7.8726e-02, 1.7099e-01, 7.3925e-03, 2.9331e-03, 3.4645e-02,\n",
      "        3.4959e-05, 5.5611e-03, 7.0315e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3830e-02, 7.0048e-02, 8.6994e-04, 4.7967e-02, 1.4663e-05, 1.3667e-01,\n",
      "        6.4688e-03, 5.8093e-04, 6.1010e-02, 5.1153e-02, 2.6258e-04, 4.9884e-03,\n",
      "        3.3619e-03, 4.3952e-03, 3.0315e-03, 1.4896e-01, 1.3059e-01, 1.0877e-03,\n",
      "        1.2372e-03, 1.5211e-03, 1.3567e-01, 1.2888e-01, 1.5359e-04, 4.5117e-03,\n",
      "        9.6865e-05, 1.2579e-02, 6.1608e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1580e-04, 7.0529e-02, 6.5490e-05, 1.1456e-03, 8.4037e-07, 2.1752e-01,\n",
      "        8.6248e-05, 9.2260e-06, 5.4941e-03, 5.0742e-01, 2.4573e-05, 8.3480e-06,\n",
      "        1.5483e-03, 1.2401e-03, 4.6701e-05, 8.3130e-02, 4.3816e-03, 3.3650e-05,\n",
      "        9.3386e-02, 1.4324e-04, 4.3130e-04, 1.2608e-02, 1.3111e-04, 1.1852e-04,\n",
      "        5.5748e-05, 2.8914e-04, 3.1905e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.2539e-05, 9.9123e-03, 2.1834e-03, 3.6785e-02, 3.1966e-03, 5.3075e-02,\n",
      "        6.0225e-03, 3.5234e-03, 1.7286e-04, 3.0268e-03, 4.5678e-05, 1.8262e-04,\n",
      "        3.3664e-02, 2.0262e-03, 4.4410e-02, 5.7678e-03, 5.2531e-03, 1.2184e-04,\n",
      "        7.7472e-01, 2.8142e-03, 8.5207e-03, 4.7770e-04, 2.7451e-03, 5.9226e-05,\n",
      "        7.2940e-04, 1.5886e-05, 5.3512e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.6139e-03, 1.8113e-02, 3.2904e-03, 7.5232e-03, 2.1287e-03, 7.0842e-02,\n",
      "        3.7401e-03, 4.5732e-04, 2.2956e-03, 7.9041e-01, 2.6356e-04, 5.2365e-05,\n",
      "        1.7286e-03, 4.1908e-03, 2.6927e-03, 1.8384e-02, 2.3135e-03, 3.6105e-05,\n",
      "        5.3327e-03, 9.7467e-03, 4.9648e-02, 3.1635e-04, 4.7982e-04, 7.4148e-04,\n",
      "        3.6584e-05, 2.4202e-03, 2.0157e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.2298e-04, 4.0576e-03, 9.7675e-04, 4.8859e-03, 9.7531e-04, 1.7108e-02,\n",
      "        3.7715e-03, 2.1049e-03, 1.5795e-04, 1.8183e-03, 4.9188e-06, 8.7935e-05,\n",
      "        5.9359e-03, 2.3342e-04, 2.8323e-02, 2.1994e-02, 7.6884e-05, 2.9693e-05,\n",
      "        6.9245e-04, 4.8680e-03, 9.0077e-01, 3.6686e-04, 1.9092e-04, 7.7785e-05,\n",
      "        9.0967e-06, 7.5195e-05, 2.7970e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.9158e-01, 3.5435e-02, 1.0146e-04, 1.6878e-04, 1.1270e-04, 3.9287e-02,\n",
      "        1.4374e-03, 2.8596e-05, 1.2021e-03, 1.3545e-01, 4.3433e-06, 8.1443e-05,\n",
      "        1.3481e-03, 1.0702e-03, 7.1037e-04, 1.4252e-03, 9.0703e-04, 9.0725e-06,\n",
      "        4.1598e-04, 1.8693e-01, 1.2757e-03, 7.4728e-02, 2.9603e-05, 2.6741e-04,\n",
      "        1.5026e-06, 2.5986e-02, 7.5552e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7767e-01, 6.9683e-04, 1.6535e-05, 1.5791e-04, 2.6010e-06, 6.6405e-03,\n",
      "        1.1115e-04, 3.0688e-06, 1.7586e-05, 1.0124e-02, 4.2217e-07, 5.6089e-06,\n",
      "        7.5844e-05, 3.8350e-04, 2.0125e-05, 1.2253e-03, 8.3516e-05, 1.2370e-06,\n",
      "        8.7657e-06, 1.2402e-04, 1.6217e-03, 5.5297e-04, 3.5794e-07, 2.3384e-05,\n",
      "        4.6179e-08, 4.3663e-04, 5.4976e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0694e-06, 2.2437e-01, 2.3301e-02, 2.1759e-02, 1.3035e-02, 1.2176e-02,\n",
      "        4.5152e-02, 5.6645e-03, 3.7860e-02, 1.0972e-01, 2.9978e-03, 9.6212e-04,\n",
      "        1.4113e-02, 2.2143e-02, 1.4773e-02, 1.1766e-01, 1.7121e-02, 1.2237e-03,\n",
      "        1.1712e-02, 4.0581e-02, 1.8182e-01, 1.0431e-02, 4.1644e-03, 6.4419e-02,\n",
      "        2.5678e-05, 2.7644e-03, 4.7116e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.1729e-05, 5.3809e-02, 8.9453e-06, 6.9313e-06, 1.0012e-07, 1.2019e-01,\n",
      "        2.6040e-05, 2.5108e-06, 4.5515e-01, 2.8764e-01, 4.8498e-06, 1.3788e-05,\n",
      "        5.3733e-04, 1.0515e-04, 1.1263e-04, 7.6830e-02, 9.1553e-06, 1.1734e-05,\n",
      "        4.3655e-03, 3.5237e-05, 2.8845e-04, 2.8033e-04, 1.1058e-06, 6.2806e-05,\n",
      "        3.3924e-06, 4.3025e-04, 8.2553e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.0625e-04, 1.5656e-03, 2.1545e-04, 2.9135e-03, 1.5539e-03, 1.2490e-04,\n",
      "        8.3505e-04, 6.3689e-04, 4.9618e-04, 3.7171e-05, 5.8047e-06, 1.2876e-03,\n",
      "        1.4517e-01, 4.2789e-03, 2.0222e-02, 6.3280e-04, 2.5939e-04, 4.7069e-05,\n",
      "        3.0933e-03, 4.8071e-02, 7.6571e-01, 1.2058e-04, 1.0037e-03, 1.4718e-04,\n",
      "        2.9069e-04, 1.5365e-05, 3.5716e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.6957e-03, 3.5089e-03, 2.6874e-05, 4.7297e-05, 7.3863e-05, 1.6006e-03,\n",
      "        5.6888e-05, 4.5741e-05, 9.7870e-01, 3.8246e-04, 6.1066e-06, 2.0371e-03,\n",
      "        2.3258e-03, 6.5194e-05, 1.9336e-04, 2.6064e-04, 2.0966e-05, 9.2444e-05,\n",
      "        4.9811e-04, 1.8511e-03, 1.5358e-03, 2.0866e-03, 1.0639e-05, 2.4663e-05,\n",
      "        6.6076e-06, 8.1466e-04, 2.7526e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.3262e-01, 2.5750e-03, 1.8035e-04, 1.4052e-05, 6.4461e-05, 1.0153e-02,\n",
      "        3.3155e-04, 4.6193e-05, 6.6695e-05, 4.0956e-02, 3.0664e-05, 2.5028e-05,\n",
      "        8.4626e-04, 1.3596e-03, 1.2829e-03, 8.4441e-02, 1.5539e-05, 7.2586e-06,\n",
      "        2.3926e-03, 2.3584e-03, 9.5104e-03, 2.5601e-03, 8.1781e-05, 3.8866e-04,\n",
      "        1.2905e-05, 7.6244e-03, 5.4015e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.1549e-07, 1.3473e-01, 1.1048e-02, 2.4260e-02, 1.2257e-02, 3.2407e-02,\n",
      "        1.0559e-02, 5.3907e-03, 6.1696e-02, 1.1241e-01, 4.9065e-03, 1.2537e-03,\n",
      "        1.0317e-02, 4.5480e-02, 1.6460e-02, 4.9751e-02, 1.8802e-02, 9.1366e-04,\n",
      "        1.5149e-02, 5.8211e-02, 2.8964e-01, 1.4088e-02, 2.9898e-03, 6.3360e-02,\n",
      "        3.2729e-05, 3.8466e-03, 3.2460e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.2149e-02, 7.9123e-02, 6.0521e-04, 4.1843e-02, 9.9585e-06, 1.3489e-01,\n",
      "        1.9808e-03, 4.6101e-04, 7.7943e-02, 5.3477e-02, 2.7899e-04, 8.1983e-03,\n",
      "        4.8395e-03, 4.3842e-03, 1.1918e-03, 1.6526e-01, 5.9538e-02, 1.0564e-03,\n",
      "        9.8000e-04, 1.4273e-03, 1.4607e-01, 1.6929e-01, 8.5611e-05, 8.6606e-03,\n",
      "        8.4369e-05, 1.6104e-02, 7.2236e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.6524e-01, 1.1883e-03, 3.4532e-03, 7.8195e-02, 1.3953e-03, 1.9099e-03,\n",
      "        5.9694e-03, 1.1793e-03, 1.0748e-04, 1.0667e-02, 2.5242e-04, 2.6692e-04,\n",
      "        4.3246e-02, 2.6194e-01, 2.4654e-02, 3.3430e-02, 9.6667e-03, 2.7409e-04,\n",
      "        2.5316e-02, 1.9615e-03, 1.0421e-02, 2.0116e-01, 4.6359e-03, 1.2526e-02,\n",
      "        7.9976e-04, 1.0917e-04, 2.3856e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0604e-06, 1.2009e-01, 4.8017e-02, 6.0962e-02, 2.6468e-02, 3.1447e-02,\n",
      "        4.2598e-02, 2.6372e-02, 2.2274e-02, 1.1112e-01, 5.0202e-03, 1.6703e-03,\n",
      "        3.1122e-02, 6.0354e-02, 2.5406e-02, 1.7992e-02, 2.4894e-02, 9.9206e-04,\n",
      "        2.5898e-02, 1.2666e-02, 2.4356e-01, 1.5726e-02, 4.5502e-03, 3.9820e-02,\n",
      "        6.2590e-05, 8.7652e-04, 3.4578e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2401e-04, 3.5009e-02, 4.4146e-05, 1.0934e-05, 5.3155e-07, 4.0337e-02,\n",
      "        2.8455e-04, 7.6768e-06, 6.7746e-01, 2.3528e-02, 8.3984e-06, 5.7205e-05,\n",
      "        4.6622e-04, 4.8059e-05, 2.9743e-05, 1.8413e-01, 3.5555e-05, 2.1907e-05,\n",
      "        2.7233e-02, 7.1168e-05, 2.1114e-04, 7.5029e-03, 1.6796e-05, 5.3683e-04,\n",
      "        3.4729e-06, 2.8194e-03, 7.3935e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1558e-03, 9.6760e-02, 1.0218e-05, 3.3255e-07, 1.2836e-06, 7.5702e-01,\n",
      "        7.2840e-06, 5.0361e-06, 3.6526e-05, 1.0177e-01, 1.2014e-05, 3.3966e-06,\n",
      "        1.5375e-04, 2.8422e-04, 1.6306e-04, 2.2625e-02, 1.8721e-05, 1.0936e-06,\n",
      "        1.2986e-02, 1.5219e-04, 7.7832e-05, 5.4238e-03, 1.9534e-06, 2.4614e-04,\n",
      "        8.1123e-06, 1.0720e-03, 3.1087e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.3778e-01, 5.4484e-04, 1.8818e-04, 9.2642e-05, 8.8043e-05, 1.5392e-03,\n",
      "        3.0434e-04, 4.1052e-04, 7.2372e-04, 4.1599e-02, 8.1626e-05, 3.6322e-04,\n",
      "        1.7183e-03, 6.1974e-02, 1.1893e-02, 3.5454e-04, 1.6133e-03, 1.9394e-05,\n",
      "        6.1393e-02, 1.5191e-02, 1.6771e-03, 4.8709e-05, 2.5625e-04, 8.6527e-04,\n",
      "        4.3310e-05, 5.9171e-02, 6.9288e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.5051e-01, 1.3800e-03, 3.5343e-05, 1.1623e-03, 4.7228e-03, 1.3092e-02,\n",
      "        2.0681e-04, 2.2439e-03, 8.0936e-04, 1.8191e-03, 1.5614e-04, 2.6545e-03,\n",
      "        2.1175e-04, 8.6685e-05, 6.2730e-05, 7.9326e-03, 1.6526e-05, 5.1938e-05,\n",
      "        6.0110e-04, 2.3649e-03, 1.0741e-03, 3.5176e-04, 1.4013e-04, 2.1507e-04,\n",
      "        1.9486e-05, 8.0403e-03, 4.1011e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([3.3023e-06, 8.1397e-02, 2.2552e-02, 6.5075e-02, 7.4324e-02, 5.8034e-02,\n",
      "        3.2481e-02, 2.0457e-02, 5.1569e-02, 7.3676e-02, 4.5103e-03, 1.0362e-02,\n",
      "        2.1476e-02, 4.3697e-02, 1.8103e-02, 3.0398e-02, 3.8003e-02, 1.4017e-03,\n",
      "        1.5968e-02, 7.4679e-02, 1.7278e-01, 1.1949e-02, 9.5495e-03, 6.1117e-02,\n",
      "        5.7144e-05, 6.2877e-03, 9.4717e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8172e-04, 4.5165e-02, 4.9402e-05, 7.9522e-06, 6.9737e-07, 6.6143e-02,\n",
      "        4.7796e-04, 5.4042e-06, 5.7687e-01, 3.9502e-02, 8.4876e-06, 3.0111e-05,\n",
      "        5.5744e-04, 5.5449e-05, 5.8142e-05, 2.0591e-01, 2.6546e-05, 2.0194e-05,\n",
      "        4.3320e-02, 1.7429e-04, 1.4785e-04, 5.3154e-03, 1.8190e-05, 8.1492e-04,\n",
      "        4.6183e-06, 1.5124e-02, 1.4434e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.5742e-01, 2.0547e-03, 1.7732e-04, 4.6409e-04, 1.1175e-03, 4.5877e-03,\n",
      "        9.5751e-04, 1.0223e-03, 8.6145e-04, 5.5886e-03, 6.6166e-05, 9.4008e-04,\n",
      "        6.7911e-03, 6.8918e-03, 4.3342e-03, 6.0104e-02, 1.7984e-04, 1.7441e-05,\n",
      "        1.5362e-02, 3.2672e-03, 5.4858e-04, 1.7295e-02, 6.1740e-04, 8.5389e-03,\n",
      "        5.8572e-04, 1.9291e-04, 1.3733e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.2315e-06, 1.0561e-01, 7.4319e-02, 4.1982e-02, 3.5064e-02, 4.0330e-02,\n",
      "        2.3856e-02, 2.0399e-02, 4.1372e-02, 4.3998e-02, 5.7624e-03, 6.9421e-03,\n",
      "        3.3557e-02, 6.1431e-02, 9.8572e-03, 1.8532e-02, 5.9009e-02, 1.0972e-03,\n",
      "        2.1976e-02, 3.8572e-02, 2.5162e-01, 9.7581e-03, 1.2618e-02, 3.9325e-02,\n",
      "        8.3432e-05, 2.8941e-03, 3.9106e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.0971e-04, 2.0273e-01, 7.1795e-04, 9.1177e-06, 3.4162e-06, 3.4589e-01,\n",
      "        1.2241e-04, 9.8317e-06, 2.5807e-04, 6.6241e-02, 2.4774e-05, 2.7071e-06,\n",
      "        3.8762e-05, 3.1463e-04, 1.0080e-04, 2.4305e-01, 1.5827e-03, 2.6937e-05,\n",
      "        7.7787e-04, 3.1485e-04, 1.4987e-05, 1.2533e-01, 6.2104e-05, 3.4924e-04,\n",
      "        2.4750e-05, 1.1574e-02, 1.5554e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.6650e-01, 2.6688e-01, 4.6634e-03, 4.1660e-03, 2.5863e-02, 4.9485e-03,\n",
      "        1.9260e-03, 1.4254e-03, 6.7968e-04, 5.0570e-03, 3.5747e-04, 3.2014e-04,\n",
      "        8.9894e-03, 1.4659e-02, 2.6886e-01, 6.0305e-03, 1.6481e-03, 1.2534e-03,\n",
      "        9.2903e-02, 1.9338e-02, 8.7662e-02, 2.4069e-04, 3.1879e-03, 1.4677e-03,\n",
      "        2.0986e-03, 8.5753e-03, 3.0432e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.1916e-03, 2.6457e-05, 8.9002e-03, 6.5649e-03, 3.6126e-02, 1.4657e-05,\n",
      "        4.8360e-04, 6.9095e-03, 2.0547e-04, 5.1491e-04, 2.8784e-04, 6.9491e-03,\n",
      "        2.0607e-02, 2.9733e-03, 7.5075e-01, 3.1450e-05, 5.9327e-03, 2.2088e-04,\n",
      "        7.5191e-02, 5.0253e-02, 1.7681e-02, 2.1799e-03, 3.2633e-03, 3.6441e-04,\n",
      "        2.9351e-04, 3.1626e-04, 7.6617e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.6860e-02, 5.4541e-03, 8.9649e-03, 6.7252e-03, 1.5777e-01, 1.8301e-02,\n",
      "        6.5192e-03, 3.6438e-03, 2.6762e-03, 6.9916e-02, 1.5071e-04, 2.4031e-02,\n",
      "        3.6093e-02, 9.2204e-03, 1.2586e-01, 2.4839e-03, 2.6578e-03, 1.5794e-04,\n",
      "        1.0568e-02, 2.1899e-01, 1.5809e-01, 4.5744e-04, 2.4114e-03, 2.5097e-03,\n",
      "        6.1271e-05, 6.9045e-02, 3.8894e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "ketches that would create a more agreeab <------ | ------> l sequenta spirits with so then to mearn\n",
      "Epoch 5   Time 62.777    Train Loss: 1.402\n",
      "Softmaxed: tensor([8.9022e-01, 5.8291e-04, 8.4061e-05, 3.3467e-04, 7.1082e-04, 8.8942e-04,\n",
      "        2.0182e-04, 5.1234e-05, 7.0800e-05, 5.2102e-03, 2.8305e-06, 1.9180e-05,\n",
      "        6.4897e-02, 2.5436e-04, 2.9253e-04, 7.2529e-04, 3.5634e-05, 2.1319e-05,\n",
      "        4.7891e-04, 3.0715e-02, 2.8432e-04, 4.9449e-04, 1.7476e-04, 2.0369e-04,\n",
      "        2.4669e-05, 2.9844e-03, 3.9473e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([5.5438e-06, 9.4453e-02, 3.3010e-02, 5.5004e-02, 4.8195e-02, 2.1257e-02,\n",
      "        6.0908e-02, 2.4368e-02, 2.9175e-02, 9.1319e-02, 3.6218e-03, 3.9719e-03,\n",
      "        1.3077e-02, 5.6598e-02, 2.3520e-02, 5.3604e-02, 5.2754e-02, 2.6640e-03,\n",
      "        1.9873e-02, 1.3402e-01, 6.0445e-02, 1.5753e-02, 9.4729e-03, 8.6620e-02,\n",
      "        9.9741e-05, 5.5583e-03, 6.5350e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.0844e-06, 2.5796e-01, 1.6056e-05, 6.7168e-05, 9.5451e-06, 7.5772e-02,\n",
      "        1.2936e-04, 1.0867e-05, 1.1729e-01, 2.6685e-02, 1.5088e-05, 5.6043e-04,\n",
      "        2.7790e-02, 7.1227e-05, 7.2734e-05, 3.9779e-01, 7.5612e-05, 1.2025e-03,\n",
      "        5.3416e-02, 2.0768e-04, 2.9028e-03, 3.4965e-02, 5.3061e-05, 2.2686e-04,\n",
      "        4.2608e-05, 2.6566e-03, 6.3812e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9939e-03, 3.1703e-04, 1.5244e-04, 4.5991e-04, 2.1356e-03, 3.1806e-04,\n",
      "        9.2946e-04, 2.2986e-03, 6.0212e-05, 9.7136e-04, 2.5500e-05, 5.0348e-04,\n",
      "        2.9908e-02, 2.7824e-01, 4.8548e-01, 7.1285e-04, 4.1103e-03, 2.7985e-04,\n",
      "        4.4523e-02, 8.0233e-03, 4.4752e-04, 1.2277e-01, 5.2953e-03, 8.3718e-03,\n",
      "        1.6332e-03, 1.9814e-05, 1.2532e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.6364e-03, 2.4571e-02, 7.4219e-03, 2.5079e-03, 1.4234e-03, 1.5211e-01,\n",
      "        1.3185e-03, 1.0480e-04, 3.8389e-05, 1.5622e-02, 3.6856e-04, 6.8132e-05,\n",
      "        2.1945e-04, 3.5550e-01, 5.1814e-03, 2.2285e-04, 4.0946e-01, 2.2310e-04,\n",
      "        2.3848e-03, 1.2609e-02, 2.4201e-03, 2.9307e-03, 5.2965e-04, 4.2882e-04,\n",
      "        6.9314e-05, 4.7337e-04, 1.4943e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.2413e-02, 3.0562e-01, 4.1786e-03, 2.2822e-04, 7.9742e-05, 1.0001e-01,\n",
      "        6.8622e-04, 1.8307e-04, 2.2100e-04, 6.4823e-02, 7.9246e-05, 7.3130e-07,\n",
      "        3.2176e-04, 1.2678e-02, 2.7303e-03, 2.7154e-01, 9.5520e-03, 6.8103e-05,\n",
      "        1.5486e-03, 1.6659e-02, 1.8960e-04, 1.2243e-01, 9.3184e-05, 2.0444e-04,\n",
      "        2.1356e-05, 7.3359e-02, 9.3576e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.3283e-03, 1.3576e-03, 1.8550e-03, 1.2725e-02, 3.2561e-02, 1.9357e-04,\n",
      "        4.3910e-03, 3.9161e-03, 1.2245e-04, 1.4254e-03, 1.1089e-04, 2.2724e-04,\n",
      "        3.0704e-03, 8.2181e-03, 6.5185e-01, 3.7859e-03, 6.6991e-03, 1.2812e-04,\n",
      "        1.5966e-01, 4.1049e-02, 1.3710e-02, 2.9190e-02, 8.0833e-03, 3.9859e-03,\n",
      "        5.3070e-04, 1.2365e-03, 5.9152e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.0468e-01, 3.8167e-01, 5.8530e-04, 6.8140e-03, 3.0353e-02, 2.8307e-02,\n",
      "        6.0032e-03, 9.6057e-04, 1.9671e-03, 1.3080e-01, 9.4087e-05, 3.0120e-04,\n",
      "        1.3115e-03, 1.9098e-02, 1.5588e-02, 1.1897e-02, 7.9490e-04, 2.4080e-04,\n",
      "        2.8519e-03, 3.1481e-02, 3.2383e-02, 2.1087e-04, 1.6505e-03, 7.8129e-04,\n",
      "        8.2828e-05, 1.8899e-01, 9.8272e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3661e-03, 8.1947e-02, 1.0355e-02, 7.8330e-02, 3.6055e-03, 6.5554e-02,\n",
      "        6.4344e-02, 3.1993e-02, 7.6683e-04, 1.1892e-03, 1.0012e-04, 7.4865e-04,\n",
      "        9.2825e-03, 4.6103e-03, 4.3532e-02, 4.3383e-02, 2.2366e-03, 9.3782e-04,\n",
      "        4.7111e-04, 1.0971e-01, 3.7219e-01, 4.1487e-03, 3.2942e-02, 7.5062e-04,\n",
      "        5.1568e-04, 6.9154e-04, 3.1298e-02], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.6209e-02, 1.2802e-03, 1.2216e-02, 1.9164e-02, 5.6907e-03, 1.3772e-04,\n",
      "        4.2523e-03, 3.2983e-02, 1.2419e-03, 2.1538e-02, 2.2078e-04, 2.2456e-03,\n",
      "        1.8175e-01, 3.5675e-03, 4.5988e-01, 5.9814e-05, 9.4003e-04, 1.2474e-04,\n",
      "        2.0597e-02, 3.1382e-02, 1.7973e-01, 1.2722e-03, 2.5170e-04, 3.2667e-04,\n",
      "        5.7600e-05, 1.0512e-03, 1.8335e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.2311e-01, 2.6056e-02, 3.0064e-04, 5.7750e-02, 5.6259e-03, 3.7113e-02,\n",
      "        8.2549e-03, 2.2191e-03, 2.7974e-04, 1.1945e-01, 9.2744e-05, 9.2524e-05,\n",
      "        1.8332e-02, 9.1967e-04, 9.1283e-04, 1.3477e-02, 1.5348e-04, 4.2912e-04,\n",
      "        4.2133e-04, 1.1105e-01, 5.7497e-02, 5.3305e-04, 1.0089e-04, 5.3983e-04,\n",
      "        5.9316e-05, 1.5139e-02, 8.7985e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2886e-01, 7.7555e-03, 1.4949e-03, 1.1401e-02, 2.1802e-01, 6.7172e-04,\n",
      "        9.4414e-03, 2.5131e-03, 8.5699e-05, 2.9506e-04, 5.1161e-05, 2.0200e-04,\n",
      "        1.9126e-02, 4.0125e-03, 3.2388e-03, 3.7080e-04, 8.4550e-04, 1.1578e-03,\n",
      "        4.7107e-02, 5.2242e-01, 7.4599e-03, 3.6275e-04, 1.9809e-03, 3.0283e-03,\n",
      "        3.6698e-04, 7.5988e-03, 1.3434e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.9729e-01, 6.9537e-03, 2.1400e-04, 2.0909e-03, 2.0500e-05, 1.7088e-02,\n",
      "        5.8620e-03, 2.7929e-05, 8.1541e-03, 4.4813e-03, 4.8669e-06, 1.1250e-04,\n",
      "        4.9595e-04, 5.5520e-03, 5.5008e-05, 6.1908e-03, 2.5223e-02, 7.5629e-05,\n",
      "        9.1118e-04, 2.4152e-01, 7.4439e-02, 6.5426e-04, 7.8138e-05, 1.8724e-03,\n",
      "        3.0079e-06, 5.9003e-04, 3.8083e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.7091e-01, 4.0233e-01, 5.0281e-05, 5.7178e-06, 1.0481e-05, 3.5823e-02,\n",
      "        1.7786e-04, 5.1255e-06, 1.6320e-02, 1.2025e-01, 1.6340e-06, 4.4208e-06,\n",
      "        2.1828e-02, 2.0222e-03, 3.1730e-04, 6.5637e-02, 3.1851e-04, 2.0179e-05,\n",
      "        1.3918e-02, 9.8929e-02, 1.7747e-05, 2.2379e-02, 1.5277e-05, 8.5856e-04,\n",
      "        6.2373e-06, 2.7827e-02, 1.2787e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.1059e-04, 3.3755e-02, 2.9049e-05, 9.7471e-06, 2.8224e-06, 6.9264e-01,\n",
      "        5.1282e-05, 4.3587e-06, 4.7568e-06, 2.2413e-01, 1.2591e-06, 2.0732e-07,\n",
      "        8.0508e-05, 4.7265e-04, 1.2297e-03, 3.6893e-02, 3.6984e-05, 8.5951e-07,\n",
      "        1.2579e-03, 1.5778e-04, 3.8215e-04, 6.9344e-04, 2.6476e-06, 2.4335e-05,\n",
      "        1.3735e-06, 7.4286e-03, 1.0765e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.1997e-02, 1.3109e-03, 4.0769e-04, 2.7704e-03, 1.5421e-02, 9.2898e-04,\n",
      "        3.4191e-04, 5.5994e-04, 7.7723e-05, 2.3459e-03, 1.2431e-05, 1.1412e-05,\n",
      "        7.8492e-02, 5.6275e-03, 8.0610e-02, 2.0460e-04, 5.5258e-04, 2.6190e-05,\n",
      "        3.7438e-01, 3.3375e-01, 6.6383e-03, 8.1120e-05, 5.4273e-04, 6.4332e-04,\n",
      "        2.0178e-04, 2.0471e-03, 1.1740e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.9319e-02, 2.0068e-02, 5.9364e-03, 2.7393e-03, 5.4017e-02, 1.5037e-01,\n",
      "        5.4254e-02, 1.1789e-03, 9.2839e-05, 4.3410e-02, 4.7979e-05, 2.3984e-04,\n",
      "        1.6920e-02, 4.8379e-04, 1.1152e-03, 1.0886e-01, 1.6986e-03, 7.5708e-05,\n",
      "        1.1022e-03, 2.8537e-01, 4.3451e-02, 1.5294e-02, 9.2021e-02, 4.1801e-03,\n",
      "        4.2232e-05, 6.7413e-02, 3.0744e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.1284e-01, 3.2823e-03, 1.0677e-04, 1.0123e-03, 1.5176e-05, 4.3630e-02,\n",
      "        1.7297e-03, 5.3590e-05, 6.2502e-04, 1.3318e-02, 2.9869e-06, 7.7082e-05,\n",
      "        1.8682e-04, 2.5988e-03, 1.5380e-04, 6.6036e-03, 1.1166e-03, 7.6013e-06,\n",
      "        1.2746e-04, 3.1887e-03, 4.6500e-03, 8.0205e-04, 2.7899e-05, 2.8244e-04,\n",
      "        1.7679e-06, 3.5445e-03, 1.5789e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.3811e-07, 2.3219e-01, 2.9184e-02, 2.2825e-02, 2.9226e-02, 1.8596e-02,\n",
      "        2.7018e-02, 8.1777e-03, 3.9630e-02, 1.4773e-01, 2.5323e-03, 1.9053e-03,\n",
      "        1.1465e-02, 3.1672e-02, 1.7356e-02, 8.1449e-02, 2.0446e-02, 1.3346e-03,\n",
      "        1.5070e-02, 5.0683e-02, 1.2859e-01, 7.4309e-03, 5.1997e-03, 6.7604e-02,\n",
      "        2.3069e-05, 2.6318e-03, 3.9352e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.3540e-04, 1.3204e-02, 2.6414e-05, 2.4830e-06, 3.4585e-07, 8.8594e-03,\n",
      "        3.1317e-04, 5.6500e-06, 6.8432e-01, 1.0838e-02, 3.4209e-06, 2.3064e-05,\n",
      "        2.3586e-04, 3.8680e-05, 3.0437e-05, 2.6259e-01, 1.1674e-05, 1.0336e-05,\n",
      "        1.4103e-02, 5.8008e-05, 8.6048e-05, 3.0627e-03, 7.4183e-06, 5.1077e-04,\n",
      "        1.3722e-06, 1.4185e-03, 4.2546e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.0466e-04, 1.6256e-01, 3.8897e-06, 8.8565e-08, 8.6806e-07, 7.4147e-01,\n",
      "        3.9779e-06, 1.9314e-06, 2.6732e-05, 6.7051e-02, 4.3472e-06, 1.7266e-06,\n",
      "        5.1561e-05, 1.2112e-04, 1.0653e-04, 1.6505e-02, 6.2321e-06, 3.6975e-07,\n",
      "        8.5075e-03, 1.0887e-04, 5.4533e-05, 2.3177e-03, 5.0889e-07, 1.2733e-04,\n",
      "        3.3352e-06, 5.5819e-04, 1.3491e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.8260e-04, 5.2991e-06, 1.1968e-04, 6.5132e-05, 2.3609e-04, 5.8918e-05,\n",
      "        4.3657e-05, 1.4843e-04, 3.0000e-05, 4.7182e-04, 8.6103e-06, 9.9470e-04,\n",
      "        5.7062e-04, 1.5337e-03, 5.2501e-02, 5.3717e-06, 2.7665e-04, 1.4404e-07,\n",
      "        5.9376e-04, 7.3456e-03, 9.3288e-01, 1.1098e-04, 1.7373e-04, 2.7905e-04,\n",
      "        4.7275e-06, 7.9326e-04, 6.6988e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9398e-01, 1.1719e-05, 1.0858e-06, 5.4885e-06, 4.3809e-06, 1.7320e-03,\n",
      "        9.4402e-06, 2.5765e-06, 1.7361e-03, 7.6910e-04, 1.9057e-07, 4.8900e-05,\n",
      "        3.6900e-05, 2.1418e-05, 2.7241e-05, 2.2149e-05, 4.1567e-06, 4.7330e-07,\n",
      "        1.8372e-05, 9.5084e-04, 3.4985e-04, 1.9929e-04, 6.3669e-07, 2.4415e-05,\n",
      "        2.1149e-08, 4.6714e-05, 2.8797e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.1540e-06, 8.7847e-02, 2.6135e-02, 1.8766e-02, 3.1583e-02, 6.0494e-02,\n",
      "        2.4771e-02, 6.5062e-03, 5.9497e-02, 2.0169e-01, 4.0224e-03, 5.2011e-03,\n",
      "        1.4806e-02, 2.7958e-02, 2.8862e-02, 2.8299e-02, 1.3431e-02, 3.1336e-04,\n",
      "        1.8392e-02, 4.7387e-02, 1.9960e-01, 8.9111e-03, 6.1875e-03, 6.4127e-02,\n",
      "        1.2252e-05, 1.5150e-02, 4.6980e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.3896e-03, 2.1948e-01, 9.7180e-05, 3.6277e-04, 7.5852e-07, 2.0128e-01,\n",
      "        2.9491e-03, 5.5173e-06, 3.8401e-04, 1.5382e-01, 2.8950e-05, 2.5142e-06,\n",
      "        3.6649e-02, 4.7469e-05, 3.4167e-05, 2.4719e-01, 3.1930e-05, 2.2648e-04,\n",
      "        1.0946e-01, 6.1717e-06, 1.0793e-03, 2.4176e-02, 9.7494e-05, 7.9501e-04,\n",
      "        7.2513e-05, 3.4072e-04, 1.6368e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5088e-04, 2.3015e-02, 2.7374e-03, 6.4552e-02, 6.1326e-03, 9.4990e-03,\n",
      "        3.0030e-04, 1.1748e-03, 4.7331e-04, 1.1121e-02, 1.1828e-04, 1.2127e-03,\n",
      "        2.1621e-01, 2.0324e-02, 1.4449e-01, 5.2936e-03, 6.8257e-04, 2.5195e-04,\n",
      "        2.0836e-01, 6.9778e-03, 2.6878e-01, 2.8146e-03, 3.0001e-04, 5.8964e-04,\n",
      "        3.6438e-03, 5.5307e-05, 5.4266e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.9947e-02, 3.1645e-02, 2.3639e-02, 1.8043e-02, 6.7471e-02, 3.0437e-02,\n",
      "        4.8287e-03, 3.0023e-03, 4.9042e-03, 5.7025e-02, 8.6934e-04, 2.9204e-04,\n",
      "        2.7147e-02, 8.7374e-02, 5.8063e-02, 5.8553e-03, 2.4571e-03, 1.5017e-04,\n",
      "        5.2152e-02, 1.0847e-01, 3.4562e-01, 2.8403e-03, 3.2857e-04, 4.6606e-03,\n",
      "        2.2337e-04, 2.3864e-03, 1.7293e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.1857e-02, 1.1818e-01, 2.8738e-04, 5.5662e-05, 4.4537e-04, 1.8090e-01,\n",
      "        4.6701e-04, 1.2388e-04, 3.5127e-01, 4.4056e-02, 1.9984e-05, 2.5051e-04,\n",
      "        7.1601e-02, 6.0306e-04, 1.4822e-04, 7.9540e-03, 1.3269e-04, 2.8624e-05,\n",
      "        7.2129e-03, 1.8886e-02, 6.1908e-03, 8.5951e-02, 1.1037e-05, 2.1373e-03,\n",
      "        1.8393e-06, 3.1199e-02, 2.5884e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.4065e-04, 2.2152e-01, 8.0517e-03, 4.7684e-03, 2.0865e-02, 2.4973e-01,\n",
      "        7.1921e-04, 3.5967e-03, 2.0186e-04, 2.1027e-02, 4.3091e-05, 2.0468e-04,\n",
      "        7.1419e-02, 4.7606e-03, 1.4740e-02, 5.2221e-03, 1.6523e-03, 1.3593e-05,\n",
      "        3.5066e-01, 9.7196e-03, 3.6038e-03, 5.4053e-03, 8.3729e-05, 5.3681e-04,\n",
      "        1.0101e-04, 6.1527e-04, 1.9522e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.8296e-03, 1.0871e-01, 1.6848e-04, 3.2678e-05, 8.2984e-05, 8.0663e-01,\n",
      "        1.1675e-04, 4.8822e-05, 1.5470e-04, 5.8082e-02, 1.4784e-06, 6.3212e-07,\n",
      "        4.1345e-04, 5.3585e-04, 1.0050e-03, 6.1658e-03, 4.4027e-06, 6.9488e-07,\n",
      "        4.6170e-05, 6.1563e-04, 3.1680e-04, 1.1009e-03, 4.1525e-06, 2.9501e-05,\n",
      "        1.2740e-06, 1.3898e-02, 1.1738e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.0443e-01, 4.6317e-03, 1.7294e-04, 1.2876e-04, 2.9841e-02, 2.0241e-04,\n",
      "        7.7557e-04, 6.4065e-05, 3.2130e-06, 1.1138e-04, 2.2217e-06, 6.2197e-07,\n",
      "        5.9229e-03, 2.1749e-04, 1.5530e-03, 2.7404e-04, 1.0475e-05, 2.1177e-05,\n",
      "        4.1093e-04, 4.9452e-02, 1.1703e-03, 4.0882e-05, 1.4027e-04, 1.6387e-04,\n",
      "        1.6771e-05, 2.4351e-04, 1.0037e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.5110e-07, 2.2482e-01, 2.8337e-02, 1.8701e-02, 1.5142e-02, 4.1813e-02,\n",
      "        2.8983e-02, 8.2153e-03, 4.0404e-02, 1.3499e-01, 1.6096e-03, 2.0733e-03,\n",
      "        1.1887e-02, 2.6560e-02, 1.5362e-02, 1.3631e-01, 1.9046e-02, 1.0927e-03,\n",
      "        7.3966e-03, 2.2255e-02, 1.3378e-01, 1.4261e-02, 3.5640e-03, 6.1072e-02,\n",
      "        1.9993e-05, 2.2652e-03, 3.8927e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0189e-04, 2.0780e-02, 2.5919e-05, 2.2391e-06, 3.5051e-07, 1.2798e-02,\n",
      "        3.7499e-04, 5.1167e-06, 6.3607e-01, 1.6028e-02, 3.0422e-06, 2.4252e-05,\n",
      "        2.0836e-04, 3.4547e-05, 3.0622e-05, 2.9125e-01, 1.2973e-05, 1.1683e-05,\n",
      "        1.5161e-02, 7.0625e-05, 7.0562e-05, 2.7195e-03, 8.1422e-06, 4.9419e-04,\n",
      "        1.5001e-06, 3.6105e-03, 4.4252e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.3135e-03, 4.8060e-03, 1.3934e-03, 3.9468e-03, 8.9634e-03, 2.8721e-03,\n",
      "        1.5749e-02, 4.9754e-03, 2.8566e-04, 1.0097e-04, 6.1637e-05, 2.6794e-02,\n",
      "        6.0321e-03, 7.9533e-01, 1.9960e-02, 7.9254e-03, 1.6579e-02, 4.2402e-04,\n",
      "        9.9623e-03, 2.5739e-02, 9.7520e-03, 1.2677e-02, 2.2395e-02, 1.0514e-03,\n",
      "        8.4615e-04, 1.6542e-06, 6.8234e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.4339e-04, 3.2620e-02, 9.3499e-04, 3.3663e-05, 2.3647e-04, 8.7808e-01,\n",
      "        1.3860e-04, 9.0895e-05, 1.9035e-04, 5.3911e-02, 9.1471e-05, 1.6492e-04,\n",
      "        2.5548e-04, 6.0478e-03, 9.5446e-04, 7.8085e-04, 1.1426e-02, 1.1139e-05,\n",
      "        4.8109e-03, 3.8209e-03, 2.8597e-04, 3.9355e-03, 4.8089e-05, 5.5665e-05,\n",
      "        1.8814e-05, 3.8802e-04, 2.7038e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.9872e-01, 1.1502e-03, 4.2549e-04, 3.5248e-04, 2.5038e-02, 4.2631e-05,\n",
      "        7.9279e-04, 5.8615e-05, 1.5622e-05, 5.0706e-04, 1.3270e-05, 5.1708e-05,\n",
      "        1.3525e-02, 2.9999e-03, 1.4837e-02, 1.8061e-04, 8.2262e-05, 7.5454e-05,\n",
      "        4.8943e-03, 1.1440e-01, 2.0270e-02, 4.8091e-05, 3.0963e-04, 8.0703e-04,\n",
      "        4.0357e-05, 3.5347e-04, 6.3079e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.6271e-07, 1.7159e-01, 2.5403e-02, 2.9277e-02, 1.4266e-02, 2.4564e-02,\n",
      "        1.9713e-02, 6.3642e-03, 4.2370e-02, 1.0833e-01, 1.6187e-03, 2.6630e-03,\n",
      "        8.1746e-03, 2.8289e-02, 1.6480e-02, 1.2965e-01, 1.9474e-02, 1.3602e-03,\n",
      "        1.3585e-02, 4.1239e-02, 2.0703e-01, 1.8075e-02, 2.6575e-03, 6.4321e-02,\n",
      "        2.0786e-05, 3.4555e-03, 3.8215e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.0947e-02, 1.9509e-04, 1.4431e-02, 3.6969e-02, 1.0292e-02, 7.5623e-05,\n",
      "        7.8643e-03, 1.5105e-02, 4.2502e-04, 1.1108e-03, 2.2877e-05, 1.5897e-04,\n",
      "        6.5713e-02, 1.1298e-02, 4.8531e-01, 1.1224e-04, 1.2806e-02, 2.4762e-04,\n",
      "        4.1953e-02, 1.5723e-01, 4.1642e-02, 1.7070e-03, 9.4466e-04, 2.5484e-03,\n",
      "        2.5673e-04, 5.8679e-04, 4.7279e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.1722e-03, 5.4433e-03, 4.5620e-03, 2.0539e-03, 8.6470e-03, 6.6905e-04,\n",
      "        4.0285e-03, 2.9480e-04, 1.9038e-04, 9.5425e-03, 2.8061e-04, 2.2852e-03,\n",
      "        5.6102e-01, 6.0226e-02, 1.3148e-03, 3.2217e-02, 2.6132e-03, 6.9047e-04,\n",
      "        7.4834e-03, 1.2607e-01, 7.0638e-02, 2.2592e-03, 5.0097e-03, 8.3228e-02,\n",
      "        2.7609e-04, 1.4545e-03, 3.2795e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.2856e-01, 7.2098e-03, 7.9819e-06, 4.6298e-06, 4.6091e-05, 4.7007e-03,\n",
      "        2.2646e-04, 3.4153e-05, 4.9356e-05, 7.7587e-03, 4.9238e-06, 1.4839e-05,\n",
      "        5.8393e-04, 1.4734e-04, 1.2620e-05, 4.0175e-02, 1.3397e-05, 5.9965e-06,\n",
      "        4.4392e-05, 4.5132e-03, 1.9382e-04, 6.6040e-04, 5.5483e-05, 3.5501e-03,\n",
      "        1.9290e-05, 1.4062e-03, 3.6115e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      " unegoistic in the domain of the ethical <------ | ------>  commorianesthels that furture time all \n",
      "Epoch 6   Time 62.668    Train Loss: 1.372\n",
      "Softmaxed: tensor([6.7755e-04, 7.5871e-04, 1.4991e-03, 1.0783e-03, 9.2025e-01, 7.1559e-03,\n",
      "        2.5215e-03, 4.8621e-03, 3.8517e-04, 1.8509e-03, 1.5679e-04, 5.7703e-03,\n",
      "        2.7833e-02, 1.1942e-03, 3.4087e-03, 3.1488e-03, 1.1254e-03, 1.7607e-04,\n",
      "        1.0950e-03, 9.6016e-04, 5.2618e-03, 5.0624e-04, 2.9409e-03, 4.1082e-03,\n",
      "        6.6075e-05, 1.1946e-03, 1.5798e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.1093e-01, 5.4313e-03, 1.5698e-05, 2.6181e-06, 1.6640e-04, 6.7765e-02,\n",
      "        5.4762e-05, 5.3903e-04, 7.2683e-05, 4.4793e-03, 2.4129e-05, 1.4358e-05,\n",
      "        1.0763e-03, 1.3308e-03, 5.3822e-04, 2.0600e-03, 2.1418e-05, 6.1705e-06,\n",
      "        1.4496e-03, 2.7984e-03, 1.6462e-05, 5.1825e-04, 2.0012e-05, 2.8871e-04,\n",
      "        1.2985e-05, 3.7026e-04, 1.8907e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8536e-07, 1.3756e-01, 8.5110e-02, 5.3534e-02, 8.2284e-02, 3.3653e-02,\n",
      "        2.4082e-02, 2.4178e-02, 3.1203e-02, 4.9910e-02, 5.3467e-03, 3.9867e-03,\n",
      "        1.2140e-02, 5.1474e-02, 4.2613e-02, 4.2044e-02, 4.7864e-02, 2.8132e-03,\n",
      "        1.5888e-02, 6.7511e-02, 1.4376e-01, 7.9734e-03, 6.1183e-03, 2.6889e-02,\n",
      "        6.2899e-05, 1.9423e-03, 5.8542e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.0398e-03, 1.1195e-01, 8.5291e-04, 5.7242e-02, 6.4631e-06, 2.0259e-01,\n",
      "        4.6159e-03, 8.5800e-04, 5.6862e-02, 4.7548e-02, 1.6593e-04, 5.3438e-03,\n",
      "        5.0936e-03, 4.6696e-03, 1.5964e-03, 1.2203e-01, 5.9801e-02, 1.3476e-03,\n",
      "        1.0429e-03, 4.1196e-04, 1.2110e-01, 1.6743e-01, 7.1354e-05, 4.0263e-03,\n",
      "        6.5352e-05, 1.6205e-02, 3.5031e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.4685e-04, 1.9578e-01, 1.9774e-04, 2.2851e-04, 2.3679e-05, 2.1328e-02,\n",
      "        1.1142e-03, 1.0695e-05, 9.0036e-03, 1.9022e-01, 1.6750e-04, 7.0841e-05,\n",
      "        3.1880e-04, 3.3868e-03, 7.2728e-05, 8.3578e-02, 6.1019e-04, 1.0403e-04,\n",
      "        4.2904e-01, 1.3324e-03, 1.9337e-04, 4.3461e-02, 4.1573e-04, 2.0996e-03,\n",
      "        5.5823e-05, 1.6278e-02, 6.1975e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3820e-06, 1.2261e-01, 8.9855e-04, 6.7241e-04, 1.7228e-04, 2.3774e-01,\n",
      "        1.2382e-04, 4.9458e-04, 2.1563e-03, 9.4670e-02, 4.8350e-04, 3.3952e-04,\n",
      "        2.0271e-03, 1.1096e-03, 7.5743e-04, 4.3530e-01, 4.6156e-04, 6.1583e-05,\n",
      "        4.8940e-03, 2.4367e-05, 2.7486e-04, 8.6957e-02, 1.7735e-03, 1.5430e-04,\n",
      "        2.1988e-04, 5.5182e-03, 9.9751e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.0471e-04, 1.1300e-03, 7.8658e-03, 3.8515e-02, 1.3106e-02, 4.1566e-03,\n",
      "        9.2109e-03, 1.3128e-01, 7.3085e-04, 4.9806e-03, 1.2905e-03, 1.3222e-01,\n",
      "        4.5365e-03, 5.6941e-02, 4.5880e-01, 1.1034e-02, 2.5869e-02, 2.3760e-04,\n",
      "        6.0774e-03, 8.3093e-03, 1.2387e-02, 2.2248e-02, 3.4409e-02, 7.9268e-03,\n",
      "        2.8699e-03, 2.9089e-03, 7.5638e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.8743e-02, 4.1712e-02, 2.1833e-03, 2.6066e-03, 4.7011e-02, 6.2715e-02,\n",
      "        7.9839e-04, 5.3369e-02, 4.8805e-01, 9.1775e-02, 2.3700e-03, 1.4160e-02,\n",
      "        1.5249e-02, 6.4239e-03, 4.7525e-02, 1.6235e-02, 2.7126e-03, 3.1877e-04,\n",
      "        4.9612e-02, 1.6556e-02, 7.3573e-03, 5.4560e-03, 7.8722e-04, 2.6598e-03,\n",
      "        5.2127e-04, 2.0749e-03, 1.0218e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([0.0006, 0.2887, 0.0090, 0.0073, 0.0111, 0.2232, 0.0142, 0.0078, 0.0496,\n",
      "        0.0954, 0.0006, 0.0031, 0.0005, 0.0071, 0.0069, 0.2177, 0.0031, 0.0005,\n",
      "        0.0047, 0.0067, 0.0171, 0.0094, 0.0027, 0.0012, 0.0005, 0.0105, 0.0008],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.9085e-01, 3.7584e-02, 1.4234e-02, 8.5779e-03, 8.7898e-02, 4.2930e-03,\n",
      "        2.2433e-02, 1.0323e-02, 1.5842e-03, 2.3448e-03, 9.6068e-04, 1.6679e-03,\n",
      "        7.7933e-03, 1.7014e-02, 6.8096e-02, 7.8831e-04, 6.3690e-03, 1.8018e-03,\n",
      "        2.4276e-03, 1.7316e-01, 1.5264e-02, 1.5352e-04, 1.6514e-02, 4.6349e-03,\n",
      "        2.1534e-03, 5.3548e-04, 5.4047e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.7116e-01, 2.1928e-03, 7.3923e-04, 5.7028e-03, 1.3246e-04, 6.6347e-03,\n",
      "        1.5556e-03, 1.3290e-05, 6.6913e-03, 1.8067e-03, 1.6868e-05, 6.3604e-04,\n",
      "        4.2879e-04, 4.6926e-03, 5.3272e-04, 3.8803e-04, 5.1649e-02, 2.4991e-04,\n",
      "        1.2556e-04, 5.7229e-01, 6.8768e-02, 9.2266e-04, 7.2406e-05, 1.9733e-03,\n",
      "        1.6807e-05, 5.3128e-04, 7.5320e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.0057e-06, 2.0957e-01, 3.1068e-02, 3.6717e-02, 1.7947e-02, 8.9129e-03,\n",
      "        2.6124e-02, 4.5622e-03, 5.3545e-02, 7.8517e-02, 1.5923e-03, 2.7905e-03,\n",
      "        8.4206e-03, 2.0315e-02, 5.7191e-02, 8.4685e-02, 1.6835e-02, 1.0932e-03,\n",
      "        1.9411e-02, 4.2257e-02, 1.8973e-01, 1.4055e-02, 6.1494e-03, 6.5164e-02,\n",
      "        2.4956e-05, 3.2864e-03, 4.0141e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3732e-01, 1.0916e-04, 1.6186e-02, 4.8492e-02, 7.2276e-03, 4.0808e-05,\n",
      "        1.0355e-02, 1.3252e-02, 3.0783e-04, 7.6027e-04, 2.5874e-05, 1.9060e-04,\n",
      "        6.2485e-02, 8.9376e-03, 4.6041e-01, 9.1481e-05, 1.4420e-02, 1.8732e-04,\n",
      "        4.7367e-02, 1.2676e-01, 3.8866e-02, 1.7949e-03, 1.0556e-03, 2.7067e-03,\n",
      "        2.7445e-04, 3.1698e-04, 5.3365e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.4537e-07, 8.6135e-03, 4.9792e-02, 1.0719e-01, 8.5761e-02, 3.8603e-03,\n",
      "        5.5471e-02, 6.1388e-02, 4.0461e-02, 2.5721e-03, 2.9416e-03, 5.7314e-03,\n",
      "        1.6184e-02, 1.0709e-01, 6.6345e-02, 3.9343e-03, 9.8069e-02, 1.2001e-02,\n",
      "        4.3675e-02, 1.2236e-01, 5.4739e-02, 2.5917e-03, 1.6924e-02, 3.1755e-02,\n",
      "        1.8417e-04, 2.5749e-04, 1.0820e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.8947e-05, 1.1180e-01, 3.6911e-05, 4.7834e-04, 2.4709e-04, 5.9704e-01,\n",
      "        8.1939e-05, 2.5156e-04, 5.2405e-05, 2.1559e-02, 9.8114e-05, 6.5894e-05,\n",
      "        1.1140e-03, 9.7193e-06, 2.7587e-05, 2.5525e-01, 1.2569e-06, 5.3582e-05,\n",
      "        7.1701e-04, 5.9641e-06, 3.2418e-04, 8.7636e-03, 2.2668e-04, 5.8072e-04,\n",
      "        1.9131e-04, 9.9057e-04, 1.0764e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8035e-02, 1.5957e-04, 4.5618e-02, 6.1497e-03, 3.5986e-03, 2.2700e-03,\n",
      "        6.2216e-03, 7.0976e-03, 2.0467e-04, 1.2276e-02, 2.9127e-04, 7.6469e-04,\n",
      "        1.7736e-02, 5.3638e-02, 1.1776e-02, 2.9468e-03, 2.6027e-03, 2.5967e-04,\n",
      "        1.7928e-01, 2.3576e-03, 3.1460e-01, 7.6213e-02, 1.3170e-02, 1.9882e-01,\n",
      "        3.4762e-03, 2.6755e-04, 1.7615e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.0827e-01, 1.0255e-01, 1.4056e-04, 7.4690e-04, 5.9991e-04, 4.0091e-03,\n",
      "        5.9885e-04, 2.9061e-04, 1.4267e-03, 2.3805e-02, 5.4296e-05, 9.8927e-05,\n",
      "        1.3018e-01, 2.0088e-02, 2.2032e-01, 8.9467e-04, 4.8502e-04, 5.7709e-05,\n",
      "        3.6342e-03, 7.5547e-02, 4.1138e-03, 1.1263e-03, 5.7197e-05, 3.3272e-04,\n",
      "        9.3498e-05, 4.5777e-04, 2.0316e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.6054e-04, 1.0810e-01, 2.6444e-05, 3.1918e-06, 1.3332e-04, 7.7090e-01,\n",
      "        1.0445e-04, 2.6896e-06, 4.1690e-05, 1.1785e-02, 2.2275e-06, 4.6119e-06,\n",
      "        6.8623e-03, 6.5187e-05, 1.1136e-04, 5.3229e-02, 1.6368e-05, 1.0730e-05,\n",
      "        3.8774e-04, 3.8563e-03, 4.5497e-05, 6.6389e-03, 2.0202e-04, 2.0565e-04,\n",
      "        7.2066e-06, 3.7088e-02, 4.4696e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.8208e-03, 9.9101e-04, 1.0946e-02, 2.3517e-03, 8.9391e-03, 9.6885e-04,\n",
      "        5.3842e-03, 1.8468e-01, 1.0168e-04, 1.3912e-03, 3.5820e-04, 8.6603e-04,\n",
      "        1.0734e-02, 7.9883e-03, 1.0307e-01, 5.2807e-02, 6.9899e-03, 2.8343e-04,\n",
      "        1.3552e-02, 1.0854e-01, 3.1906e-02, 8.6159e-02, 7.8477e-02, 2.6890e-01,\n",
      "        3.7506e-03, 1.9542e-04, 4.8448e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.7531e-03, 2.8494e-02, 2.5652e-04, 4.9660e-05, 4.7277e-04, 6.6904e-02,\n",
      "        3.6664e-04, 3.4834e-05, 6.3559e-02, 2.5623e-01, 2.8681e-05, 4.7451e-04,\n",
      "        7.0300e-05, 3.5923e-04, 1.4206e-04, 1.1438e-01, 7.8916e-05, 5.3794e-05,\n",
      "        1.8726e-03, 1.3113e-03, 1.2266e-02, 6.2964e-03, 6.8929e-04, 2.2929e-03,\n",
      "        4.6963e-06, 4.3864e-01, 9.1706e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7646e-01, 1.6245e-03, 2.6685e-04, 1.6339e-04, 8.6058e-05, 1.1724e-03,\n",
      "        8.8402e-04, 1.0861e-04, 4.9214e-05, 3.2978e-03, 5.6448e-06, 1.0718e-05,\n",
      "        3.2809e-04, 3.9737e-03, 3.0729e-03, 2.9001e-03, 4.9926e-04, 2.3670e-05,\n",
      "        2.0978e-04, 2.5821e-03, 1.4641e-03, 3.5178e-04, 1.8254e-04, 1.4263e-04,\n",
      "        1.8620e-05, 1.1399e-04, 1.0680e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([4.7187e-07, 3.0631e-01, 2.1282e-02, 2.6094e-02, 1.5657e-02, 1.7555e-02,\n",
      "        1.6672e-02, 5.6465e-03, 3.3582e-02, 1.1243e-01, 2.3394e-03, 2.4505e-03,\n",
      "        7.8931e-03, 3.9446e-02, 2.5724e-02, 9.7425e-02, 2.7404e-02, 2.0610e-03,\n",
      "        1.0637e-02, 3.9005e-02, 1.1090e-01, 1.8762e-02, 3.3737e-03, 5.5557e-02,\n",
      "        2.6441e-05, 1.7163e-03, 4.5205e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.3679e-06, 1.8236e-01, 5.4910e-06, 2.7688e-05, 3.9071e-06, 5.6616e-02,\n",
      "        9.7250e-05, 5.8339e-06, 1.0964e-01, 2.7171e-02, 6.6763e-06, 4.1477e-04,\n",
      "        4.0639e-02, 3.6184e-05, 5.6677e-05, 5.0337e-01, 4.5181e-05, 5.7943e-04,\n",
      "        4.7142e-02, 1.3458e-04, 1.4274e-03, 2.7998e-02, 3.2350e-05, 1.3939e-04,\n",
      "        1.8586e-05, 2.0257e-03, 2.1869e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.2331e-03, 2.2502e-04, 4.9649e-05, 1.7124e-04, 1.7739e-03, 1.7874e-04,\n",
      "        5.5324e-04, 1.1689e-03, 4.1628e-05, 5.7229e-04, 1.1321e-05, 3.2583e-04,\n",
      "        2.5336e-02, 1.7426e-01, 6.4922e-01, 4.5109e-04, 1.7471e-03, 1.5872e-04,\n",
      "        3.8865e-02, 4.6327e-03, 1.8972e-04, 8.5645e-02, 3.4021e-03, 7.5442e-03,\n",
      "        1.2276e-03, 1.0723e-05, 7.1197e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5625e-04, 1.9220e-02, 5.8913e-03, 4.6569e-03, 3.9888e-01, 1.4456e-01,\n",
      "        8.5029e-03, 8.9429e-04, 2.6730e-04, 2.1541e-02, 3.9098e-04, 3.2008e-03,\n",
      "        2.6002e-01, 3.7176e-03, 1.2442e-02, 7.7871e-03, 2.2548e-02, 1.0993e-03,\n",
      "        3.6693e-03, 9.1498e-03, 2.5614e-02, 2.4305e-02, 1.5489e-02, 3.1362e-03,\n",
      "        1.1498e-04, 2.6911e-03, 6.0237e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.2111e-02, 8.4217e-02, 4.3830e-05, 5.9887e-05, 2.5989e-04, 3.7080e-01,\n",
      "        5.9246e-05, 5.5727e-04, 2.0213e-04, 3.3123e-01, 2.9459e-05, 5.7233e-05,\n",
      "        2.3256e-02, 1.2759e-02, 3.9280e-03, 6.1193e-03, 8.3286e-05, 2.7162e-05,\n",
      "        1.6685e-02, 1.7879e-02, 2.4070e-04, 5.8189e-02, 1.5579e-05, 2.2027e-04,\n",
      "        8.1639e-06, 9.5410e-04, 1.0269e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.3069e-03, 9.0224e-03, 1.3568e-03, 7.2379e-03, 2.4318e-01, 1.1751e-03,\n",
      "        3.8682e-03, 8.2812e-03, 5.1309e-05, 4.0426e-04, 3.0739e-05, 3.5926e-04,\n",
      "        3.5518e-03, 2.4168e-02, 3.8454e-01, 9.3769e-05, 5.1031e-03, 1.7613e-04,\n",
      "        2.7605e-01, 1.0863e-02, 7.8756e-03, 9.0202e-05, 5.6727e-03, 1.7354e-04,\n",
      "        2.1912e-04, 1.2120e-04, 2.5501e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.6394e-01, 2.1185e-03, 7.0794e-05, 1.0117e-05, 4.4723e-04, 5.1621e-03,\n",
      "        1.5225e-04, 3.4225e-04, 1.6072e-05, 1.0619e-02, 2.1217e-06, 2.8151e-05,\n",
      "        2.2136e-03, 2.6001e-04, 2.2735e-03, 1.1608e-03, 4.0364e-06, 2.8160e-06,\n",
      "        1.2174e-04, 4.2214e-03, 1.3357e-04, 6.3603e-03, 2.5416e-05, 4.0505e-05,\n",
      "        1.9787e-06, 2.6563e-04, 3.5637e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([2.7523e-07, 2.8169e-01, 4.6765e-02, 1.6650e-02, 1.3163e-02, 2.5964e-02,\n",
      "        3.3913e-02, 9.3752e-03, 5.1087e-02, 6.2588e-02, 1.5536e-03, 2.3405e-03,\n",
      "        1.8203e-03, 2.1623e-02, 5.1496e-02, 4.1932e-02, 3.3004e-02, 1.0230e-03,\n",
      "        8.2411e-03, 2.8391e-02, 2.2239e-01, 7.4759e-03, 3.0674e-03, 3.0173e-02,\n",
      "        2.0041e-05, 4.1797e-03, 7.6417e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4112e-04, 2.1761e-02, 2.1937e-05, 1.4051e-06, 3.3100e-07, 1.5959e-02,\n",
      "        3.9555e-04, 6.5870e-06, 6.0876e-01, 1.6071e-02, 2.8351e-06, 2.6462e-05,\n",
      "        2.4784e-04, 2.9534e-05, 2.2410e-05, 3.1662e-01, 6.5352e-06, 7.3540e-06,\n",
      "        1.2829e-02, 5.5226e-05, 5.7926e-05, 2.9236e-03, 3.9934e-06, 5.2612e-04,\n",
      "        1.1310e-06, 3.5179e-03, 5.2532e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.8204e-04, 2.1051e-01, 5.0369e-06, 6.0971e-08, 1.3777e-06, 6.6785e-01,\n",
      "        4.4314e-06, 2.1897e-06, 4.1681e-05, 6.7296e-02, 4.1080e-06, 2.2142e-06,\n",
      "        6.5261e-05, 1.5176e-04, 1.9801e-04, 3.0167e-02, 6.4966e-06, 4.0162e-07,\n",
      "        1.7769e-02, 2.3886e-04, 5.0768e-05, 3.9655e-03, 4.3390e-07, 2.3137e-04,\n",
      "        3.8953e-06, 4.4914e-04, 1.6961e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.8718e-01, 3.0569e-04, 7.2190e-05, 1.2910e-05, 3.9679e-05, 1.5268e-03,\n",
      "        1.5272e-04, 3.5101e-04, 7.6533e-04, 4.1635e-02, 3.2852e-05, 1.9133e-04,\n",
      "        8.5602e-04, 3.7832e-02, 7.5048e-03, 3.2670e-04, 6.1798e-04, 5.4872e-06,\n",
      "        3.8098e-02, 1.3955e-02, 8.6414e-04, 2.2418e-05, 1.3478e-04, 7.0899e-04,\n",
      "        2.3905e-05, 6.6735e-02, 5.4836e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.2337e-06, 5.3837e-02, 5.3620e-02, 9.3844e-02, 6.9598e-02, 4.6128e-02,\n",
      "        4.1446e-02, 3.5043e-02, 4.6469e-02, 4.8187e-02, 5.9077e-03, 6.0833e-03,\n",
      "        2.4457e-02, 6.0853e-02, 2.8287e-02, 4.2974e-02, 6.1852e-02, 4.6361e-03,\n",
      "        3.9321e-02, 1.0729e-01, 4.4308e-02, 1.8906e-02, 2.1798e-02, 4.1753e-02,\n",
      "        4.6141e-05, 3.2958e-03, 5.4677e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.4476e-07, 1.5655e-01, 1.8978e-04, 1.4275e-05, 8.8207e-05, 4.8167e-01,\n",
      "        8.0776e-06, 2.6726e-04, 3.9857e-04, 3.0548e-02, 2.0387e-04, 5.2708e-05,\n",
      "        6.2715e-02, 1.9534e-05, 3.3607e-04, 8.4988e-02, 5.0686e-05, 2.8129e-05,\n",
      "        8.0534e-02, 8.1922e-05, 2.4045e-04, 7.2359e-02, 1.1228e-05, 1.3005e-04,\n",
      "        4.1948e-05, 2.8462e-02, 1.7248e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.3786e-02, 6.7898e-02, 1.6611e-03, 3.6818e-02, 3.0105e-03, 7.0162e-02,\n",
      "        2.5658e-02, 1.3531e-02, 5.8117e-03, 6.7660e-02, 5.1135e-04, 3.9546e-04,\n",
      "        3.1009e-01, 4.9457e-03, 8.2682e-02, 4.8063e-03, 1.1668e-02, 1.6651e-03,\n",
      "        1.8216e-02, 1.0662e-01, 5.8117e-02, 1.0866e-03, 2.0025e-03, 1.4681e-02,\n",
      "        1.5555e-03, 4.9120e-03, 5.0090e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.5942e-02, 7.7275e-01, 4.3516e-05, 6.9347e-04, 1.8808e-04, 8.9303e-03,\n",
      "        2.5964e-05, 1.6560e-04, 1.4405e-02, 4.7226e-02, 5.3930e-05, 6.8734e-05,\n",
      "        6.0747e-03, 1.6132e-03, 5.4685e-03, 6.9834e-02, 1.6244e-04, 2.5389e-05,\n",
      "        3.3421e-03, 1.6005e-02, 3.0214e-03, 5.7238e-04, 1.0135e-05, 3.0971e-04,\n",
      "        1.0208e-04, 2.9544e-03, 1.1744e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.6366e-03, 6.5407e-04, 4.4705e-03, 4.7811e-03, 1.7068e-02, 6.4872e-04,\n",
      "        1.0423e-03, 1.6665e-03, 5.1781e-04, 2.6356e-04, 1.6352e-04, 3.5692e-04,\n",
      "        1.0422e-01, 9.3429e-02, 1.1280e-01, 1.0326e-02, 5.7690e-03, 3.4189e-04,\n",
      "        5.2271e-01, 1.0267e-02, 1.4417e-02, 3.2667e-02, 1.8010e-02, 3.2560e-02,\n",
      "        3.9735e-03, 1.1510e-05, 2.2501e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.8358e-02, 3.2366e-02, 6.2551e-04, 7.8588e-02, 1.0940e-01, 1.4420e-01,\n",
      "        1.1252e-03, 1.8367e-01, 3.2456e-03, 5.7475e-03, 1.8222e-03, 1.4188e-03,\n",
      "        9.5104e-02, 1.7430e-03, 1.9684e-02, 4.5118e-02, 4.0351e-04, 3.5611e-03,\n",
      "        1.2880e-03, 8.1888e-02, 1.2857e-01, 1.4047e-03, 4.1106e-03, 1.2790e-03,\n",
      "        1.1915e-03, 4.0400e-03, 4.8986e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.1939e-04, 2.7384e-02, 9.7973e-06, 7.3568e-05, 2.7675e-06, 7.5287e-01,\n",
      "        2.6455e-05, 9.3187e-06, 4.7067e-02, 6.0452e-02, 2.6581e-06, 1.4705e-04,\n",
      "        3.6516e-03, 6.9238e-05, 7.2426e-06, 2.1507e-02, 3.6038e-06, 3.7954e-05,\n",
      "        3.2072e-02, 1.5072e-03, 8.2898e-03, 2.0853e-03, 1.4529e-05, 5.4310e-05,\n",
      "        1.2073e-06, 4.2512e-02, 2.2484e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([2.5659e-01, 2.5545e-02, 1.2552e-04, 1.7615e-05, 4.2496e-06, 4.3439e-02,\n",
      "        5.1389e-04, 1.4615e-05, 1.9883e-03, 4.6781e-01, 3.1914e-06, 5.2118e-06,\n",
      "        8.6599e-03, 2.3109e-03, 4.2449e-05, 2.8670e-02, 1.2568e-04, 6.7696e-06,\n",
      "        8.5729e-03, 1.4741e-02, 3.9665e-04, 8.5758e-02, 1.0973e-04, 7.7021e-04,\n",
      "        2.4585e-06, 5.3759e-02, 2.4703e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "little we may imagine ourselves to be ol <------ | ------> d strogres a nowloty colded the bewonctu\n",
      "Epoch 7   Time 63.182    Train Loss: 1.347\n",
      "Softmaxed: tensor([2.8431e-03, 1.8600e-02, 8.0419e-03, 1.2275e-02, 6.2678e-01, 1.9123e-01,\n",
      "        1.3666e-03, 8.3259e-03, 2.1880e-03, 2.1184e-02, 2.7291e-05, 5.2816e-03,\n",
      "        7.0856e-03, 3.3341e-02, 2.5356e-03, 2.1817e-03, 1.3763e-03, 1.2318e-04,\n",
      "        3.5271e-03, 2.6695e-02, 1.7740e-02, 1.3053e-04, 1.7287e-03, 9.7525e-04,\n",
      "        1.0002e-04, 4.1990e-03, 1.2012e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.4005e-01, 2.8850e-02, 5.9749e-04, 3.2294e-04, 3.2432e-04, 1.8228e-01,\n",
      "        3.0453e-04, 2.0784e-03, 1.0557e-04, 9.0770e-02, 9.1765e-06, 7.0758e-06,\n",
      "        2.7736e-02, 2.6050e-03, 4.8881e-03, 1.4712e-02, 1.0241e-04, 2.3759e-05,\n",
      "        1.4720e-03, 1.8657e-01, 2.0224e-04, 1.4270e-02, 2.7826e-05, 2.1825e-04,\n",
      "        9.7187e-06, 1.4496e-03, 1.5412e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7667e-01, 5.6014e-04, 3.9167e-05, 7.0925e-04, 3.5614e-06, 1.5086e-03,\n",
      "        1.2009e-04, 3.5892e-05, 2.8262e-03, 7.8721e-03, 3.9665e-06, 1.5203e-04,\n",
      "        2.0996e-04, 2.8321e-03, 8.0829e-05, 3.8720e-04, 3.2988e-04, 2.8726e-05,\n",
      "        2.3178e-04, 8.8437e-04, 3.0280e-03, 8.0974e-04, 7.3358e-07, 7.7728e-05,\n",
      "        3.8191e-07, 5.9228e-04, 3.6741e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000003576278687\n",
      "Softmaxed: tensor([4.6595e-07, 1.7558e-01, 1.8155e-02, 3.2395e-02, 1.4867e-02, 6.6556e-03,\n",
      "        2.7040e-02, 3.0987e-03, 9.2274e-02, 9.3337e-02, 1.3884e-03, 1.8045e-03,\n",
      "        1.7117e-02, 1.3207e-02, 1.3093e-02, 1.3560e-01, 1.1137e-02, 1.9306e-03,\n",
      "        2.0686e-02, 3.1417e-02, 2.2936e-01, 1.3223e-02, 3.4388e-03, 4.0717e-02,\n",
      "        1.5768e-05, 2.4101e-03, 5.8163e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3714e-05, 3.6694e-02, 6.7519e-06, 2.9865e-06, 3.0634e-08, 1.0879e-01,\n",
      "        1.4776e-05, 2.1749e-06, 4.6131e-01, 3.2622e-01, 1.7025e-06, 6.4092e-06,\n",
      "        4.3254e-04, 7.1116e-05, 1.2971e-04, 6.0440e-02, 3.2695e-06, 4.7338e-06,\n",
      "        4.7079e-03, 2.9263e-05, 2.7150e-04, 1.4603e-04, 3.5161e-07, 7.5232e-05,\n",
      "        1.8573e-06, 5.7515e-04, 5.3127e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.6477e-04, 1.2739e-01, 3.8726e-06, 4.3860e-06, 1.2211e-07, 1.6753e-01,\n",
      "        1.9932e-06, 1.0232e-06, 7.7024e-05, 4.2402e-01, 6.8655e-07, 3.2214e-07,\n",
      "        2.1495e-03, 6.8198e-05, 1.4036e-04, 2.3480e-01, 1.4643e-06, 4.2231e-07,\n",
      "        1.8267e-04, 1.6056e-04, 4.2517e-04, 1.0169e-03, 4.3390e-07, 8.1819e-05,\n",
      "        1.3825e-06, 4.0962e-02, 8.5582e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.9874e-01, 6.5373e-04, 7.5153e-05, 5.6247e-03, 1.7387e-04, 5.0573e-03,\n",
      "        1.2444e-04, 3.1131e-04, 6.6931e-04, 8.1679e-04, 1.3079e-05, 2.0438e-04,\n",
      "        7.0354e-02, 4.9150e-02, 6.6143e-03, 5.7652e-04, 6.0459e-03, 1.4682e-05,\n",
      "        6.2470e-03, 2.2073e-02, 4.1850e-03, 1.3364e-02, 8.0335e-04, 7.7539e-03,\n",
      "        1.8945e-04, 1.0410e-04, 5.8794e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.9178e-06, 1.2322e-01, 2.0324e-02, 5.5331e-02, 6.9513e-02, 3.0450e-02,\n",
      "        2.8110e-02, 2.6519e-02, 1.1570e-01, 4.5351e-02, 2.0300e-03, 1.5091e-02,\n",
      "        3.9698e-02, 4.1039e-02, 1.8498e-02, 2.9260e-02, 2.5433e-02, 1.8079e-03,\n",
      "        3.3306e-02, 1.2774e-01, 4.1293e-02, 1.0467e-02, 1.0626e-02, 8.8603e-02,\n",
      "        7.0429e-05, 4.6949e-04, 4.2693e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.8062e-05, 5.5826e-02, 1.1644e-04, 9.1798e-06, 3.8081e-05, 7.6347e-01,\n",
      "        6.9186e-06, 9.5940e-05, 2.1938e-04, 1.1441e-02, 8.9951e-05, 3.2982e-05,\n",
      "        1.9095e-02, 8.1952e-06, 2.8815e-04, 6.6160e-02, 1.2412e-05, 4.9192e-06,\n",
      "        4.0009e-02, 1.4744e-04, 3.6992e-04, 2.2738e-02, 9.3296e-06, 2.0181e-04,\n",
      "        1.6924e-05, 1.9573e-02, 6.7064e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.6568e-02, 4.8481e-02, 9.1818e-04, 4.4946e-02, 2.2406e-03, 3.1372e-01,\n",
      "        7.1258e-03, 1.1544e-02, 5.0579e-03, 5.9842e-02, 3.4607e-04, 7.4849e-04,\n",
      "        2.7010e-01, 2.2958e-03, 2.3847e-02, 2.1034e-03, 2.6374e-03, 7.3634e-04,\n",
      "        3.6726e-03, 3.2204e-02, 4.7391e-02, 8.7237e-04, 6.4017e-04, 1.4250e-02,\n",
      "        7.0473e-04, 6.9767e-03, 2.5652e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.9803e-04, 5.7407e-04, 6.0123e-04, 6.9853e-04, 1.1759e-02, 3.4789e-04,\n",
      "        1.2129e-03, 8.1941e-02, 7.5920e-06, 5.1313e-05, 2.1969e-05, 1.4146e-03,\n",
      "        2.4585e-03, 4.9327e-03, 8.7326e-01, 2.4847e-04, 1.5028e-04, 9.3629e-06,\n",
      "        1.1050e-02, 8.0730e-04, 3.2410e-03, 2.1859e-04, 4.0052e-03, 1.8375e-04,\n",
      "        1.4660e-04, 1.8309e-06, 4.5638e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.3789e-03, 2.2114e-03, 2.3718e-04, 1.3598e-03, 1.4166e-02, 1.4839e-02,\n",
      "        2.2908e-04, 9.4931e-01, 1.2706e-05, 1.1562e-03, 6.4844e-05, 6.5064e-04,\n",
      "        3.1754e-04, 6.0880e-05, 3.1914e-03, 2.5330e-04, 7.2892e-06, 2.6219e-05,\n",
      "        9.7888e-06, 1.5909e-03, 2.4094e-03, 2.0009e-04, 1.7236e-04, 1.3984e-05,\n",
      "        4.2833e-05, 6.8957e-05, 1.4231e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.7943e-01, 3.6889e-03, 5.2407e-04, 3.3832e-05, 2.7754e-03, 9.9939e-03,\n",
      "        3.0270e-04, 2.6374e-03, 2.1030e-03, 2.0106e-03, 2.2318e-05, 1.3780e-05,\n",
      "        1.6881e-02, 2.6613e-03, 6.1052e-03, 4.6319e-04, 6.7724e-05, 1.9478e-05,\n",
      "        1.4231e-03, 1.5906e-01, 1.9323e-03, 5.1767e-03, 1.3636e-04, 3.6350e-04,\n",
      "        1.1745e-05, 2.1373e-03, 2.3547e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.2912e-07, 1.5101e-01, 4.5107e-02, 2.9954e-02, 1.4445e-02, 3.1020e-02,\n",
      "        5.1214e-02, 1.3392e-02, 4.3098e-02, 7.2040e-02, 2.8172e-03, 1.7866e-03,\n",
      "        1.8948e-02, 2.6209e-02, 1.6674e-02, 6.2039e-02, 4.2307e-02, 1.2967e-03,\n",
      "        1.7052e-02, 4.3531e-02, 2.4826e-01, 1.9652e-02, 4.5051e-03, 4.0134e-02,\n",
      "        1.8420e-05, 3.4231e-03, 6.4088e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.3091e-04, 1.0373e-02, 1.3788e-05, 9.7697e-07, 1.6847e-07, 1.1201e-02,\n",
      "        2.4457e-04, 4.9104e-06, 6.7639e-01, 9.6362e-03, 2.2394e-06, 2.0345e-05,\n",
      "        2.1399e-04, 2.1439e-05, 1.5806e-05, 2.7309e-01, 6.6858e-06, 7.1098e-06,\n",
      "        1.3981e-02, 4.9967e-05, 5.2956e-05, 2.4774e-03, 2.4747e-06, 5.9010e-04,\n",
      "        7.2829e-07, 1.4742e-03, 2.1113e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.8833e-04, 1.3697e-01, 2.9960e-06, 2.6189e-08, 1.0846e-06, 7.3374e-01,\n",
      "        2.5928e-06, 1.6223e-06, 2.4110e-05, 8.9108e-02, 2.6518e-06, 1.5938e-06,\n",
      "        4.9091e-05, 8.5572e-05, 1.5287e-04, 1.9200e-02, 4.1280e-06, 1.9383e-07,\n",
      "        1.4817e-02, 1.7733e-04, 2.7012e-05, 4.4096e-03, 2.2330e-07, 1.7162e-04,\n",
      "        2.9664e-06, 5.5352e-04, 1.1648e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.6106e-01, 2.9213e-04, 8.0299e-05, 1.3070e-05, 4.0967e-05, 1.3476e-03,\n",
      "        1.2723e-04, 3.6435e-04, 9.2382e-04, 5.6010e-02, 3.4523e-05, 1.7067e-04,\n",
      "        1.0501e-03, 5.3360e-02, 1.2523e-02, 4.2017e-04, 7.2320e-04, 4.1687e-06,\n",
      "        9.8371e-02, 1.4693e-02, 1.0202e-03, 3.2404e-05, 1.1582e-04, 8.2034e-04,\n",
      "        3.2559e-05, 9.6283e-02, 8.4218e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.2716e-06, 5.6259e-02, 3.5594e-02, 8.0009e-02, 6.1051e-02, 4.0000e-02,\n",
      "        4.4784e-02, 4.2545e-02, 4.2557e-02, 3.6861e-02, 5.5437e-03, 5.6295e-03,\n",
      "        4.7903e-02, 7.1438e-02, 2.2225e-02, 4.7649e-02, 7.5630e-02, 5.5762e-03,\n",
      "        4.8840e-02, 1.1355e-01, 3.1475e-02, 2.2255e-02, 2.2210e-02, 3.7974e-02,\n",
      "        4.1323e-05, 2.3379e-03, 5.3402e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.7523e-03, 1.2038e-01, 5.3812e-04, 4.1261e-02, 1.2252e-05, 1.7609e-01,\n",
      "        1.4453e-03, 1.2581e-03, 5.2420e-02, 5.5513e-02, 9.2952e-05, 1.6550e-02,\n",
      "        6.2070e-03, 4.5966e-03, 5.1024e-04, 8.2155e-02, 8.5646e-02, 2.3570e-03,\n",
      "        8.2576e-04, 7.9401e-04, 2.0812e-01, 1.1674e-01, 5.3554e-05, 3.8714e-03,\n",
      "        5.1028e-05, 1.8728e-02, 2.7766e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.2557e-04, 2.2189e-01, 7.6725e-05, 9.9281e-05, 6.7287e-06, 1.3968e-02,\n",
      "        6.8242e-04, 5.9415e-06, 4.6427e-03, 1.0469e-01, 7.8313e-05, 3.7397e-05,\n",
      "        1.4077e-04, 1.8258e-03, 3.2991e-05, 9.7368e-02, 4.6539e-04, 5.6118e-05,\n",
      "        5.1100e-01, 6.8634e-04, 7.8434e-05, 2.6597e-02, 1.8806e-04, 1.3705e-03,\n",
      "        4.7009e-05, 1.3589e-02, 4.9020e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.4759e-06, 1.4831e-01, 7.1963e-04, 6.0912e-04, 1.6137e-04, 3.6779e-01,\n",
      "        1.0390e-04, 7.7421e-04, 1.6015e-03, 9.6999e-02, 3.6221e-04, 3.9188e-04,\n",
      "        1.2110e-03, 1.3907e-03, 1.0792e-03, 2.1090e-01, 5.9962e-04, 6.3111e-05,\n",
      "        4.9113e-03, 2.6429e-05, 2.3846e-04, 1.5642e-01, 1.3753e-03, 1.1349e-04,\n",
      "        1.7322e-04, 3.5895e-03, 7.5973e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.6280e-05, 2.2948e-03, 8.2272e-03, 3.0723e-02, 7.1409e-03, 4.4709e-03,\n",
      "        7.6132e-03, 9.8160e-02, 3.2351e-04, 1.0408e-02, 9.1085e-04, 6.7274e-02,\n",
      "        2.5699e-03, 4.1909e-02, 5.9173e-01, 1.3088e-02, 1.7985e-02, 1.5956e-04,\n",
      "        7.5868e-03, 1.0393e-02, 8.9481e-03, 3.8461e-02, 1.8686e-02, 4.8347e-03,\n",
      "        2.3951e-03, 2.6352e-03, 9.7738e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.1699e-04, 1.8756e-03, 7.8614e-05, 8.5415e-03, 1.2625e-02, 8.5334e-03,\n",
      "        2.2944e-04, 9.2684e-01, 6.1580e-04, 4.4940e-03, 2.8075e-04, 1.4120e-02,\n",
      "        5.6912e-04, 6.7986e-05, 1.2507e-03, 1.8731e-03, 2.0864e-05, 1.6525e-04,\n",
      "        1.6325e-05, 6.3436e-03, 6.4042e-03, 1.6049e-03, 3.2445e-04, 9.9079e-05,\n",
      "        3.7590e-05, 2.0516e-03, 1.8031e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5547e-01, 3.5926e-02, 1.4385e-04, 3.3945e-05, 1.7625e-04, 5.1895e-01,\n",
      "        8.7810e-05, 3.8535e-04, 5.3478e-03, 1.4183e-02, 1.2414e-05, 1.6670e-05,\n",
      "        7.1306e-03, 1.2627e-03, 1.5300e-04, 2.7186e-03, 8.9406e-05, 1.2819e-05,\n",
      "        4.3416e-03, 4.3786e-02, 1.5072e-03, 6.6677e-03, 2.0984e-05, 5.7721e-04,\n",
      "        1.1158e-05, 9.6599e-04, 2.5473e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([5.7226e-04, 6.0579e-01, 1.0971e-03, 9.5288e-05, 5.4988e-04, 1.7450e-01,\n",
      "        6.6561e-04, 1.6604e-04, 1.9635e-04, 5.7866e-02, 1.3209e-05, 2.2456e-05,\n",
      "        1.7617e-04, 1.1861e-02, 9.2597e-04, 1.1313e-01, 7.6295e-05, 1.3026e-05,\n",
      "        2.4316e-03, 1.7133e-03, 7.0915e-04, 1.8891e-02, 2.0139e-04, 1.3772e-04,\n",
      "        1.7845e-05, 8.1616e-03, 1.7335e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.5811e-03, 4.7363e-04, 2.3546e-02, 7.1438e-02, 5.9123e-02, 3.2301e-04,\n",
      "        3.0711e-03, 1.7588e-01, 6.8318e-05, 4.3837e-02, 1.3887e-04, 7.6941e-04,\n",
      "        1.4513e-01, 1.7634e-02, 1.8001e-01, 2.6918e-04, 3.7094e-03, 3.7900e-05,\n",
      "        6.5622e-03, 1.0633e-01, 1.2795e-01, 1.9269e-02, 4.7842e-03, 1.0335e-03,\n",
      "        3.2459e-04, 3.9254e-03, 7.7222e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3187e-04, 2.6452e-02, 1.9374e-04, 2.4723e-04, 6.9638e-04, 8.7388e-01,\n",
      "        2.0531e-04, 4.7904e-04, 5.7557e-04, 6.2129e-02, 6.9038e-06, 8.2216e-05,\n",
      "        7.6776e-03, 4.0261e-04, 1.3042e-03, 1.1729e-02, 9.2294e-05, 2.2293e-05,\n",
      "        6.4261e-04, 4.7754e-03, 4.0372e-04, 2.7325e-03, 5.1257e-05, 3.1095e-05,\n",
      "        6.6825e-06, 4.8138e-03, 3.4783e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5378e-03, 4.5099e-04, 3.4593e-02, 4.1305e-02, 2.3942e-03, 2.8795e-04,\n",
      "        2.1515e-03, 1.8305e-03, 1.1589e-04, 3.0239e-01, 3.6509e-05, 3.9158e-04,\n",
      "        1.7286e-02, 7.3647e-03, 8.9086e-02, 1.2584e-03, 2.1910e-03, 9.9756e-05,\n",
      "        7.1121e-02, 1.0788e-02, 3.7494e-01, 8.1425e-03, 3.0038e-03, 2.8472e-04,\n",
      "        1.1982e-04, 2.5477e-02, 1.3494e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2362e-03, 1.7257e-01, 1.0776e-04, 5.4731e-03, 1.2529e-04, 4.1787e-01,\n",
      "        3.1441e-05, 5.4339e-05, 1.0902e-02, 2.7491e-01, 6.5167e-06, 3.2042e-03,\n",
      "        8.2400e-03, 8.9455e-05, 3.5739e-04, 9.7483e-03, 1.3645e-05, 2.6672e-04,\n",
      "        1.6917e-02, 1.9626e-03, 3.9816e-02, 2.0609e-02, 6.0743e-06, 6.0592e-05,\n",
      "        4.6017e-06, 1.5401e-02, 1.2722e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.0249e-01, 2.8189e-03, 1.2658e-04, 9.6083e-05, 3.9272e-02, 1.1393e-04,\n",
      "        2.0281e-04, 3.9085e-06, 1.7345e-06, 1.7091e-04, 9.4582e-07, 1.7605e-06,\n",
      "        2.4909e-03, 8.0491e-04, 8.9233e-04, 8.4820e-05, 5.1159e-05, 1.0562e-05,\n",
      "        3.4719e-03, 4.4530e-02, 1.7094e-03, 1.3031e-04, 1.2197e-04, 1.1599e-04,\n",
      "        2.8225e-05, 2.4941e-04, 4.7494e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.3735e-07, 1.9883e-01, 2.6531e-02, 1.9921e-02, 1.1387e-02, 2.1210e-02,\n",
      "        4.5233e-02, 3.0617e-03, 2.4276e-02, 7.7244e-02, 1.6553e-03, 8.1545e-04,\n",
      "        1.1092e-02, 1.7064e-02, 1.3649e-02, 2.3649e-01, 1.1844e-02, 1.6808e-03,\n",
      "        1.9362e-02, 3.8851e-02, 1.4448e-01, 1.7679e-02, 5.3359e-03, 4.8209e-02,\n",
      "        2.3102e-05, 4.0364e-03, 4.9169e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8147e-04, 1.3498e-02, 1.5295e-05, 1.1106e-06, 2.0581e-07, 9.1409e-03,\n",
      "        2.7024e-04, 3.9952e-06, 5.7964e-01, 6.4572e-03, 2.2772e-06, 2.1429e-05,\n",
      "        2.2379e-04, 2.6513e-05, 1.6760e-05, 3.7052e-01, 9.3113e-06, 7.6471e-06,\n",
      "        1.3969e-02, 5.6507e-05, 9.1498e-05, 3.5797e-03, 3.6675e-06, 6.0813e-04,\n",
      "        7.5879e-07, 1.6509e-03, 2.6794e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.6463e-01, 6.6374e-04, 4.2946e-05, 4.7495e-05, 1.0700e-03, 1.2654e-03,\n",
      "        3.1515e-04, 4.8776e-04, 4.9100e-04, 6.5200e-04, 1.1290e-05, 2.8901e-04,\n",
      "        7.9776e-04, 1.0572e-03, 1.0050e-03, 1.5103e-02, 4.6438e-05, 2.5490e-06,\n",
      "        2.1006e-03, 1.2082e-03, 8.6413e-05, 3.6295e-03, 2.3503e-04, 4.5717e-03,\n",
      "        1.7444e-04, 1.1365e-05, 1.7689e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.6145e-06, 6.2761e-02, 1.0538e-01, 3.7855e-02, 4.9721e-02, 1.9645e-02,\n",
      "        3.6665e-02, 2.4012e-02, 5.5578e-02, 2.7279e-02, 4.4130e-03, 3.7407e-03,\n",
      "        3.5859e-02, 4.8026e-02, 1.4194e-02, 1.8507e-02, 7.3135e-02, 2.3546e-03,\n",
      "        3.2981e-02, 9.6722e-02, 1.7747e-01, 1.0416e-02, 1.5962e-02, 4.3690e-02,\n",
      "        8.6204e-05, 3.5121e-03, 2.7037e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([5.1572e-06, 2.0009e-01, 7.9048e-06, 5.2168e-05, 1.2708e-05, 1.0062e-01,\n",
      "        5.3399e-05, 1.3197e-05, 8.6927e-02, 1.6273e-02, 1.1784e-05, 2.0007e-03,\n",
      "        4.6913e-02, 5.4322e-05, 4.9735e-05, 4.5184e-01, 6.1593e-05, 6.4915e-04,\n",
      "        5.8793e-02, 1.2758e-04, 1.1280e-03, 3.3038e-02, 3.4971e-05, 1.4981e-04,\n",
      "        2.8718e-05, 1.0684e-03, 2.4608e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.9676e-03, 3.6100e-04, 6.2652e-05, 2.4138e-04, 2.1539e-03, 2.3234e-04,\n",
      "        3.9228e-04, 1.5214e-03, 3.8544e-05, 4.9197e-04, 1.5491e-05, 4.7468e-04,\n",
      "        2.8386e-02, 3.2246e-01, 5.2253e-01, 5.7903e-04, 3.3610e-03, 2.1679e-04,\n",
      "        2.9247e-02, 7.4902e-03, 1.0992e-04, 6.6652e-02, 2.4249e-03, 6.1776e-03,\n",
      "        1.3959e-03, 1.0274e-05, 1.0228e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.8203e-03, 2.0383e-02, 7.5240e-03, 1.5404e-03, 7.8424e-04, 1.9099e-01,\n",
      "        1.0605e-03, 3.8498e-05, 2.6069e-05, 1.1400e-02, 1.8456e-04, 3.8749e-05,\n",
      "        7.4163e-05, 3.3306e-01, 4.9719e-03, 1.3669e-04, 4.0903e-01, 2.4368e-04,\n",
      "        1.8977e-03, 1.1101e-02, 1.1150e-03, 1.4702e-03, 2.9826e-04, 3.6565e-04,\n",
      "        3.4613e-05, 2.6468e-04, 1.5106e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.1281e-01, 2.7310e-02, 3.8393e-04, 3.7097e-03, 7.4027e-02, 1.2297e-04,\n",
      "        1.5419e-03, 5.6790e-05, 1.6673e-04, 3.8329e-04, 5.5389e-05, 1.2358e-04,\n",
      "        1.8162e-02, 3.4519e-03, 1.1366e-01, 3.7811e-04, 8.6239e-05, 1.9192e-03,\n",
      "        3.7214e-03, 2.0730e-01, 2.8072e-02, 1.4988e-05, 2.9958e-04, 1.6411e-03,\n",
      "        3.4032e-04, 2.3526e-04, 2.8728e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8522e-01, 5.9264e-02, 2.1254e-04, 1.1093e-01, 7.5288e-02, 4.4852e-02,\n",
      "        2.6436e-03, 2.8172e-03, 2.2472e-04, 3.8291e-03, 1.2310e-03, 6.7143e-04,\n",
      "        4.1915e-03, 3.2498e-04, 3.6834e-03, 1.7362e-02, 7.9169e-06, 1.7023e-03,\n",
      "        1.4243e-04, 8.1481e-03, 3.6683e-01, 1.8133e-03, 1.4697e-03, 1.7253e-03,\n",
      "        1.0014e-03, 3.4285e-03, 9.8734e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.1900e-01, 4.3320e-02, 6.0852e-05, 8.6560e-05, 9.8680e-05, 2.2365e-02,\n",
      "        2.3148e-03, 2.1314e-05, 2.0663e-03, 2.1383e-02, 1.6882e-05, 7.5241e-05,\n",
      "        1.8558e-02, 2.9309e-04, 1.5754e-05, 1.3230e-03, 3.4762e-05, 5.5447e-05,\n",
      "        4.3709e-04, 1.0752e-01, 3.1313e-03, 9.3980e-04, 4.8432e-05, 6.0658e-04,\n",
      "        1.0058e-05, 5.5880e-02, 3.4079e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "hough the cowardly creature always inwar <------ | ------> ds who being the strongragace to coment \n",
      "Epoch 8   Time 63.354    Train Loss: 1.326\n",
      "Softmaxed: tensor([4.3626e-03, 3.7266e-05, 1.4736e-03, 4.4359e-04, 6.9802e-04, 3.8786e-04,\n",
      "        8.3652e-04, 2.3014e-03, 3.8521e-04, 8.6939e-06, 1.2252e-05, 1.8313e-05,\n",
      "        8.1210e-03, 6.7138e-04, 1.2145e-02, 6.0304e-05, 2.1694e-04, 6.2656e-06,\n",
      "        9.5112e-01, 1.3544e-02, 5.7332e-04, 1.4266e-05, 1.7743e-03, 3.1251e-05,\n",
      "        1.5442e-05, 2.7028e-06, 7.3468e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.8666e-01, 1.7770e-04, 3.8961e-05, 1.3121e-04, 1.1196e-04, 5.6640e-03,\n",
      "        1.8160e-04, 1.4291e-05, 2.9309e-04, 2.5817e-04, 4.5929e-06, 1.2726e-05,\n",
      "        2.3897e-04, 1.6232e-03, 2.2634e-04, 3.6008e-04, 4.1050e-06, 3.6443e-06,\n",
      "        1.0911e-03, 2.6381e-03, 5.3356e-05, 4.0757e-06, 7.9562e-05, 5.6368e-05,\n",
      "        4.8336e-06, 5.3287e-05, 1.5599e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.7763e-06, 5.8384e-02, 4.1076e-02, 5.7134e-02, 5.5158e-02, 4.6827e-02,\n",
      "        7.2778e-02, 3.1838e-02, 3.6172e-02, 5.5428e-02, 1.0227e-02, 6.1084e-03,\n",
      "        2.8307e-02, 5.0456e-02, 4.4991e-02, 8.8693e-02, 6.4789e-02, 3.5137e-03,\n",
      "        3.4093e-02, 9.3200e-02, 1.6294e-02, 2.9316e-02, 2.2997e-02, 4.8879e-02,\n",
      "        5.8513e-05, 3.1417e-03, 1.3743e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.2175e-06, 2.5126e-01, 2.0221e-04, 4.1835e-06, 2.9103e-07, 2.1712e-01,\n",
      "        4.2274e-05, 5.0019e-06, 7.7307e-06, 3.9279e-01, 3.7124e-06, 2.9840e-07,\n",
      "        3.0810e-04, 5.8753e-05, 2.9250e-05, 7.4176e-02, 3.9413e-04, 2.0865e-06,\n",
      "        3.8678e-03, 1.4654e-04, 7.1404e-05, 4.3405e-02, 1.4741e-05, 2.8238e-04,\n",
      "        3.6075e-06, 1.5797e-02, 1.5352e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.5812e-04, 7.4768e-04, 9.2017e-04, 1.2416e-02, 2.1103e-02, 4.5273e-03,\n",
      "        2.1426e-03, 2.4623e-01, 4.5299e-05, 4.5107e-05, 1.7475e-05, 2.6486e-04,\n",
      "        1.2323e-02, 1.4693e-01, 2.5788e-02, 1.7355e-04, 6.5908e-03, 5.6059e-05,\n",
      "        1.2906e-02, 4.8993e-01, 1.4567e-02, 2.8186e-05, 8.9796e-04, 1.5143e-04,\n",
      "        6.7548e-04, 2.3921e-06, 6.3905e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.1599e-01, 2.5574e-04, 1.3216e-04, 1.5618e-02, 1.9442e-03, 6.1108e-02,\n",
      "        5.7136e-03, 3.0417e-03, 1.9423e-02, 4.9878e-03, 3.4950e-05, 1.0323e-02,\n",
      "        4.9882e-04, 4.5933e-03, 1.9848e-04, 2.5965e-04, 1.0522e-02, 5.0178e-05,\n",
      "        1.5688e-04, 5.5786e-02, 3.8805e-01, 2.8367e-04, 1.9591e-05, 9.1526e-04,\n",
      "        3.4643e-06, 2.1927e-05, 6.7573e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5232e-06, 6.5519e-02, 1.8232e-02, 4.8187e-02, 6.2819e-02, 3.3870e-02,\n",
      "        4.7006e-02, 1.2971e-02, 2.5790e-02, 6.9070e-02, 5.3563e-03, 2.2383e-03,\n",
      "        7.6207e-02, 8.4551e-02, 1.6933e-02, 1.2309e-01, 6.5935e-02, 2.6317e-03,\n",
      "        9.7839e-03, 7.2181e-02, 8.2999e-02, 1.8819e-02, 1.9946e-02, 3.4783e-02,\n",
      "        6.8815e-05, 9.6236e-04, 4.9571e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5159e-06, 3.0874e-01, 1.4400e-05, 9.2998e-07, 5.9167e-06, 7.3406e-02,\n",
      "        2.5293e-04, 3.1727e-05, 1.2060e-05, 3.1135e-01, 2.9113e-06, 2.6808e-05,\n",
      "        2.8236e-04, 4.6310e-06, 2.8027e-06, 2.8245e-01, 4.3912e-06, 5.5149e-06,\n",
      "        1.3136e-04, 2.4644e-05, 2.2154e-06, 2.0602e-02, 3.5722e-05, 2.4961e-04,\n",
      "        5.6190e-06, 2.3464e-03, 1.4388e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.6780e-03, 3.7126e-04, 6.0320e-02, 1.1656e-01, 3.6819e-03, 4.8117e-04,\n",
      "        1.4057e-02, 1.8022e-02, 5.3552e-05, 3.0082e-02, 1.4399e-03, 1.0549e-02,\n",
      "        4.9839e-03, 2.0924e-02, 3.9848e-02, 3.5123e-04, 8.5558e-03, 2.4245e-04,\n",
      "        1.1286e-02, 1.2801e-01, 3.9611e-01, 6.7190e-02, 1.2505e-02, 3.9190e-02,\n",
      "        2.5699e-03, 6.7826e-03, 2.1542e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.9278e-03, 1.0212e-03, 4.0009e-04, 1.9366e-03, 5.5901e-04, 6.7532e-01,\n",
      "        2.8465e-04, 1.1773e-03, 6.9425e-02, 2.6135e-02, 7.8161e-05, 3.6394e-03,\n",
      "        4.8084e-04, 9.8426e-05, 8.4116e-05, 8.4637e-03, 2.3031e-04, 1.1691e-04,\n",
      "        5.2837e-03, 1.7238e-03, 1.4351e-01, 3.9898e-02, 5.7272e-05, 2.7371e-03,\n",
      "        7.0969e-06, 1.5026e-02, 3.7200e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.7518e-04, 4.0626e-03, 9.3532e-06, 5.0652e-06, 7.5907e-05, 9.6341e-01,\n",
      "        4.1177e-06, 1.6183e-04, 2.3284e-04, 9.4657e-03, 4.0425e-06, 1.0464e-05,\n",
      "        8.2383e-03, 3.7330e-04, 2.6691e-04, 6.8493e-03, 1.7476e-05, 2.1121e-06,\n",
      "        1.3969e-03, 2.5732e-04, 5.0311e-05, 2.9922e-03, 4.7863e-06, 1.9296e-05,\n",
      "        9.6162e-06, 1.5063e-03, 1.3111e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.9945e-01, 3.4708e-03, 1.2257e-03, 7.2628e-03, 3.2248e-02, 9.7382e-03,\n",
      "        1.1899e-02, 7.6027e-05, 3.8591e-04, 1.2831e-03, 1.2642e-05, 3.2223e-04,\n",
      "        2.1881e-03, 1.8967e-02, 9.8060e-02, 7.1042e-04, 1.0721e-02, 1.2002e-04,\n",
      "        1.1520e-01, 2.5414e-01, 2.3760e-02, 3.0474e-04, 6.9326e-03, 6.4287e-04,\n",
      "        3.1516e-04, 5.2095e-04, 4.1981e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.6985e-01, 9.4807e-03, 1.3898e-04, 6.9014e-02, 1.5668e-02, 1.9341e-01,\n",
      "        1.3836e-03, 5.1400e-03, 1.7752e-04, 1.6591e-02, 8.2613e-05, 3.5591e-04,\n",
      "        6.3320e-03, 1.7654e-04, 2.6999e-03, 9.0092e-03, 1.3373e-04, 1.8545e-04,\n",
      "        1.4753e-04, 1.2543e-01, 5.3127e-02, 1.5888e-02, 5.2830e-04, 9.8116e-04,\n",
      "        1.2767e-04, 3.8613e-03, 7.8389e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.5878e-01, 5.9803e-02, 8.2145e-04, 8.5348e-05, 2.9730e-04, 1.2046e-01,\n",
      "        6.3721e-04, 1.3551e-03, 4.8557e-05, 2.8143e-01, 4.0376e-06, 1.1677e-05,\n",
      "        3.6998e-02, 9.2834e-03, 2.1224e-02, 3.1271e-02, 2.6328e-04, 1.7731e-05,\n",
      "        2.2709e-03, 9.4168e-02, 1.6195e-04, 5.1326e-02, 1.2393e-04, 1.8530e-04,\n",
      "        2.1680e-05, 2.8851e-02, 8.7623e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0718e-03, 5.0884e-02, 3.0767e-03, 3.2717e-02, 5.5683e-03, 5.1618e-03,\n",
      "        1.2967e-02, 1.5472e-03, 2.3649e-04, 1.9152e-04, 1.5076e-05, 1.1030e-04,\n",
      "        8.3716e-04, 2.2228e-03, 6.7126e-01, 5.7621e-03, 1.2217e-03, 2.3188e-04,\n",
      "        7.5051e-04, 3.2777e-02, 1.5731e-01, 4.6868e-04, 9.0762e-03, 1.0679e-04,\n",
      "        6.6506e-05, 3.1592e-05, 3.3287e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.8463e-03, 5.8137e-02, 1.0637e-05, 9.3784e-04, 8.3321e-04, 4.1086e-02,\n",
      "        8.2980e-05, 8.7584e-01, 2.4679e-05, 6.5643e-03, 1.0682e-05, 9.3913e-05,\n",
      "        8.0219e-04, 3.9428e-04, 5.8864e-04, 1.7711e-03, 2.4979e-06, 7.7041e-06,\n",
      "        1.2019e-05, 8.0677e-04, 1.2735e-03, 2.7775e-03, 5.0650e-05, 1.1002e-05,\n",
      "        3.2590e-05, 9.8760e-04, 1.0702e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.7045e-01, 2.0007e-04, 2.6661e-05, 1.0628e-06, 2.3388e-04, 7.3098e-03,\n",
      "        8.4967e-05, 9.4325e-05, 4.2388e-05, 3.5168e-04, 8.2550e-07, 1.7950e-07,\n",
      "        7.8955e-03, 3.4400e-04, 4.2421e-04, 3.7353e-04, 5.5506e-06, 5.5896e-07,\n",
      "        2.3361e-04, 1.0288e-02, 3.7183e-04, 1.1653e-03, 1.8115e-05, 2.8719e-05,\n",
      "        1.0819e-06, 5.1434e-05, 1.1764e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([2.3480e-07, 1.4557e-01, 2.2097e-02, 2.1959e-02, 1.4842e-02, 3.9227e-02,\n",
      "        3.4069e-02, 1.1720e-02, 3.2207e-02, 9.4646e-02, 1.7169e-03, 9.6956e-04,\n",
      "        1.0517e-02, 3.1352e-02, 8.7515e-03, 7.9676e-02, 3.3183e-02, 1.5205e-03,\n",
      "        9.9890e-03, 3.2910e-02, 3.1484e-01, 1.3289e-02, 4.4471e-03, 3.7414e-02,\n",
      "        1.4457e-05, 3.0159e-03, 5.6433e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.8713e-05, 1.0425e-01, 4.5367e-05, 4.3479e-06, 1.4559e-06, 9.3784e-02,\n",
      "        1.1950e-04, 1.3564e-05, 9.9800e-02, 2.8268e-02, 8.0193e-06, 1.7083e-06,\n",
      "        8.6355e-02, 2.2495e-05, 8.6780e-05, 1.3914e-01, 3.2622e-03, 1.6850e-05,\n",
      "        3.3561e-01, 1.4007e-03, 8.1624e-04, 1.0511e-01, 2.6508e-05, 8.0674e-04,\n",
      "        4.2616e-05, 9.6406e-04, 4.3476e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.0765e-07, 2.3629e-02, 1.6004e-05, 3.1485e-05, 9.4791e-06, 2.1853e-01,\n",
      "        1.1731e-05, 7.7291e-07, 3.0530e-05, 1.4175e-01, 1.6429e-05, 1.9015e-07,\n",
      "        2.7412e-05, 8.8420e-06, 7.1650e-06, 6.0926e-01, 2.6630e-06, 1.5625e-06,\n",
      "        1.4251e-04, 5.9603e-05, 6.1089e-05, 2.2740e-03, 5.8903e-05, 1.4543e-04,\n",
      "        1.0145e-05, 3.9144e-03, 2.5556e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.0464e-05, 1.1696e-03, 9.7801e-02, 6.9456e-02, 7.1246e-02, 5.4548e-03,\n",
      "        6.9048e-02, 1.9910e-02, 1.3682e-04, 1.8917e-03, 2.1315e-03, 2.5722e-03,\n",
      "        5.5354e-03, 1.1226e-01, 7.9018e-03, 4.3228e-02, 2.4379e-01, 3.1105e-04,\n",
      "        2.3853e-03, 5.6215e-02, 3.7217e-02, 3.6494e-02, 5.2395e-02, 5.3274e-02,\n",
      "        4.1190e-03, 2.6560e-03, 1.3335e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7601e-04, 4.3110e-02, 6.7925e-04, 2.8708e-04, 4.2956e-04, 4.7720e-01,\n",
      "        5.5061e-05, 1.9010e-04, 1.1914e-02, 6.7932e-02, 7.8634e-04, 2.7336e-04,\n",
      "        1.3957e-02, 2.1273e-03, 8.0013e-05, 2.2440e-01, 3.9257e-03, 2.9790e-05,\n",
      "        9.0216e-02, 2.3560e-02, 3.2696e-03, 3.1180e-02, 2.2253e-05, 1.6815e-03,\n",
      "        1.4788e-04, 1.5580e-03, 1.9261e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.5359e-03, 2.5734e-03, 2.5580e-03, 7.6117e-03, 2.7728e-02, 1.0107e-03,\n",
      "        9.4864e-04, 6.3993e-05, 2.8936e-04, 1.1409e-03, 3.5812e-05, 4.4323e-06,\n",
      "        9.5308e-03, 2.7483e-03, 1.3090e-02, 1.4925e-03, 5.9114e-03, 1.3069e-04,\n",
      "        8.6504e-01, 3.2056e-02, 2.1692e-02, 4.5649e-05, 7.2218e-04, 6.9671e-04,\n",
      "        2.9356e-04, 3.4029e-05, 1.6444e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.9022e-02, 5.1266e-02, 1.1776e-03, 7.1033e-03, 7.7792e-03, 3.2656e-02,\n",
      "        2.6819e-02, 6.9072e-04, 6.3029e-03, 2.3452e-01, 3.8320e-05, 4.3130e-05,\n",
      "        2.1508e-02, 1.7748e-02, 1.2390e-01, 1.5077e-02, 5.1739e-03, 5.6566e-05,\n",
      "        7.8039e-03, 2.9164e-01, 7.9076e-02, 4.9299e-04, 9.8015e-03, 1.0642e-03,\n",
      "        1.0560e-04, 9.1037e-03, 3.4058e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.4152e-03, 1.3106e-01, 1.8575e-03, 2.5277e-04, 1.8227e-04, 2.5146e-02,\n",
      "        5.8037e-04, 6.2202e-05, 2.7989e-02, 3.7537e-02, 3.3518e-05, 6.3596e-06,\n",
      "        1.0393e-01, 4.7100e-03, 1.9664e-03, 1.8732e-01, 3.9882e-03, 1.2933e-05,\n",
      "        2.8668e-01, 2.4349e-02, 6.8036e-02, 8.6209e-02, 3.5966e-05, 1.0679e-04,\n",
      "        8.2879e-05, 4.4376e-04, 1.2220e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.5745e-05, 1.6816e-01, 4.2799e-05, 9.2287e-05, 5.2760e-05, 5.3836e-01,\n",
      "        2.7665e-05, 6.1889e-06, 3.5684e-05, 1.9416e-01, 1.5778e-06, 1.7296e-07,\n",
      "        1.7704e-03, 1.0212e-03, 2.4606e-04, 9.0569e-02, 2.4627e-06, 7.5584e-07,\n",
      "        1.9034e-04, 4.5506e-04, 4.2498e-04, 2.8048e-03, 9.6260e-06, 7.0815e-06,\n",
      "        3.8353e-06, 1.4604e-03, 3.4248e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.7622e-03, 5.4100e-02, 8.9386e-04, 4.9001e-02, 1.2136e-01, 1.1414e-02,\n",
      "        2.0929e-03, 2.9735e-03, 1.6083e-03, 1.1568e-03, 3.4009e-05, 4.0135e-04,\n",
      "        1.1628e-02, 2.7858e-02, 1.0255e-01, 5.4043e-04, 7.1327e-03, 1.6028e-04,\n",
      "        1.4642e-02, 1.2312e-01, 4.5737e-01, 7.6977e-04, 9.9839e-04, 2.3049e-03,\n",
      "        9.1788e-05, 2.6769e-05, 1.2809e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.1303e-02, 1.7929e-02, 1.0600e-04, 2.3323e-01, 4.3573e-03, 5.0647e-01,\n",
      "        7.1103e-04, 1.0719e-02, 5.0685e-05, 1.8979e-02, 3.1282e-05, 7.4120e-05,\n",
      "        2.8188e-03, 2.5074e-04, 2.3868e-04, 3.2982e-03, 6.0867e-05, 1.8100e-04,\n",
      "        1.1767e-05, 2.5942e-02, 1.5040e-01, 2.3311e-03, 1.2206e-04, 2.3896e-04,\n",
      "        1.6023e-05, 1.2205e-04, 7.3552e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.5724e-04, 1.9188e-02, 2.4491e-05, 8.0974e-05, 1.7087e-05, 8.0355e-01,\n",
      "        1.9151e-05, 5.3044e-05, 5.8554e-03, 7.3765e-02, 6.2900e-07, 4.6272e-05,\n",
      "        3.0267e-03, 1.2081e-04, 4.3964e-05, 5.0521e-04, 1.1955e-05, 2.7782e-05,\n",
      "        2.1039e-02, 7.6923e-03, 2.1998e-02, 6.8091e-03, 2.9312e-06, 2.9191e-05,\n",
      "        1.4932e-06, 3.5808e-02, 2.4484e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.1403e-01, 4.3287e-04, 2.4336e-04, 1.3768e-05, 5.0212e-02, 2.4982e-05,\n",
      "        1.0371e-03, 2.3158e-05, 8.4251e-07, 5.3046e-05, 4.2246e-07, 3.2402e-07,\n",
      "        1.0321e-03, 7.4297e-04, 9.9684e-04, 3.4822e-05, 4.3141e-05, 3.4261e-06,\n",
      "        1.0013e-03, 2.9240e-02, 4.8517e-04, 2.3578e-05, 1.6811e-04, 3.4662e-05,\n",
      "        1.0439e-05, 1.0799e-04, 1.0900e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.0074e-07, 1.6307e-01, 1.8811e-02, 1.7179e-02, 1.5782e-02, 1.5240e-02,\n",
      "        4.3218e-02, 3.6544e-03, 3.2768e-02, 9.5144e-02, 1.5868e-03, 9.3894e-04,\n",
      "        6.5510e-03, 1.9031e-02, 9.7395e-03, 1.9431e-01, 1.1296e-02, 1.6610e-03,\n",
      "        8.7474e-03, 3.4354e-02, 2.1717e-01, 1.4289e-02, 5.9295e-03, 6.4515e-02,\n",
      "        1.9617e-05, 4.9471e-03, 5.2002e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.9200e-06, 2.0668e-01, 3.6094e-06, 1.0213e-05, 2.3226e-06, 6.1653e-02,\n",
      "        6.4590e-05, 4.0098e-06, 6.5721e-02, 3.1443e-02, 6.3058e-06, 3.0578e-04,\n",
      "        5.9328e-02, 1.5000e-05, 4.0098e-05, 4.7621e-01, 3.8513e-05, 4.1989e-04,\n",
      "        6.1653e-02, 1.2042e-04, 7.9322e-04, 3.3043e-02, 2.9800e-05, 1.0508e-04,\n",
      "        1.5345e-05, 2.2929e-03, 1.1626e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.4513e-03, 2.4502e-04, 4.4674e-05, 1.4389e-04, 1.7811e-03, 2.3837e-04,\n",
      "        3.5662e-04, 8.3661e-04, 3.7357e-05, 7.1796e-04, 1.9458e-05, 4.0938e-04,\n",
      "        3.5605e-02, 1.4338e-01, 5.3960e-01, 5.3053e-04, 2.5404e-03, 1.5723e-04,\n",
      "        7.1921e-02, 5.4627e-03, 1.1991e-04, 1.7850e-01, 5.2528e-03, 8.2744e-03,\n",
      "        1.3480e-03, 1.9733e-05, 7.2006e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.5231e-03, 1.1072e-03, 6.7908e-04, 2.4407e-01, 5.1118e-02, 1.8468e-02,\n",
      "        4.5351e-02, 8.3292e-03, 2.0723e-04, 5.7131e-03, 7.8257e-03, 2.9923e-04,\n",
      "        7.1368e-03, 2.6194e-03, 1.3334e-02, 5.2526e-04, 2.7645e-03, 8.5962e-03,\n",
      "        6.4939e-04, 3.1367e-01, 2.3611e-01, 1.8106e-03, 1.6679e-02, 2.5808e-03,\n",
      "        4.6506e-04, 3.2734e-04, 3.6032e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.4759e-04, 5.1962e-02, 1.9118e-04, 1.6144e-04, 6.6133e-06, 4.0619e-01,\n",
      "        6.6105e-04, 4.8924e-06, 1.2700e-02, 1.0030e-01, 1.7487e-05, 4.9207e-06,\n",
      "        2.2745e-02, 5.8536e-04, 5.8535e-05, 4.9556e-03, 7.5598e-05, 3.5195e-05,\n",
      "        3.4918e-01, 2.4695e-03, 1.5795e-03, 4.1608e-02, 8.8717e-05, 7.7187e-04,\n",
      "        2.1025e-06, 3.0459e-03, 4.9907e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.9987e-01, 1.6133e-03, 2.4569e-04, 3.3876e-04, 2.4123e-04, 4.0812e-03,\n",
      "        4.0348e-04, 3.8953e-05, 4.4313e-06, 1.7294e-02, 5.6917e-06, 2.3763e-05,\n",
      "        6.4920e-03, 2.0459e-02, 1.6535e-02, 3.6556e-03, 1.6098e-03, 1.4330e-05,\n",
      "        6.6159e-03, 2.6661e-03, 2.5302e-03, 1.5164e-02, 3.9443e-05, 2.0465e-05,\n",
      "        1.9032e-05, 1.3606e-05, 3.9866e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.0561e-02, 2.3141e-01, 7.0846e-05, 4.3589e-02, 1.2647e-02, 2.6591e-01,\n",
      "        1.6224e-03, 3.7596e-03, 2.0995e-04, 2.1558e-01, 2.9235e-04, 1.0780e-04,\n",
      "        3.9116e-03, 1.4278e-03, 4.3663e-03, 2.7415e-02, 1.6444e-04, 2.4396e-04,\n",
      "        2.7546e-04, 3.0759e-02, 6.5579e-02, 4.5669e-02, 2.5811e-03, 1.7696e-03,\n",
      "        1.8198e-04, 9.8876e-03, 1.1236e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.1267e-03, 2.5450e-04, 2.1889e-02, 1.2637e-02, 1.9014e-02, 2.5270e-05,\n",
      "        1.3035e-03, 2.1480e-03, 1.4840e-05, 8.3948e-03, 6.3438e-05, 7.8066e-05,\n",
      "        1.5020e-01, 2.1780e-02, 7.6596e-02, 3.1837e-05, 1.0641e-02, 4.9906e-05,\n",
      "        7.5575e-02, 4.9952e-03, 5.6859e-01, 1.2210e-02, 8.8904e-03, 3.0613e-04,\n",
      "        1.7606e-04, 1.2913e-03, 7.1877e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2911e-03, 2.6353e-03, 1.0607e-04, 8.5128e-05, 6.4573e-06, 2.9492e-01,\n",
      "        7.7393e-05, 2.7757e-06, 3.8094e-03, 6.7968e-01, 9.7060e-07, 4.7106e-06,\n",
      "        2.1730e-04, 1.0141e-04, 2.3044e-04, 3.2437e-03, 3.2089e-05, 2.6958e-05,\n",
      "        2.3261e-03, 1.6526e-03, 9.7713e-04, 1.9125e-03, 6.5074e-06, 7.8805e-05,\n",
      "        2.0586e-07, 6.5353e-03, 4.0064e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.6542e-03, 9.6978e-03, 5.3983e-03, 4.9260e-02, 4.3801e-03, 1.1861e-02,\n",
      "        7.5933e-03, 1.4759e-04, 4.5000e-05, 2.0110e-04, 4.3764e-06, 2.7745e-05,\n",
      "        4.8474e-03, 1.3772e-03, 4.5154e-02, 7.6415e-01, 3.9212e-04, 2.1864e-04,\n",
      "        5.5422e-04, 7.8675e-03, 1.2996e-02, 1.4652e-04, 6.9940e-02, 1.2304e-04,\n",
      "        4.3760e-05, 1.8458e-05, 8.9957e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "ics of conscience who prefer to put thei <------ | ------> r his latgending properprence contynatio\n",
      "Epoch 9   Time 63.274    Train Loss: 1.307\n",
      "Softmaxed: tensor([3.3610e-07, 1.3561e-01, 3.9705e-02, 1.7323e-02, 3.7299e-02, 2.3027e-02,\n",
      "        3.6991e-02, 8.9913e-03, 2.6976e-02, 9.0910e-02, 1.7691e-03, 8.5196e-04,\n",
      "        1.3488e-02, 2.2569e-02, 1.8689e-02, 1.7377e-01, 1.8185e-02, 1.1112e-03,\n",
      "        2.1100e-02, 2.8523e-02, 2.2769e-01, 1.4810e-02, 3.5730e-03, 3.5317e-02,\n",
      "        1.4083e-05, 1.6184e-03, 8.6602e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.0759e-04, 5.9003e-05, 1.2595e-02, 3.1502e-03, 6.4233e-04, 2.2277e-04,\n",
      "        7.3110e-01, 5.1315e-04, 1.0992e-04, 8.6269e-05, 5.8432e-05, 4.4548e-05,\n",
      "        5.9549e-03, 4.8290e-04, 7.0609e-02, 5.0049e-04, 1.8244e-02, 6.9757e-05,\n",
      "        9.6734e-02, 4.6660e-05, 1.2103e-02, 2.8594e-02, 1.0056e-02, 7.8566e-03,\n",
      "        4.5951e-05, 6.8545e-06, 5.0927e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9089e-01, 3.9334e-05, 2.1822e-05, 1.5516e-04, 6.8088e-05, 5.8317e-04,\n",
      "        3.0602e-03, 8.5352e-06, 6.0068e-06, 3.1376e-05, 3.4910e-05, 8.4609e-06,\n",
      "        8.2841e-04, 2.7376e-04, 3.8159e-06, 3.1992e-05, 1.2978e-04, 8.5787e-06,\n",
      "        1.4660e-04, 1.7293e-05, 3.4209e-03, 1.7312e-05, 1.1401e-04, 7.0995e-05,\n",
      "        1.5460e-06, 2.2194e-05, 1.5128e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.1815e-07, 9.8091e-02, 1.2609e-02, 3.5551e-02, 4.6514e-02, 5.4524e-02,\n",
      "        2.6892e-02, 2.7791e-02, 5.1254e-02, 3.7818e-02, 7.6030e-03, 5.6787e-03,\n",
      "        2.1853e-02, 5.7796e-02, 2.4332e-02, 3.1045e-02, 3.3149e-02, 1.1547e-03,\n",
      "        4.3799e-02, 6.3555e-02, 2.6659e-01, 3.1676e-03, 1.4884e-02, 2.9504e-02,\n",
      "        6.3434e-05, 4.6436e-03, 1.3098e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.6297e-05, 6.8556e-03, 4.6678e-06, 2.2171e-07, 7.0011e-08, 2.5393e-03,\n",
      "        4.8967e-05, 5.9017e-06, 9.5033e-01, 3.4171e-03, 7.9845e-07, 1.8920e-05,\n",
      "        4.3685e-04, 1.6125e-05, 3.1812e-06, 9.0046e-03, 1.5637e-06, 2.0816e-06,\n",
      "        2.4631e-02, 9.9808e-06, 1.9961e-05, 1.0173e-03, 1.7893e-06, 9.1444e-04,\n",
      "        4.1926e-07, 6.9498e-04, 2.7384e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.1185e-05, 1.7970e-02, 5.9206e-07, 5.1985e-09, 1.2373e-07, 8.7392e-01,\n",
      "        6.8065e-07, 2.0126e-07, 1.2443e-05, 8.8307e-02, 7.1726e-07, 4.9487e-07,\n",
      "        1.3999e-05, 8.2535e-06, 1.9856e-05, 1.5451e-02, 8.8741e-07, 3.9206e-08,\n",
      "        2.8839e-03, 6.6214e-06, 9.0192e-06, 1.0051e-03, 3.0304e-08, 2.4742e-05,\n",
      "        1.8178e-07, 3.4851e-04, 2.2701e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.1543e-01, 5.5475e-05, 1.0564e-05, 2.7792e-06, 2.4968e-06, 1.4540e-03,\n",
      "        7.9161e-05, 1.0117e-04, 5.5619e-04, 4.7298e-02, 1.7309e-05, 8.6752e-06,\n",
      "        4.7457e-04, 8.1057e-03, 2.2129e-03, 9.7607e-05, 2.0081e-04, 1.1181e-06,\n",
      "        4.1157e-03, 1.2873e-02, 1.4247e-04, 4.4877e-06, 3.6404e-05, 5.3413e-04,\n",
      "        5.9594e-06, 6.1499e-03, 3.4399e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9281e-01, 8.3881e-06, 1.3776e-04, 7.0690e-05, 3.2429e-05, 4.3835e-04,\n",
      "        6.2515e-05, 1.1087e-04, 7.6446e-05, 1.8012e-04, 4.1768e-06, 1.6913e-04,\n",
      "        5.5611e-04, 3.5201e-04, 9.3113e-05, 1.4615e-04, 8.4122e-05, 1.1931e-06,\n",
      "        1.3793e-03, 2.5248e-03, 5.8576e-04, 8.4179e-06, 4.9340e-05, 7.9409e-05,\n",
      "        1.0347e-06, 4.9983e-06, 3.0327e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.4123e-06, 1.7492e-01, 1.8498e-02, 7.2662e-02, 9.9364e-03, 1.0963e-01,\n",
      "        2.0430e-02, 7.9087e-03, 1.2037e-01, 6.6387e-02, 5.4228e-03, 1.1246e-02,\n",
      "        3.0292e-02, 4.3900e-02, 2.0518e-02, 2.5520e-02, 2.1858e-02, 1.2764e-03,\n",
      "        5.6207e-02, 6.9598e-02, 1.2368e-02, 8.0158e-03, 7.4848e-03, 8.2985e-02,\n",
      "        2.4301e-05, 2.5039e-03, 3.2899e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1075e-02, 2.1777e-01, 1.1719e-04, 1.6344e-02, 4.9511e-06, 2.8851e-01,\n",
      "        5.0900e-04, 3.1585e-04, 8.8863e-02, 1.7514e-02, 6.1179e-05, 1.1363e-02,\n",
      "        4.6408e-03, 4.9475e-03, 3.6364e-04, 9.6032e-02, 3.6885e-02, 9.4227e-04,\n",
      "        5.1596e-04, 2.4520e-04, 4.7832e-02, 9.7875e-02, 3.7544e-05, 4.1301e-03,\n",
      "        3.0335e-05, 5.3056e-02, 1.3188e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.7063e-04, 3.4281e-01, 4.5564e-05, 1.0135e-04, 9.5628e-06, 3.0388e-02,\n",
      "        8.1895e-04, 6.8272e-06, 1.8895e-03, 1.4039e-01, 6.3151e-05, 2.1580e-05,\n",
      "        2.4880e-04, 1.8439e-03, 4.1303e-05, 9.3886e-02, 2.1719e-04, 4.9282e-05,\n",
      "        3.0916e-01, 4.6909e-04, 6.3931e-05, 4.6231e-02, 2.6385e-04, 9.6928e-04,\n",
      "        3.7587e-05, 2.9338e-02, 5.4791e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.8513e-05, 1.8355e-04, 1.4588e-02, 1.7691e-02, 1.8259e-02, 2.2256e-03,\n",
      "        1.1475e-03, 2.1957e-02, 6.1582e-05, 2.9375e-02, 1.0404e-04, 1.0143e-02,\n",
      "        6.7875e-02, 1.0278e-02, 3.6930e-01, 1.6913e-04, 2.0601e-02, 4.6549e-05,\n",
      "        2.9856e-02, 6.4949e-03, 3.7240e-01, 6.4553e-04, 2.2724e-03, 8.9789e-04,\n",
      "        1.2121e-04, 1.9109e-03, 1.3304e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.5825e-02, 3.7368e-02, 1.0871e-03, 1.9978e-04, 1.0887e-01, 3.4189e-01,\n",
      "        6.1582e-03, 8.1684e-04, 1.2758e-03, 2.6926e-01, 8.8873e-05, 1.5476e-03,\n",
      "        1.6266e-02, 4.2557e-03, 2.6718e-02, 2.1964e-02, 3.0947e-04, 1.8920e-04,\n",
      "        2.0602e-03, 5.4126e-02, 6.1555e-04, 3.1628e-03, 4.4002e-04, 3.9416e-04,\n",
      "        7.7637e-05, 4.9626e-03, 6.5241e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.0770e-01, 7.2378e-03, 4.9072e-04, 3.7083e-03, 2.9217e-01, 6.3559e-04,\n",
      "        1.3050e-02, 8.5331e-05, 7.1301e-05, 4.2997e-04, 6.4411e-06, 3.8674e-05,\n",
      "        1.4712e-04, 2.9840e-03, 1.4736e-01, 1.3274e-04, 1.2919e-03, 1.0365e-04,\n",
      "        8.0732e-03, 1.0928e-01, 3.0094e-03, 1.6763e-05, 1.3133e-03, 1.5787e-04,\n",
      "        1.8180e-04, 3.0046e-04, 3.0882e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([3.8747e-07, 1.4858e-01, 2.6325e-02, 1.8122e-02, 1.4522e-02, 1.0235e-02,\n",
      "        4.6313e-02, 3.3727e-03, 2.4205e-02, 6.9357e-02, 1.2521e-03, 6.7296e-04,\n",
      "        4.0603e-03, 1.4759e-02, 1.7065e-02, 2.8494e-01, 1.0652e-02, 7.7284e-04,\n",
      "        1.8261e-02, 4.2290e-02, 1.6532e-01, 1.0324e-02, 4.1131e-03, 6.1931e-02,\n",
      "        1.5730e-05, 2.4843e-03, 5.5883e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.1340e-04, 8.0067e-02, 5.1694e-05, 2.0117e-05, 1.6669e-05, 1.7467e-01,\n",
      "        1.2921e-04, 8.0735e-05, 6.2829e-04, 2.7036e-01, 1.6228e-05, 2.7453e-06,\n",
      "        3.4827e-03, 3.3582e-04, 4.0525e-04, 3.6314e-01, 2.9357e-05, 1.2445e-05,\n",
      "        6.7022e-02, 1.6913e-04, 3.0642e-05, 3.7915e-02, 8.5767e-05, 6.9045e-04,\n",
      "        1.4991e-05, 3.1250e-04, 6.2711e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.3129e-05, 4.6022e-03, 1.9408e-03, 4.2270e-03, 1.0560e-01, 3.6627e-02,\n",
      "        5.1781e-02, 3.9375e-02, 3.3051e-05, 1.7835e-04, 2.3806e-04, 1.4254e-04,\n",
      "        6.7061e-03, 1.3967e-02, 2.3137e-02, 3.0214e-03, 5.5528e-03, 5.1022e-04,\n",
      "        1.7482e-02, 6.1157e-01, 1.1030e-02, 3.5133e-04, 5.5597e-02, 2.1777e-04,\n",
      "        5.0086e-03, 1.4492e-04, 8.7868e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.7504e-02, 1.6180e-02, 4.5274e-03, 2.0315e-01, 6.1811e-04, 5.3837e-02,\n",
      "        2.8098e-02, 6.4894e-02, 1.6201e-02, 1.8132e-02, 3.5002e-04, 3.1621e-03,\n",
      "        2.6722e-03, 7.7535e-03, 6.1820e-03, 4.3024e-03, 1.1555e-01, 2.2688e-03,\n",
      "        2.0423e-03, 2.9023e-02, 3.8864e-01, 1.1635e-02, 1.3412e-04, 1.2592e-03,\n",
      "        7.8771e-05, 1.4972e-03, 3.1258e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.4696e-03, 8.8174e-03, 2.9730e-03, 6.1073e-03, 3.7010e-02, 1.3690e-04,\n",
      "        5.2379e-02, 4.6701e-03, 1.1386e-04, 3.3619e-04, 5.5955e-05, 1.0061e-05,\n",
      "        2.9020e-02, 1.2973e-02, 4.1456e-01, 1.0601e-03, 3.6232e-03, 2.3382e-02,\n",
      "        2.8269e-01, 8.1301e-02, 1.3270e-02, 1.5375e-04, 1.4756e-02, 8.8161e-04,\n",
      "        3.4999e-03, 6.9020e-04, 6.3354e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.0243e-02, 2.4670e-03, 6.7246e-05, 5.3033e-03, 1.9782e-02, 1.1037e-03,\n",
      "        1.0138e-02, 1.0880e-03, 6.5621e-04, 5.8785e-04, 1.6457e-04, 6.6546e-04,\n",
      "        1.4397e-03, 2.5274e-05, 2.8579e-04, 6.6836e-04, 3.1318e-05, 4.8064e-04,\n",
      "        7.2413e-05, 9.9335e-02, 7.7217e-01, 7.7620e-04, 9.8904e-04, 2.2026e-04,\n",
      "        4.8948e-05, 1.0453e-03, 1.4736e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.7294e-01, 1.3393e-02, 2.5283e-05, 2.1083e-06, 2.9112e-06, 1.0218e-02,\n",
      "        2.9752e-04, 5.6077e-06, 3.2724e-04, 7.2353e-02, 9.7183e-07, 1.0073e-06,\n",
      "        4.5376e-03, 9.1904e-04, 1.1836e-05, 5.6117e-04, 2.0663e-05, 1.4898e-06,\n",
      "        2.5779e-04, 7.5670e-03, 1.4793e-04, 5.1432e-03, 2.3769e-06, 5.0754e-04,\n",
      "        5.6064e-07, 1.0749e-02, 9.0570e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.5594e-07, 1.8241e-01, 4.8093e-02, 1.6734e-02, 3.5491e-02, 3.3283e-02,\n",
      "        2.7215e-02, 1.9387e-02, 5.3936e-02, 1.2011e-01, 2.3220e-03, 2.0928e-03,\n",
      "        9.7119e-03, 3.2534e-02, 9.8543e-03, 1.1404e-01, 3.0178e-02, 7.1826e-04,\n",
      "        1.6726e-02, 4.2663e-02, 1.2031e-01, 1.5746e-02, 2.5164e-03, 6.1556e-02,\n",
      "        9.3360e-06, 2.3242e-03, 4.1952e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.0578e-04, 7.7817e-02, 2.8569e-05, 4.0240e-05, 8.3888e-08, 4.6229e-02,\n",
      "        4.0229e-04, 5.2582e-07, 4.9571e-05, 5.2883e-02, 2.9060e-06, 1.4390e-07,\n",
      "        9.5821e-03, 4.8690e-06, 7.4888e-06, 5.9907e-01, 4.3333e-06, 1.1366e-05,\n",
      "        1.8848e-01, 8.7737e-07, 1.1372e-04, 2.4611e-02, 4.9826e-05, 1.9701e-04,\n",
      "        1.7306e-05, 8.8156e-05, 1.8475e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2967e-04, 2.1947e-04, 7.1556e-05, 1.2958e-03, 9.9932e-06, 1.9488e-03,\n",
      "        4.3476e-05, 2.5379e-05, 1.1921e-04, 1.9417e-04, 3.7157e-06, 1.1012e-05,\n",
      "        2.9204e-02, 2.6166e-04, 1.5545e-03, 2.8464e-02, 1.2978e-05, 4.5640e-06,\n",
      "        9.2081e-01, 4.6167e-06, 7.0929e-04, 1.4490e-02, 7.1031e-05, 2.4423e-04,\n",
      "        5.5655e-05, 4.2746e-05, 1.0118e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.4889e-02, 4.5117e-03, 2.7355e-05, 1.1527e-02, 3.4590e-03, 8.0468e-02,\n",
      "        5.5018e-06, 1.3289e-04, 6.7182e-03, 4.5522e-03, 6.4904e-05, 4.6304e-03,\n",
      "        2.3341e-01, 3.2148e-04, 1.0924e-03, 5.2093e-03, 1.2515e-05, 6.3236e-04,\n",
      "        7.1980e-02, 3.4483e-03, 5.5164e-01, 1.0506e-03, 1.4998e-05, 6.2596e-05,\n",
      "        2.9559e-05, 9.6665e-05, 9.1529e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5256e-02, 1.0184e-02, 3.6358e-05, 8.8573e-06, 7.0720e-05, 7.4085e-01,\n",
      "        1.9622e-04, 5.3716e-06, 4.7659e-06, 8.9262e-02, 5.8385e-06, 3.9242e-06,\n",
      "        1.4972e-02, 1.4927e-03, 4.4898e-04, 6.3903e-02, 5.0754e-05, 6.7821e-06,\n",
      "        3.2520e-04, 2.4187e-02, 3.6560e-04, 1.3180e-02, 2.2785e-03, 7.0176e-04,\n",
      "        2.6533e-05, 2.1669e-03, 8.0701e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.7238e-01, 9.0329e-03, 3.2095e-04, 9.3060e-03, 1.7376e-01, 3.1519e-02,\n",
      "        6.4326e-03, 6.0074e-03, 9.7834e-05, 2.5341e-03, 6.3069e-05, 4.0770e-04,\n",
      "        6.9134e-04, 8.2417e-03, 3.1681e-02, 4.1484e-04, 5.6900e-04, 2.0495e-04,\n",
      "        9.3647e-03, 3.2613e-01, 2.7744e-03, 1.6977e-04, 4.1841e-03, 2.0839e-03,\n",
      "        2.6884e-04, 1.2397e-03, 1.2080e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.4861e-01, 4.6253e-03, 3.7127e-04, 2.2471e-03, 9.2494e-06, 3.3810e-02,\n",
      "        2.7278e-02, 4.3612e-04, 1.2589e-02, 9.9186e-02, 3.0076e-06, 3.7701e-04,\n",
      "        4.0581e-05, 4.1104e-03, 2.0829e-04, 8.8598e-03, 1.1047e-02, 3.9090e-05,\n",
      "        8.0113e-04, 1.8150e-01, 2.6131e-01, 3.0148e-04, 4.5048e-05, 1.7742e-03,\n",
      "        1.3301e-06, 3.6412e-04, 6.2585e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.5784e-03, 1.3333e-03, 1.9607e-03, 1.0748e-03, 7.4115e-03, 1.3410e-03,\n",
      "        1.7124e-03, 1.3567e-03, 3.8144e-05, 1.0026e-04, 4.2140e-07, 1.3149e-04,\n",
      "        7.2173e-04, 1.5044e-03, 4.4767e-01, 1.3764e-02, 3.2378e-04, 1.0107e-05,\n",
      "        2.0469e-03, 5.0659e-01, 3.7663e-03, 9.6781e-06, 1.2321e-03, 8.8357e-05,\n",
      "        3.4728e-05, 7.0755e-07, 1.9321e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.9817e-01, 4.1255e-04, 1.7843e-04, 7.6903e-04, 9.1642e-06, 1.3722e-02,\n",
      "        2.5012e-02, 1.5826e-04, 3.1508e-03, 1.9954e-03, 6.1890e-07, 5.7404e-05,\n",
      "        1.3079e-03, 1.0325e-02, 1.0693e-02, 3.3299e-03, 6.5411e-04, 1.5005e-05,\n",
      "        2.0164e-05, 3.0391e-03, 2.6074e-02, 5.4202e-04, 1.5472e-05, 1.3574e-04,\n",
      "        1.6604e-06, 2.0145e-04, 1.3720e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.8570e-07, 1.5473e-01, 1.9083e-02, 2.2118e-02, 2.2053e-02, 2.6950e-02,\n",
      "        5.7372e-02, 7.6176e-03, 3.7304e-02, 1.4090e-01, 2.8315e-03, 8.7125e-04,\n",
      "        1.9364e-02, 2.1799e-02, 2.1338e-02, 1.7280e-01, 1.6681e-02, 1.2715e-03,\n",
      "        1.1938e-02, 6.2642e-02, 1.0164e-01, 7.0091e-03, 6.5471e-03, 6.3762e-02,\n",
      "        1.1223e-05, 1.3213e-03, 5.4384e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.2878e-02, 8.6719e-05, 1.5497e-02, 2.8156e-02, 4.2832e-03, 1.6636e-05,\n",
      "        8.4787e-03, 1.2928e-02, 1.4013e-04, 5.7381e-04, 1.2265e-05, 7.0967e-05,\n",
      "        6.2258e-02, 8.8374e-03, 5.9280e-01, 4.5458e-05, 9.4086e-03, 7.9192e-05,\n",
      "        5.0904e-02, 9.2738e-02, 4.4825e-02, 1.4147e-03, 5.9177e-04, 2.7025e-03,\n",
      "        1.3464e-04, 1.2318e-04, 1.5049e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5133e-03, 4.4148e-03, 3.6879e-03, 2.4854e-03, 6.3012e-03, 9.2723e-04,\n",
      "        2.8912e-03, 2.2529e-04, 3.0394e-04, 8.2376e-03, 3.4881e-04, 3.4647e-03,\n",
      "        4.4924e-01, 6.7885e-02, 6.6024e-04, 4.2931e-02, 1.2843e-03, 4.3970e-04,\n",
      "        2.1525e-02, 1.5277e-01, 1.0066e-01, 1.4622e-03, 5.4309e-03, 1.1628e-01,\n",
      "        3.1496e-04, 1.6686e-03, 6.5218e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1489e-02, 5.6674e-02, 1.5367e-04, 1.1528e-06, 1.2476e-06, 2.0802e-02,\n",
      "        3.5213e-05, 5.9053e-06, 4.5363e-04, 1.5972e-02, 8.9197e-06, 1.2835e-06,\n",
      "        9.7781e-05, 6.4828e-04, 1.1720e-05, 8.7844e-01, 5.9674e-04, 3.0260e-06,\n",
      "        2.9474e-04, 5.3846e-03, 2.1269e-05, 5.9419e-03, 2.8981e-05, 8.8629e-04,\n",
      "        4.4648e-06, 1.9429e-03, 9.6053e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.3078e-03, 1.2445e-03, 1.4010e-04, 1.7705e-03, 1.5714e-02, 2.8249e-04,\n",
      "        1.6297e-04, 9.4929e-04, 1.2821e-04, 2.3882e-04, 3.3436e-05, 9.1023e-05,\n",
      "        3.6484e-04, 1.1767e-03, 2.6758e-03, 2.8927e-03, 4.2073e-04, 2.3767e-05,\n",
      "        5.6376e-03, 9.4848e-01, 2.6405e-03, 2.3045e-03, 1.4397e-03, 3.9018e-03,\n",
      "        5.4017e-04, 5.8629e-05, 3.7910e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([2.0529e-02, 1.6875e-04, 2.2318e-05, 1.5011e-03, 5.4819e-05, 1.6123e-03,\n",
      "        3.8989e-04, 7.4536e-05, 2.7893e-03, 2.5506e-03, 3.3553e-06, 5.4841e-04,\n",
      "        8.4352e-05, 1.3027e-03, 1.7168e-04, 4.4101e-03, 8.7221e-04, 7.0798e-06,\n",
      "        6.8991e-05, 1.4081e-03, 9.6007e-01, 1.2278e-04, 8.4068e-06, 9.4545e-04,\n",
      "        1.3139e-06, 2.4192e-04, 3.8298e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.9492e-01, 2.6019e-04, 6.4419e-07, 6.9033e-07, 2.0636e-06, 1.9921e-04,\n",
      "        8.2411e-06, 2.0757e-07, 6.5829e-04, 8.2440e-04, 5.8471e-08, 5.2358e-07,\n",
      "        2.1570e-04, 4.3496e-05, 1.8211e-06, 3.9578e-04, 1.9679e-06, 1.1093e-06,\n",
      "        1.8635e-05, 1.7611e-03, 3.3115e-06, 3.7642e-04, 2.6968e-07, 3.2248e-05,\n",
      "        1.2210e-07, 2.7461e-04, 8.9483e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.3967e-07, 1.9562e-01, 2.5216e-02, 3.2434e-02, 8.2385e-02, 4.6142e-02,\n",
      "        4.2520e-02, 1.2104e-02, 4.1208e-02, 1.7935e-01, 3.7443e-03, 1.8828e-03,\n",
      "        1.0017e-02, 3.4005e-02, 1.7306e-02, 9.1551e-02, 1.8123e-02, 7.9423e-04,\n",
      "        1.2525e-02, 4.5423e-02, 5.5952e-02, 9.9407e-03, 3.2108e-03, 3.3428e-02,\n",
      "        1.0095e-05, 5.0333e-03, 7.6367e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.0709e-03, 6.0190e-02, 1.2762e-03, 8.3696e-03, 1.9098e-02, 2.0510e-03,\n",
      "        1.5176e-02, 6.8751e-03, 4.0273e-04, 8.8271e-04, 5.3477e-04, 5.1419e-05,\n",
      "        4.0376e-02, 4.6261e-02, 1.0296e-01, 1.5081e-03, 9.0077e-03, 1.2949e-02,\n",
      "        6.6177e-03, 6.7656e-02, 2.1517e-02, 5.3752e-02, 3.4008e-01, 5.1085e-03,\n",
      "        1.6901e-01, 7.0155e-03, 2.0495e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.2851e-05, 7.6712e-02, 2.5344e-01, 1.9046e-03, 3.9495e-05, 1.3826e-01,\n",
      "        3.3402e-03, 1.2571e-05, 3.2495e-04, 7.1627e-02, 1.5706e-03, 9.7345e-06,\n",
      "        1.2445e-04, 1.4759e-03, 1.1297e-04, 1.0053e-01, 3.1457e-01, 7.5499e-05,\n",
      "        1.0385e-02, 1.0981e-03, 1.6766e-03, 5.0748e-03, 1.0069e-02, 7.8723e-04,\n",
      "        1.2012e-04, 5.5593e-03, 1.0170e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "d about the theologians any more except  <------ | ------> of they stade disent foclesis almost emi\n",
      "Epoch 10   Time 62.388    Train Loss: 1.293\n",
      "Softmaxed: tensor([1.7355e-01, 9.1925e-02, 3.9417e-04, 7.8716e-04, 1.0525e-05, 1.0383e-01,\n",
      "        1.5592e-03, 4.5008e-05, 3.1472e-04, 5.6782e-01, 1.3940e-06, 1.7065e-05,\n",
      "        2.9479e-03, 1.1033e-02, 5.4107e-03, 7.4148e-03, 5.1541e-03, 2.6181e-05,\n",
      "        1.8962e-04, 2.5988e-03, 6.0268e-03, 1.2784e-02, 7.5506e-06, 1.3413e-04,\n",
      "        1.5564e-06, 5.9894e-03, 2.0347e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.3591e-03, 6.9480e-02, 6.2226e-02, 3.8329e-03, 2.6446e-03, 1.4163e-02,\n",
      "        6.2712e-03, 4.3910e-04, 3.6560e-05, 4.7354e-04, 1.9841e-06, 6.0482e-06,\n",
      "        1.1171e-03, 1.2425e-02, 8.2130e-02, 6.6603e-01, 1.7046e-03, 4.7284e-05,\n",
      "        2.4309e-03, 7.0963e-03, 4.2247e-02, 4.3069e-04, 2.2129e-02, 7.7738e-05,\n",
      "        2.5641e-05, 1.3186e-05, 1.1616e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.6577e-06, 1.0680e-02, 3.2543e-07, 2.0253e-07, 7.7337e-07, 9.8493e-01,\n",
      "        2.4143e-06, 9.2244e-06, 1.2178e-07, 2.6832e-03, 3.1913e-08, 4.6517e-08,\n",
      "        1.5600e-04, 1.0829e-05, 7.3996e-05, 5.6272e-04, 4.7124e-07, 3.0550e-08,\n",
      "        2.9739e-06, 1.7016e-05, 1.3298e-05, 7.3097e-05, 1.9181e-08, 4.6967e-07,\n",
      "        7.7877e-08, 7.7752e-04, 1.6791e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.5514e-01, 2.0611e-05, 1.3590e-05, 2.9932e-05, 8.0154e-03, 2.2931e-06,\n",
      "        1.3479e-04, 4.8228e-07, 9.4709e-07, 6.4407e-05, 2.0035e-07, 4.8699e-07,\n",
      "        6.7491e-03, 3.0650e-04, 1.5414e-03, 4.6516e-06, 3.2552e-05, 1.8050e-06,\n",
      "        1.7887e-04, 2.7350e-02, 2.6660e-04, 1.8716e-05, 3.4912e-05, 3.9067e-05,\n",
      "        1.3590e-06, 5.5716e-05, 4.5698e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.9261e-07, 1.2686e-01, 3.6596e-02, 3.0964e-02, 4.2185e-02, 7.4353e-02,\n",
      "        3.4209e-02, 1.2208e-02, 4.0340e-02, 1.3170e-01, 1.7929e-03, 1.4797e-03,\n",
      "        1.1895e-02, 2.7224e-02, 9.2872e-03, 8.9079e-02, 4.1740e-02, 2.0494e-03,\n",
      "        6.9327e-03, 5.3126e-02, 1.4320e-01, 1.6283e-02, 6.3407e-03, 5.4635e-02,\n",
      "        1.3932e-05, 5.4530e-03, 5.9941e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.6318e-02, 3.1323e-04, 2.8665e-04, 3.9350e-05, 1.5700e-02, 1.2704e-04,\n",
      "        2.2699e-02, 5.4072e-04, 9.3049e-05, 3.3108e-06, 1.6991e-06, 8.2187e-06,\n",
      "        1.1906e-03, 4.0847e-02, 6.1528e-01, 3.5977e-04, 9.4656e-04, 5.3996e-05,\n",
      "        1.6888e-03, 1.1184e-01, 1.7068e-01, 2.8002e-05, 5.8657e-04, 2.9951e-04,\n",
      "        6.7755e-05, 1.3283e-06, 2.4084e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9737e-01, 1.0829e-05, 2.2580e-06, 1.1995e-04, 5.6190e-06, 1.0156e-04,\n",
      "        9.8795e-05, 3.4237e-07, 6.8519e-05, 3.1207e-06, 3.9046e-07, 2.9758e-06,\n",
      "        6.0174e-05, 7.8699e-04, 3.5934e-06, 2.6904e-06, 1.1522e-04, 2.0770e-06,\n",
      "        3.5156e-06, 6.3614e-04, 4.9532e-04, 6.3297e-05, 1.0219e-06, 3.5914e-05,\n",
      "        1.6444e-07, 5.5375e-06, 7.3664e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.0043e-07, 1.6185e-01, 2.8627e-02, 2.5474e-02, 3.1172e-02, 3.7345e-02,\n",
      "        2.9517e-02, 1.8591e-02, 3.6617e-02, 6.5021e-02, 4.5823e-03, 6.4171e-03,\n",
      "        1.9399e-02, 2.6844e-02, 5.6352e-02, 6.4698e-02, 4.5491e-02, 9.7387e-04,\n",
      "        4.0586e-02, 6.3752e-02, 1.5640e-01, 1.5028e-02, 1.2078e-02, 5.1515e-02,\n",
      "        2.4763e-05, 1.6155e-03, 2.7239e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.9959e-05, 2.6960e-02, 1.0482e-05, 1.1596e-06, 1.9468e-07, 1.2171e-02,\n",
      "        1.3372e-04, 6.9942e-06, 7.6646e-01, 1.1833e-02, 1.3766e-06, 1.2686e-05,\n",
      "        3.4656e-04, 1.5665e-05, 1.3767e-05, 1.5595e-01, 3.1029e-06, 5.8796e-06,\n",
      "        2.1939e-02, 4.1956e-05, 2.0253e-05, 1.6840e-03, 1.6466e-06, 1.5837e-03,\n",
      "        5.6927e-07, 7.1973e-04, 3.9568e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.1477e-04, 8.2020e-02, 1.1616e-06, 7.6138e-09, 2.7027e-07, 8.4470e-01,\n",
      "        1.4726e-06, 6.1948e-07, 1.2819e-05, 4.6677e-02, 7.9306e-07, 5.9796e-07,\n",
      "        2.3372e-05, 3.9432e-05, 1.0375e-04, 1.5736e-02, 2.0647e-06, 5.0758e-08,\n",
      "        8.6265e-03, 1.0768e-04, 1.6223e-05, 1.3929e-03, 4.3632e-08, 1.1476e-04,\n",
      "        9.4088e-07, 3.0466e-04, 6.9072e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.6420e-01, 1.9844e-04, 3.0550e-05, 7.7316e-06, 2.0855e-05, 1.1439e-03,\n",
      "        1.1997e-04, 7.0848e-04, 1.4759e-03, 4.9417e-02, 2.5095e-05, 1.2046e-04,\n",
      "        8.9605e-04, 5.5991e-02, 1.6903e-02, 3.5887e-04, 7.0289e-04, 3.2445e-06,\n",
      "        3.8746e-02, 1.9355e-02, 1.0006e-03, 8.5360e-06, 9.9653e-05, 6.8520e-04,\n",
      "        2.2934e-05, 4.7688e-02, 7.5034e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4429e-06, 4.7419e-02, 5.4372e-02, 9.6966e-02, 5.6923e-02, 4.3643e-02,\n",
      "        5.4279e-02, 4.2072e-02, 3.9085e-02, 4.6133e-02, 5.6872e-03, 3.6543e-03,\n",
      "        2.3056e-02, 5.5725e-02, 2.1757e-02, 4.8026e-02, 7.3369e-02, 4.0533e-03,\n",
      "        4.0255e-02, 1.0720e-01, 3.3164e-02, 1.7368e-02, 2.3191e-02, 5.8905e-02,\n",
      "        3.0567e-05, 3.6201e-03, 4.7877e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.0613e-05, 8.2850e-02, 5.7991e-05, 1.0831e-05, 4.1674e-05, 5.5166e-01,\n",
      "        1.6024e-05, 1.8853e-04, 2.3181e-04, 1.3046e-01, 1.7104e-05, 4.0202e-06,\n",
      "        6.1445e-03, 2.6697e-04, 2.5831e-04, 1.7304e-01, 2.2573e-05, 1.0691e-05,\n",
      "        4.2208e-02, 5.3379e-05, 1.1479e-05, 1.1172e-02, 1.0654e-05, 1.7809e-04,\n",
      "        1.7109e-05, 1.0381e-03, 3.7559e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4440e-03, 4.7759e-02, 1.2857e-03, 8.8591e-02, 1.8199e-03, 4.3642e-02,\n",
      "        6.5009e-02, 3.7065e-02, 2.0266e-04, 9.3931e-03, 6.2196e-04, 1.5309e-04,\n",
      "        1.8781e-01, 5.9500e-02, 3.5334e-02, 5.4708e-03, 6.8026e-02, 3.0820e-03,\n",
      "        7.9168e-03, 2.4118e-01, 1.7945e-02, 4.7780e-04, 6.7170e-02, 5.4553e-03,\n",
      "        2.2614e-03, 3.4541e-04, 4.5460e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8677e-03, 3.6767e-03, 1.3973e-04, 5.1758e-02, 2.9831e-05, 1.4571e-01,\n",
      "        8.7949e-04, 1.0927e-04, 4.9227e-03, 3.9310e-01, 3.0721e-05, 3.1273e-03,\n",
      "        1.3266e-02, 1.5216e-03, 6.6445e-04, 5.7501e-03, 1.7028e-01, 1.8918e-04,\n",
      "        1.5567e-03, 2.4581e-02, 1.3000e-01, 3.4748e-02, 7.6480e-05, 1.1494e-02,\n",
      "        1.4631e-05, 3.8058e-04, 1.2076e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.5096e-05, 5.0623e-02, 5.5446e-06, 3.7283e-04, 9.6660e-08, 3.7070e-01,\n",
      "        1.8468e-05, 8.0615e-07, 1.9716e-04, 4.5413e-01, 1.8704e-06, 4.7506e-06,\n",
      "        4.7431e-04, 7.1414e-05, 3.1570e-05, 9.3966e-02, 8.8749e-04, 2.1087e-06,\n",
      "        1.8799e-02, 6.8140e-04, 4.4906e-05, 8.6870e-03, 3.9941e-05, 6.1826e-05,\n",
      "        3.2688e-05, 1.2869e-04, 8.2295e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1956e-05, 2.1264e-02, 7.3851e-06, 2.7854e-04, 2.4644e-06, 5.0434e-01,\n",
      "        1.9120e-05, 2.6710e-06, 5.8865e-06, 4.6293e-01, 1.1581e-06, 5.5931e-07,\n",
      "        4.6228e-06, 4.5156e-05, 8.3181e-05, 9.2884e-03, 1.5362e-06, 1.2006e-07,\n",
      "        1.4419e-04, 2.8197e-05, 1.4877e-04, 8.7584e-04, 1.3395e-05, 9.2883e-06,\n",
      "        1.8738e-06, 4.8791e-04, 5.6691e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.7411e-05, 3.4248e-02, 1.3961e-02, 1.0825e-01, 4.0091e-03, 6.8022e-02,\n",
      "        6.3756e-02, 8.7880e-03, 2.2903e-04, 2.5835e-03, 6.7294e-05, 1.3765e-04,\n",
      "        3.9637e-04, 1.0757e-02, 2.6812e-01, 2.2790e-01, 1.7557e-03, 1.7747e-04,\n",
      "        2.1301e-04, 9.5146e-02, 7.0516e-02, 1.1607e-03, 1.4859e-02, 2.0503e-04,\n",
      "        3.3384e-04, 2.8119e-05, 4.3317e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1406e-02, 2.3229e-03, 1.0287e-03, 7.1747e-03, 2.4776e-02, 9.1040e-04,\n",
      "        5.5770e-02, 2.6109e-04, 1.3995e-04, 4.5549e-03, 3.1481e-06, 1.9992e-04,\n",
      "        3.0712e-05, 3.5489e-03, 6.9431e-02, 3.8550e-04, 3.4754e-04, 8.1453e-05,\n",
      "        1.0003e-02, 7.6262e-01, 3.0194e-02, 1.0597e-03, 7.2027e-03, 6.1602e-03,\n",
      "        1.2747e-04, 1.1117e-04, 1.4343e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.5587e-01, 1.8726e-03, 2.6451e-04, 6.3710e-04, 2.7851e-05, 8.2883e-04,\n",
      "        1.4533e-02, 3.7866e-05, 2.1796e-06, 4.9092e-03, 1.3805e-05, 1.4120e-05,\n",
      "        1.0622e-03, 6.7547e-05, 2.4327e-04, 4.8674e-03, 6.1008e-06, 2.8916e-05,\n",
      "        2.5937e-04, 1.0025e-03, 1.4149e-02, 9.4881e-02, 2.2346e-05, 3.5163e-04,\n",
      "        2.4566e-05, 3.8627e-03, 1.5831e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.5387e-07, 2.3891e-01, 1.0140e-02, 3.4733e-02, 8.8410e-03, 1.2495e-02,\n",
      "        2.7614e-02, 7.9522e-03, 3.6504e-02, 2.1057e-01, 1.6032e-03, 1.1991e-03,\n",
      "        5.5121e-03, 8.9445e-03, 3.6388e-03, 1.1910e-01, 5.4980e-03, 2.2216e-03,\n",
      "        3.5663e-03, 2.7082e-02, 1.3336e-01, 1.6278e-02, 5.0517e-03, 7.3544e-02,\n",
      "        1.3760e-05, 5.5647e-03, 5.8527e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3642e-02, 5.2645e-04, 3.0310e-04, 1.1207e-04, 1.0553e-02, 1.8744e-04,\n",
      "        2.2152e-02, 1.1109e-03, 1.3739e-04, 4.9950e-06, 1.5955e-06, 8.9467e-06,\n",
      "        1.3325e-03, 2.0409e-02, 4.1037e-01, 2.3224e-04, 7.9529e-04, 7.5228e-05,\n",
      "        4.8616e-04, 2.7156e-01, 2.0505e-01, 2.0737e-05, 5.4720e-04, 3.0287e-04,\n",
      "        7.7077e-05, 1.6854e-06, 1.9522e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.9787e-01, 1.0564e-04, 9.3078e-06, 2.7380e-05, 8.1660e-06, 1.6118e-04,\n",
      "        6.1647e-04, 2.7314e-06, 7.7043e-04, 5.4471e-05, 3.8509e-06, 1.4149e-06,\n",
      "        6.6799e-05, 1.2570e-04, 1.1385e-06, 4.5228e-06, 6.5864e-05, 5.0521e-06,\n",
      "        5.2357e-05, 1.9958e-01, 2.0541e-04, 4.9488e-05, 1.0188e-05, 1.1312e-04,\n",
      "        1.2494e-07, 8.9579e-05, 1.0205e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1223e-06, 6.6595e-02, 4.0956e-02, 1.1029e-02, 7.4884e-03, 3.4027e-02,\n",
      "        2.1654e-02, 9.9550e-03, 7.5535e-02, 3.4516e-01, 2.6774e-03, 1.7738e-03,\n",
      "        1.0483e-02, 3.6411e-02, 2.0592e-02, 1.2835e-02, 2.5121e-02, 3.0113e-04,\n",
      "        2.7958e-02, 4.5227e-02, 3.4896e-02, 1.7311e-02, 7.5490e-03, 1.3985e-01,\n",
      "        3.7282e-06, 4.5953e-03, 1.6238e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.9874e-03, 1.1566e-02, 5.6026e-04, 3.8670e-04, 2.6169e-06, 4.4714e-01,\n",
      "        5.5476e-04, 3.8772e-05, 1.3454e-04, 5.1242e-03, 4.3333e-06, 3.5804e-06,\n",
      "        1.0642e-03, 5.6667e-04, 1.4932e-03, 5.0719e-01, 3.4720e-03, 6.3744e-05,\n",
      "        7.5678e-03, 1.1889e-03, 3.9120e-04, 8.2666e-03, 8.1098e-04, 3.2313e-04,\n",
      "        5.6385e-05, 4.4129e-05, 8.6180e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5703e-01, 5.2993e-02, 8.8050e-04, 2.6883e-02, 4.9690e-03, 1.2286e-02,\n",
      "        1.8353e-03, 7.7403e-04, 9.4703e-04, 3.1429e-04, 1.0842e-04, 1.0525e-03,\n",
      "        4.3378e-02, 7.7845e-03, 4.2229e-02, 4.7352e-05, 1.0994e-03, 1.6790e-04,\n",
      "        6.1323e-03, 6.3178e-03, 6.2846e-01, 5.0286e-05, 1.8984e-03, 1.8958e-03,\n",
      "        3.3915e-04, 3.2484e-05, 9.2023e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.0147e-01, 2.7984e-02, 5.2900e-05, 7.4027e-06, 3.5343e-05, 5.5324e-02,\n",
      "        5.4966e-04, 2.1835e-05, 5.1573e-02, 2.6072e-02, 4.7653e-06, 6.1367e-05,\n",
      "        3.0489e-03, 2.4243e-04, 4.3599e-05, 9.5972e-04, 7.4591e-05, 1.7437e-05,\n",
      "        2.3076e-03, 7.0833e-03, 3.5579e-03, 1.7522e-02, 2.4745e-05, 1.5764e-03,\n",
      "        8.6264e-07, 3.5236e-04, 2.9738e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.0413e-07, 3.7169e-02, 6.8688e-02, 5.3524e-02, 4.4615e-02, 5.0900e-02,\n",
      "        4.3145e-02, 5.6826e-03, 4.9855e-02, 9.2871e-02, 4.9924e-03, 2.6461e-03,\n",
      "        3.0190e-02, 2.7494e-02, 1.8787e-02, 3.4864e-02, 4.9319e-02, 5.3387e-04,\n",
      "        9.7483e-03, 5.7821e-02, 1.9567e-01, 1.9717e-02, 5.2283e-03, 9.2826e-02,\n",
      "        8.7611e-06, 3.6543e-03, 4.7065e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9930e-04, 1.2883e-02, 1.3268e-05, 1.1630e-06, 1.2170e-07, 1.6452e-02,\n",
      "        1.4856e-04, 3.0912e-06, 6.6170e-01, 1.2024e-02, 1.6351e-06, 1.3333e-05,\n",
      "        3.3171e-04, 1.8094e-05, 1.1099e-05, 2.7231e-01, 4.5583e-06, 3.8372e-06,\n",
      "        1.8672e-02, 2.6307e-05, 2.7942e-05, 3.4421e-03, 1.9082e-06, 7.7198e-04,\n",
      "        3.8818e-07, 9.4038e-04, 2.6447e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.6111e-04, 1.5045e-01, 1.6586e-06, 1.2224e-08, 4.7039e-07, 7.5504e-01,\n",
      "        1.3958e-06, 8.3057e-07, 1.8305e-05, 5.6536e-02, 1.0825e-06, 8.1560e-07,\n",
      "        3.5372e-05, 4.3815e-05, 1.0414e-04, 1.9452e-02, 2.3236e-06, 8.5852e-08,\n",
      "        1.5202e-02, 1.1770e-04, 2.0017e-05, 2.2469e-03, 6.4796e-08, 1.4097e-04,\n",
      "        1.7865e-06, 4.1778e-04, 1.1314e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.7801e-01, 2.1963e-04, 3.9075e-05, 9.2132e-06, 2.4559e-05, 1.1723e-03,\n",
      "        1.3884e-04, 6.1785e-04, 1.4583e-03, 5.2629e-02, 3.0454e-05, 1.2092e-04,\n",
      "        8.7877e-04, 6.3663e-02, 1.6520e-02, 3.5592e-04, 7.6935e-04, 3.2636e-06,\n",
      "        8.4584e-02, 1.7718e-02, 1.1167e-03, 1.2823e-05, 1.1672e-04, 7.9277e-04,\n",
      "        3.2418e-05, 7.8875e-02, 8.9008e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.5315e-06, 4.7251e-02, 5.3200e-02, 9.5464e-02, 5.7310e-02, 4.5054e-02,\n",
      "        5.1527e-02, 4.4251e-02, 4.2260e-02, 4.3778e-02, 5.7108e-03, 3.5742e-03,\n",
      "        2.5051e-02, 5.4261e-02, 2.1098e-02, 5.1971e-02, 7.2036e-02, 4.3706e-03,\n",
      "        4.1996e-02, 1.0321e-01, 3.5097e-02, 1.6620e-02, 2.4098e-02, 5.7188e-02,\n",
      "        3.0819e-05, 3.5447e-03, 4.9129e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.0978e-05, 8.2232e-02, 5.9553e-05, 1.1068e-05, 4.2541e-05, 5.5786e-01,\n",
      "        1.6233e-05, 1.9510e-04, 2.3808e-04, 1.2737e-01, 1.7257e-05, 4.0157e-06,\n",
      "        6.4641e-03, 2.6890e-04, 2.7319e-04, 1.7040e-01, 2.3054e-05, 1.1115e-05,\n",
      "        4.2084e-02, 5.3509e-05, 1.1396e-05, 1.1133e-02, 1.0926e-05, 1.7971e-04,\n",
      "        1.7659e-05, 9.9479e-04, 3.7771e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.3558e-03, 4.8318e-02, 1.3073e-03, 8.9580e-02, 1.8014e-03, 4.3649e-02,\n",
      "        6.5667e-02, 3.6694e-02, 2.0152e-04, 9.2835e-03, 6.1592e-04, 1.5022e-04,\n",
      "        1.9004e-01, 5.9544e-02, 3.5898e-02, 5.4966e-03, 6.8429e-02, 3.1060e-03,\n",
      "        7.9731e-03, 2.3543e-01, 1.8372e-02, 4.7350e-04, 6.7567e-02, 5.4046e-03,\n",
      "        2.2578e-03, 3.4390e-04, 4.5345e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.8624e-03, 3.6705e-03, 1.4088e-04, 5.1912e-02, 3.0434e-05, 1.4335e-01,\n",
      "        8.8434e-04, 1.0958e-04, 4.9500e-03, 3.9353e-01, 3.0836e-05, 3.1369e-03,\n",
      "        1.3431e-02, 1.5107e-03, 6.6486e-04, 5.7040e-03, 1.6971e-01, 1.9047e-04,\n",
      "        1.5478e-03, 2.4858e-02, 1.3194e-01, 3.4769e-02, 7.6561e-05, 1.1474e-02,\n",
      "        1.4563e-05, 3.8094e-04, 1.2179e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.1078e-03, 7.6799e-02, 1.8874e-05, 1.0022e-05, 1.3932e-06, 4.9513e-02,\n",
      "        6.0495e-04, 4.3524e-06, 4.3090e-04, 4.5656e-01, 2.0737e-06, 7.1694e-06,\n",
      "        2.9482e-04, 1.7568e-03, 6.4786e-04, 8.6605e-02, 3.6803e-04, 2.0919e-05,\n",
      "        3.0096e-01, 1.1621e-02, 3.2467e-05, 8.5115e-03, 4.2510e-05, 6.3062e-04,\n",
      "        9.3911e-06, 1.4114e-03, 3.3124e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.0013e-05, 9.8620e-03, 1.8826e-03, 7.7591e-03, 6.3799e-03, 1.4593e-03,\n",
      "        3.7172e-03, 4.0687e-04, 2.4664e-05, 5.0395e-05, 3.4274e-06, 3.2971e-05,\n",
      "        1.6680e-02, 2.2495e-02, 8.4369e-01, 3.7107e-02, 3.1226e-03, 1.4079e-04,\n",
      "        1.1719e-02, 4.1973e-03, 2.1637e-02, 8.5563e-05, 6.5155e-03, 6.5046e-05,\n",
      "        3.0701e-04, 1.2025e-07, 5.7947e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.5490e-02, 2.7106e-01, 3.2528e-05, 2.5187e-01, 6.9640e-02, 8.6094e-02,\n",
      "        6.1335e-04, 1.3422e-01, 1.4289e-04, 4.3277e-02, 2.6750e-04, 1.7645e-03,\n",
      "        1.2491e-04, 5.4789e-03, 6.4271e-03, 1.3260e-02, 7.2130e-06, 1.7084e-04,\n",
      "        1.9537e-04, 1.8242e-02, 5.8044e-03, 6.1090e-02, 2.0243e-04, 6.2403e-04,\n",
      "        6.5712e-04, 3.1903e-03, 5.5414e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2659e-01, 1.8851e-03, 1.0977e-04, 3.1342e-03, 1.8077e-05, 2.2742e-03,\n",
      "        1.8271e-03, 8.4663e-06, 1.2584e-04, 1.2491e-02, 7.5196e-06, 2.2913e-05,\n",
      "        2.1558e-03, 3.4879e-03, 3.5883e-05, 3.1218e-03, 2.2947e-03, 6.5803e-05,\n",
      "        1.4010e-05, 1.8113e-02, 8.1949e-01, 1.0835e-03, 5.3449e-06, 5.5871e-04,\n",
      "        1.0505e-06, 1.0602e-03, 1.2205e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.0194e-01, 8.4298e-03, 6.1434e-05, 3.7306e-04, 7.0091e-06, 6.4521e-02,\n",
      "        5.6140e-04, 3.1589e-05, 2.3336e-03, 4.3930e-01, 1.2596e-06, 1.3019e-05,\n",
      "        1.3008e-02, 5.3092e-03, 5.2195e-05, 3.1430e-02, 4.4847e-04, 3.1147e-05,\n",
      "        3.1963e-05, 2.7152e-03, 1.4908e-02, 5.7148e-03, 2.3648e-06, 2.8702e-04,\n",
      "        4.7778e-07, 8.4898e-03, 3.0067e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      " impossible while the collective impress <------ | ------> ive is the desprief it yet the destinss \n",
      "Epoch 11   Time 62.618    Train Loss: 1.279\n",
      "Softmaxed: tensor([2.7046e-04, 3.8649e-04, 7.3712e-03, 4.1473e-01, 4.4232e-03, 1.8852e-04,\n",
      "        2.1301e-03, 8.0143e-04, 1.1798e-04, 1.4142e-01, 2.9475e-04, 3.1455e-04,\n",
      "        5.7887e-02, 1.3838e-02, 3.4032e-02, 1.8657e-04, 6.3663e-04, 7.2365e-04,\n",
      "        1.4709e-01, 3.2817e-02, 6.2831e-02, 1.0755e-02, 3.8764e-02, 1.3480e-03,\n",
      "        7.9577e-03, 1.6220e-02, 2.4518e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.2906e-01, 2.2646e-03, 7.3946e-03, 3.6146e-02, 1.8472e-03, 6.6913e-03,\n",
      "        2.7406e-03, 1.1487e-04, 1.4124e-03, 3.6762e-02, 9.1885e-05, 4.8872e-05,\n",
      "        3.6099e-02, 5.7807e-03, 1.4010e-03, 1.9692e-03, 1.2027e-03, 2.0257e-05,\n",
      "        3.1580e-02, 4.9210e-02, 3.8221e-02, 1.7324e-04, 2.8403e-03, 1.8554e-03,\n",
      "        6.3901e-05, 4.9012e-03, 1.0245e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([5.3295e-02, 1.7442e-02, 1.8107e-03, 1.1583e-02, 7.4988e-06, 3.2681e-02,\n",
      "        8.6817e-04, 1.0860e-05, 7.5929e-02, 2.4147e-02, 2.1470e-05, 2.0068e-04,\n",
      "        1.3838e-02, 1.1909e-03, 1.7061e-03, 1.3822e-01, 7.8177e-04, 1.2184e-04,\n",
      "        1.1824e-03, 1.2337e-03, 6.1918e-01, 1.8623e-03, 2.9370e-05, 4.7996e-04,\n",
      "        1.5953e-06, 2.1487e-03, 2.6117e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.9398e-01, 3.5938e-01, 1.9478e-06, 2.3385e-06, 4.3170e-07, 1.1139e-01,\n",
      "        1.1235e-04, 2.8334e-06, 1.0455e-03, 9.4446e-02, 8.4622e-07, 8.6375e-07,\n",
      "        2.4650e-02, 2.8237e-05, 1.2288e-05, 6.8332e-03, 5.5748e-06, 1.5319e-06,\n",
      "        1.1286e-03, 5.7231e-03, 9.1534e-07, 1.1107e-03, 9.1214e-07, 3.0279e-05,\n",
      "        7.4036e-07, 1.0380e-04, 4.0679e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([2.5968e-04, 1.0517e-04, 4.2702e-02, 2.0998e-02, 8.3626e-03, 3.2811e-05,\n",
      "        1.6990e-03, 2.3735e-02, 2.6943e-05, 5.2572e-02, 3.9294e-05, 5.8881e-04,\n",
      "        1.7101e-01, 5.2423e-03, 4.4358e-01, 6.4852e-05, 2.0816e-03, 1.4133e-05,\n",
      "        8.6972e-02, 1.4393e-03, 9.2191e-02, 6.2126e-03, 2.7476e-03, 1.3765e-04,\n",
      "        9.9855e-05, 3.6876e-02, 2.0640e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.6419e-01, 3.0805e-03, 1.3255e-04, 1.3411e-03, 2.9728e-03, 2.8855e-03,\n",
      "        1.5651e-03, 2.0851e-05, 1.5037e-05, 1.5928e-01, 2.6730e-06, 3.4301e-04,\n",
      "        5.5060e-01, 3.0361e-04, 8.9410e-04, 1.3001e-03, 1.8756e-04, 1.6919e-05,\n",
      "        2.1209e-04, 1.0638e-01, 2.6598e-04, 2.0122e-04, 6.7640e-04, 7.5354e-04,\n",
      "        7.6876e-06, 2.3422e-03, 3.2831e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.5166e-07, 9.5286e-02, 2.7706e-02, 2.7141e-02, 6.2801e-02, 6.9189e-02,\n",
      "        5.9361e-02, 7.4227e-03, 2.2510e-02, 5.6923e-02, 4.8332e-03, 3.3647e-03,\n",
      "        2.1789e-02, 3.3310e-02, 2.6585e-02, 3.1882e-02, 6.2574e-02, 2.0156e-03,\n",
      "        2.1543e-02, 2.2827e-01, 4.7082e-02, 2.2634e-02, 1.4244e-02, 4.7964e-02,\n",
      "        3.6236e-05, 2.9192e-03, 6.1739e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.7879e-03, 5.2018e-02, 3.6328e-04, 8.9772e-02, 2.2217e-06, 1.7019e-01,\n",
      "        2.7929e-03, 6.4463e-04, 4.2822e-02, 8.2701e-02, 1.2393e-04, 4.7036e-03,\n",
      "        6.2170e-03, 4.4238e-03, 1.9104e-03, 1.0116e-01, 1.0839e-01, 1.1114e-03,\n",
      "        1.5907e-03, 1.3699e-03, 1.2323e-01, 1.4863e-01, 7.7069e-05, 5.9957e-03,\n",
      "        6.6977e-05, 4.0848e-02, 5.4843e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.3195e-03, 3.4451e-03, 1.3414e-03, 2.1490e-01, 2.3761e-03, 1.5136e-01,\n",
      "        7.6338e-03, 2.8831e-03, 3.1486e-04, 1.7379e-03, 7.7153e-05, 8.2324e-05,\n",
      "        7.1364e-02, 1.9051e-02, 3.5986e-01, 2.1598e-03, 4.9913e-03, 4.2315e-03,\n",
      "        9.8732e-02, 2.6804e-03, 2.0828e-02, 8.4720e-04, 1.5758e-02, 8.5648e-04,\n",
      "        8.8778e-03, 1.2465e-03, 4.3217e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.0380e-02, 4.7906e-04, 1.0090e-05, 5.4150e-03, 6.7555e-03, 2.0746e-04,\n",
      "        3.8059e-03, 4.7609e-04, 1.8214e-04, 1.9490e-04, 1.5283e-04, 1.9845e-03,\n",
      "        5.0043e-03, 3.3250e-05, 3.1954e-05, 6.5145e-04, 2.2578e-04, 6.4329e-04,\n",
      "        3.3598e-05, 7.4111e-01, 1.9508e-01, 1.5121e-02, 1.6944e-03, 2.0336e-04,\n",
      "        3.8589e-05, 1.7854e-05, 5.9007e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4789e-02, 1.3993e-01, 6.3039e-05, 1.4220e-04, 1.0862e-06, 6.6508e-01,\n",
      "        2.0016e-04, 1.3450e-05, 1.2975e-03, 1.2752e-01, 8.3681e-07, 2.8706e-05,\n",
      "        9.1063e-04, 3.2683e-03, 1.6780e-05, 8.1010e-03, 1.7413e-03, 3.9598e-05,\n",
      "        2.3016e-05, 1.3512e-03, 9.9367e-03, 2.4567e-02, 2.2285e-06, 1.9808e-04,\n",
      "        8.5398e-07, 7.5789e-04, 2.1074e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.8215e-01, 3.5409e-04, 1.1476e-04, 4.5479e-05, 4.3026e-02, 9.7751e-06,\n",
      "        6.6134e-04, 8.2487e-05, 4.2526e-06, 7.4427e-05, 1.5421e-06, 5.0599e-07,\n",
      "        6.0215e-04, 1.2514e-03, 1.0970e-03, 1.0430e-04, 1.6582e-05, 1.8181e-05,\n",
      "        2.4922e-03, 1.6739e-01, 2.5883e-04, 6.1691e-06, 1.0657e-04, 9.5904e-05,\n",
      "        3.1623e-05, 6.5716e-06, 5.8202e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.8941e-01, 1.2620e-05, 3.7295e-06, 8.2680e-05, 3.7046e-07, 3.6621e-05,\n",
      "        1.2552e-04, 2.3596e-07, 2.7359e-04, 1.6840e-04, 1.5676e-07, 2.5953e-06,\n",
      "        9.4767e-05, 2.0665e-04, 4.8317e-06, 8.4538e-05, 1.9326e-03, 1.5544e-06,\n",
      "        3.1110e-06, 1.7925e-03, 5.4633e-03, 8.7065e-05, 9.9549e-07, 1.9670e-04,\n",
      "        3.4827e-08, 1.2098e-05, 1.8558e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([1.7183e-07, 2.0840e-01, 1.2284e-02, 1.9295e-02, 1.6577e-02, 6.7833e-03,\n",
      "        5.7701e-02, 2.7285e-03, 6.2007e-02, 9.6596e-02, 3.6625e-03, 1.1838e-03,\n",
      "        8.0438e-03, 2.1286e-02, 8.6703e-03, 1.2029e-01, 1.7666e-02, 7.2461e-04,\n",
      "        1.4748e-02, 4.5303e-02, 2.1086e-01, 3.8786e-03, 3.3658e-03, 5.5706e-02,\n",
      "        1.1826e-05, 2.2062e-03, 2.7800e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.4011e-05, 2.1608e-01, 1.0194e-04, 1.0992e-06, 1.7628e-07, 2.2145e-01,\n",
      "        2.6591e-04, 7.5914e-06, 2.5260e-05, 3.6434e-01, 3.1942e-06, 1.8822e-07,\n",
      "        2.8237e-04, 5.1654e-05, 9.7663e-05, 1.5419e-01, 2.5934e-04, 2.4292e-06,\n",
      "        2.0872e-03, 8.9204e-05, 3.1332e-05, 3.8297e-02, 5.3586e-06, 9.6061e-04,\n",
      "        1.7040e-06, 1.3109e-03, 5.4404e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.1877e-03, 4.3574e-05, 1.3868e-02, 1.0150e-03, 5.8797e-02, 3.8253e-05,\n",
      "        1.4798e-03, 8.4483e-04, 2.5834e-05, 8.1183e-03, 2.8655e-05, 5.5089e-04,\n",
      "        1.7353e-03, 1.0090e-02, 6.1794e-02, 1.0160e-05, 9.6908e-02, 1.6501e-05,\n",
      "        7.6282e-02, 2.5367e-01, 8.0919e-03, 2.4629e-03, 3.9211e-01, 2.0916e-03,\n",
      "        2.6426e-04, 5.9887e-03, 1.4889e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.4120e-02, 9.2256e-04, 4.6302e-02, 3.8092e-03, 3.8656e-01, 7.7307e-02,\n",
      "        1.2483e-02, 6.2371e-03, 1.8268e-03, 3.4274e-02, 9.1173e-05, 6.4025e-02,\n",
      "        9.3439e-03, 4.0312e-02, 1.7621e-02, 1.1461e-03, 9.5301e-03, 6.9711e-05,\n",
      "        9.1435e-02, 6.8013e-03, 4.4219e-02, 2.2554e-04, 4.1670e-02, 4.4437e-03,\n",
      "        6.2938e-05, 4.8513e-03, 3.0974e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.7742e-01, 1.2351e-02, 2.6086e-04, 1.5785e-05, 4.3939e-04, 1.0163e-01,\n",
      "        5.2736e-04, 9.3913e-04, 1.2744e-04, 5.6547e-02, 1.0946e-05, 2.7549e-05,\n",
      "        2.2843e-01, 1.9762e-03, 5.5435e-02, 1.0613e-02, 3.3084e-04, 5.3912e-05,\n",
      "        1.2208e-03, 3.7561e-02, 7.9103e-05, 2.2467e-03, 9.2273e-05, 1.2562e-03,\n",
      "        1.7342e-05, 1.0340e-02, 5.2070e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4653e-07, 1.6742e-01, 2.6946e-02, 3.5178e-02, 1.8147e-02, 2.6760e-02,\n",
      "        4.7814e-02, 9.2847e-03, 8.2026e-02, 1.5469e-01, 3.6872e-03, 2.7020e-03,\n",
      "        8.4027e-03, 1.6641e-02, 3.4552e-02, 1.0590e-01, 2.9797e-02, 9.5159e-04,\n",
      "        1.5072e-02, 4.1515e-02, 1.0364e-01, 1.0310e-02, 3.9792e-03, 5.2311e-02,\n",
      "        1.2585e-05, 2.1787e-03, 7.0836e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.8702e-05, 9.9582e-03, 6.8378e-06, 4.7198e-07, 7.0287e-08, 9.7204e-03,\n",
      "        1.7000e-04, 3.1816e-06, 6.1003e-01, 1.4409e-02, 1.2363e-06, 7.2720e-06,\n",
      "        2.1829e-04, 8.5394e-06, 6.3535e-06, 3.3472e-01, 1.2870e-06, 3.2481e-06,\n",
      "        1.7040e-02, 2.9318e-05, 9.6922e-06, 9.0939e-04, 7.6022e-07, 8.4227e-04,\n",
      "        3.2932e-07, 1.8388e-03, 1.5927e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.7064e-04, 1.5007e-01, 1.4694e-06, 4.6854e-09, 7.8660e-07, 7.4759e-01,\n",
      "        9.7379e-07, 6.5363e-07, 1.2042e-05, 6.4898e-02, 9.8119e-07, 4.7790e-07,\n",
      "        2.6640e-05, 4.1986e-05, 1.0867e-04, 1.5161e-02, 2.0300e-06, 5.3975e-08,\n",
      "        1.9120e-02, 1.4287e-04, 8.0006e-06, 2.1665e-03, 5.4001e-08, 1.0199e-04,\n",
      "        1.5900e-06, 3.7537e-04, 8.7315e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.7899e-01, 1.1725e-04, 3.3794e-05, 4.1918e-06, 2.1164e-05, 1.1403e-03,\n",
      "        7.8868e-05, 3.2489e-04, 9.7448e-04, 4.7997e-02, 1.9272e-05, 7.7861e-05,\n",
      "        3.8835e-04, 4.1083e-02, 6.1350e-03, 3.7603e-04, 3.7355e-04, 1.5097e-06,\n",
      "        1.2378e-01, 9.6165e-03, 4.4060e-04, 1.1560e-05, 9.1940e-05, 6.5692e-04,\n",
      "        2.6627e-05, 8.7166e-02, 7.1659e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4677e-06, 3.7586e-02, 4.6848e-02, 8.2018e-02, 5.5799e-02, 3.4503e-02,\n",
      "        5.7606e-02, 4.0030e-02, 4.7801e-02, 3.9916e-02, 9.1002e-03, 4.5141e-03,\n",
      "        2.8888e-02, 7.5255e-02, 2.2590e-02, 5.5621e-02, 6.9646e-02, 3.4936e-03,\n",
      "        5.2189e-02, 1.3155e-01, 3.0196e-02, 2.0638e-02, 1.8421e-02, 3.3374e-02,\n",
      "        3.0593e-05, 2.3425e-03, 3.9508e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.2881e-04, 1.5240e-03, 4.1707e-04, 9.0956e-05, 1.2138e-01, 7.1477e-04,\n",
      "        1.4339e-02, 1.9047e-02, 3.2483e-04, 2.3293e-05, 8.3879e-06, 5.8788e-04,\n",
      "        3.7119e-03, 1.5318e-01, 5.7572e-01, 2.7551e-04, 1.6339e-03, 2.2784e-04,\n",
      "        1.2147e-02, 2.6350e-02, 6.3646e-02, 9.4400e-05, 1.9207e-03, 4.8489e-04,\n",
      "        1.1992e-03, 1.5788e-05, 1.1394e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2171e-02, 6.9586e-03, 8.1864e-04, 1.3679e-01, 1.9824e-01, 1.0863e-02,\n",
      "        1.4215e-01, 8.7166e-03, 4.2240e-04, 1.0743e-02, 2.1531e-02, 3.5527e-04,\n",
      "        2.9076e-03, 3.2472e-03, 6.6380e-03, 9.4723e-04, 4.8551e-04, 3.3473e-03,\n",
      "        5.2393e-04, 1.2450e-01, 2.6161e-01, 6.0022e-04, 3.9432e-02, 3.6988e-03,\n",
      "        1.2198e-03, 1.0694e-03, 5.4525e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.1614e-04, 2.3695e-03, 1.0470e-04, 1.0237e-02, 3.3593e-07, 5.0862e-03,\n",
      "        4.4295e-04, 6.5340e-06, 1.1335e-03, 6.4531e-02, 1.7540e-05, 3.1955e-05,\n",
      "        6.8645e-03, 1.5881e-03, 1.4057e-05, 5.9943e-03, 4.7955e-02, 1.0829e-04,\n",
      "        4.7768e-05, 1.6565e-03, 8.3368e-01, 1.4577e-02, 6.3291e-05, 1.6332e-03,\n",
      "        1.1310e-06, 1.1236e-03, 1.6877e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.2635e-04, 1.9707e-01, 3.4598e-06, 1.4975e-06, 1.4428e-07, 1.0696e-02,\n",
      "        3.5286e-05, 1.4227e-06, 4.2356e-04, 5.1820e-01, 1.1553e-06, 6.3789e-07,\n",
      "        1.3540e-03, 2.4100e-04, 6.6382e-05, 2.4953e-02, 2.6276e-05, 6.7416e-06,\n",
      "        2.3126e-01, 7.1261e-04, 9.6986e-06, 1.3075e-02, 5.8652e-07, 1.0582e-04,\n",
      "        4.5599e-06, 1.1137e-03, 4.0041e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.3700e-04, 9.7953e-03, 7.5638e-04, 9.8548e-02, 8.5730e-03, 7.9762e-04,\n",
      "        5.4954e-03, 2.2195e-03, 5.7114e-05, 4.9148e-05, 6.0363e-06, 8.8076e-05,\n",
      "        5.5884e-02, 3.4003e-02, 6.1507e-01, 1.5079e-02, 1.5467e-02, 2.8333e-04,\n",
      "        5.1698e-03, 3.0823e-03, 1.2031e-01, 3.4441e-04, 7.7270e-03, 2.8857e-05,\n",
      "        6.2946e-04, 1.9266e-07, 4.0142e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.6045e-03, 8.2417e-02, 1.5867e-04, 6.5259e-03, 2.7419e-04, 5.9119e-03,\n",
      "        4.6562e-03, 3.8424e-04, 2.9393e-03, 1.7011e-01, 1.1150e-05, 2.5718e-05,\n",
      "        1.4403e-03, 4.7844e-04, 1.5478e-03, 2.3692e-03, 1.5804e-03, 1.0353e-04,\n",
      "        1.5662e-03, 1.8324e-02, 9.0300e-03, 6.2068e-01, 1.2992e-04, 3.5968e-04,\n",
      "        8.7162e-06, 6.3301e-02, 5.9443e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.0419e-04, 9.1897e-02, 1.3517e-03, 3.0734e-02, 2.9807e-03, 3.4903e-01,\n",
      "        2.9339e-03, 2.3798e-04, 6.7860e-06, 3.1358e-04, 1.4662e-05, 4.3116e-05,\n",
      "        1.5253e-02, 4.3651e-03, 1.2402e-01, 2.3245e-01, 8.6790e-04, 1.3392e-04,\n",
      "        2.7940e-04, 1.6115e-02, 8.3960e-02, 2.5379e-04, 4.2102e-02, 3.9538e-05,\n",
      "        2.7427e-05, 1.4387e-05, 2.7717e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5696e-03, 2.0676e-04, 7.5979e-06, 1.5160e-04, 1.1982e-02, 6.7796e-05,\n",
      "        2.6092e-04, 1.4073e-05, 2.2540e-06, 1.8996e-04, 5.3763e-07, 7.6082e-06,\n",
      "        5.5960e-04, 1.8548e-03, 3.3761e-02, 2.3742e-06, 6.6350e-05, 5.5936e-06,\n",
      "        2.1442e-03, 9.4353e-01, 2.5376e-03, 3.7776e-04, 3.8941e-04, 2.7215e-04,\n",
      "        2.3161e-05, 1.2813e-05, 5.4996e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.9893e-01, 8.9117e-05, 1.8460e-06, 7.7779e-05, 2.8356e-06, 4.0450e-04,\n",
      "        7.8729e-05, 2.3865e-07, 3.6185e-04, 1.8781e-04, 1.6712e-07, 1.2842e-05,\n",
      "        2.0756e-05, 5.7253e-04, 2.4127e-05, 4.1992e-05, 1.1433e-04, 2.8021e-06,\n",
      "        3.1435e-06, 7.0271e-02, 2.8655e-02, 6.5388e-05, 8.0333e-07, 5.7178e-05,\n",
      "        3.6331e-08, 2.6476e-05, 3.7937e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.0272e-07, 2.7187e-01, 1.4866e-02, 1.9131e-02, 6.0295e-03, 5.7348e-03,\n",
      "        3.7995e-02, 3.0616e-03, 3.9043e-02, 6.2041e-02, 2.3698e-03, 8.7180e-04,\n",
      "        8.6918e-03, 1.8619e-02, 8.6555e-03, 2.1841e-01, 8.9299e-03, 5.3041e-04,\n",
      "        5.9198e-03, 5.1089e-02, 1.4065e-01, 1.0056e-02, 2.3170e-03, 5.9815e-02,\n",
      "        9.7314e-06, 3.2703e-03, 2.4055e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.5927e-05, 1.7659e-05, 3.2785e-03, 2.4521e-03, 4.6521e-04, 3.6718e-05,\n",
      "        8.8031e-01, 1.5325e-04, 4.3997e-05, 2.2709e-05, 3.5713e-05, 2.4747e-05,\n",
      "        2.2627e-03, 2.2076e-04, 5.1919e-02, 1.5119e-04, 5.2388e-03, 4.8653e-05,\n",
      "        2.8892e-02, 2.4216e-05, 5.0123e-03, 7.6290e-03, 6.2274e-03, 5.4091e-03,\n",
      "        2.5745e-05, 2.4065e-06, 3.1712e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.9002e-01, 2.7437e-05, 1.1352e-05, 7.3869e-05, 5.6746e-05, 2.3888e-04,\n",
      "        6.0039e-03, 4.3011e-06, 4.7643e-06, 7.2027e-06, 2.8165e-05, 7.7787e-06,\n",
      "        4.3316e-04, 2.3490e-04, 1.5123e-06, 2.2012e-05, 7.8546e-05, 8.4042e-06,\n",
      "        7.8020e-05, 7.5139e-06, 2.3280e-03, 6.1654e-06, 2.3575e-04, 6.1512e-05,\n",
      "        1.6859e-06, 1.5552e-05, 3.0702e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.3979e-06, 9.5300e-02, 1.3457e-02, 3.7063e-02, 2.3873e-02, 4.5294e-02,\n",
      "        3.3870e-02, 1.3702e-02, 5.9460e-02, 4.5826e-02, 1.0823e-02, 8.2842e-03,\n",
      "        2.7342e-02, 5.1904e-02, 1.7542e-02, 4.0785e-02, 4.6571e-02, 8.5317e-04,\n",
      "        6.3884e-02, 8.1443e-02, 1.9944e-01, 4.2449e-03, 1.9678e-02, 5.1865e-02,\n",
      "        7.5007e-05, 7.3077e-03, 1.1504e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.0724e-05, 2.7439e-01, 7.3922e-05, 1.3125e-04, 3.5885e-07, 1.2369e-01,\n",
      "        9.5843e-04, 4.7115e-06, 1.3967e-04, 1.4099e-01, 2.1589e-05, 2.4911e-06,\n",
      "        6.8836e-02, 2.7571e-05, 5.3317e-05, 8.6226e-02, 1.7116e-05, 8.3197e-05,\n",
      "        2.6102e-01, 2.7248e-07, 6.2209e-04, 4.1908e-02, 1.4461e-04, 3.3729e-04,\n",
      "        7.2446e-05, 1.7506e-04, 1.4295e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2247e-05, 1.7152e-01, 2.0342e-05, 1.3433e-02, 6.0670e-05, 6.0560e-01,\n",
      "        4.0880e-05, 1.2637e-03, 4.3606e-04, 1.7067e-02, 1.6100e-05, 1.2955e-04,\n",
      "        9.5648e-02, 5.9281e-03, 4.8808e-03, 3.4737e-04, 2.5582e-04, 8.9068e-05,\n",
      "        4.2963e-02, 1.5860e-03, 3.5160e-02, 6.6012e-05, 8.2884e-05, 8.9811e-04,\n",
      "        2.0010e-03, 4.5188e-04, 2.9796e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.6144e-03, 2.1099e-04, 3.1073e-05, 2.9546e-04, 1.0787e-02, 1.3660e-04,\n",
      "        4.8738e-05, 1.0116e-04, 5.1949e-05, 1.4526e-03, 4.4215e-06, 3.0232e-04,\n",
      "        9.5489e-01, 1.5893e-03, 7.3015e-03, 3.7455e-05, 4.4385e-04, 5.7796e-06,\n",
      "        1.0101e-02, 2.3245e-04, 7.3932e-03, 4.7424e-05, 9.8382e-05, 1.7612e-03,\n",
      "        5.2380e-05, 3.4009e-06, 6.1975e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3124e-01, 1.8016e-03, 2.3619e-03, 1.2792e-04, 3.5453e-03, 2.2685e-02,\n",
      "        3.4450e-03, 3.7273e-05, 1.0650e-05, 6.2812e-01, 1.6107e-06, 1.1693e-04,\n",
      "        5.8853e-03, 5.4180e-04, 1.6612e-03, 4.1200e-02, 9.6791e-04, 1.4974e-05,\n",
      "        1.1845e-03, 1.3293e-01, 6.3780e-03, 6.5902e-03, 8.8664e-04, 3.6967e-03,\n",
      "        3.6336e-05, 4.4647e-03, 7.1347e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "the efficacy of her results in actual fa <------ | ------> rstal senses hard the instities of feel \n",
      "Epoch 12   Time 62.594    Train Loss: 1.265\n",
      "Softmaxed: tensor([2.6604e-04, 2.8130e-02, 2.6440e-03, 4.4404e-03, 8.3195e-03, 1.2513e-03,\n",
      "        2.8131e-02, 5.0245e-03, 3.7169e-04, 8.7717e-04, 3.5470e-04, 1.4526e-05,\n",
      "        1.8377e-02, 2.8356e-02, 2.6203e-01, 2.6431e-03, 6.9940e-03, 1.5058e-02,\n",
      "        1.1192e-02, 4.4551e-02, 1.5099e-02, 3.7119e-02, 3.2174e-01, 2.9023e-03,\n",
      "        1.4198e-01, 1.1957e-02, 1.7695e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.6191e-03, 1.0281e-01, 4.8605e-05, 2.7144e-01, 9.3361e-06, 4.3400e-02,\n",
      "        2.3430e-03, 1.5528e-03, 3.0383e-03, 1.6923e-01, 3.1169e-04, 7.9922e-04,\n",
      "        5.3599e-03, 9.4605e-03, 1.1456e-05, 1.8789e-02, 1.9520e-01, 4.0050e-04,\n",
      "        3.0960e-03, 3.2254e-03, 9.8771e-02, 6.6607e-02, 4.1743e-04, 1.7521e-03,\n",
      "        1.6368e-04, 1.2004e-04, 3.0320e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2437e-07, 1.0438e-02, 2.4158e-06, 2.8809e-04, 1.5074e-05, 7.6337e-01,\n",
      "        1.3489e-05, 8.3546e-06, 1.4796e-02, 6.4823e-02, 1.0661e-05, 3.5732e-04,\n",
      "        2.1596e-03, 1.1543e-05, 7.4590e-07, 1.9090e-02, 2.3220e-05, 1.4197e-04,\n",
      "        1.0851e-01, 1.3255e-03, 7.0070e-05, 1.4291e-02, 4.1385e-06, 1.8063e-06,\n",
      "        3.4877e-06, 2.4577e-04, 1.0047e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.1784e-02, 6.4694e-02, 1.7451e-03, 5.6129e-03, 2.0129e-02, 1.0341e-02,\n",
      "        2.2947e-02, 2.8101e-04, 3.6496e-06, 3.7282e-02, 6.1197e-05, 2.1476e-05,\n",
      "        1.8770e-02, 3.4085e-02, 3.8454e-02, 1.3601e-03, 5.8481e-01, 5.2303e-04,\n",
      "        4.1706e-02, 7.4494e-02, 5.3994e-03, 3.2522e-03, 1.8315e-03, 4.3803e-03,\n",
      "        5.8122e-03, 2.0302e-04, 1.5152e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.4135e-04, 5.8624e-04, 2.7602e-05, 1.8016e-03, 6.8947e-05, 9.0394e-04,\n",
      "        3.3207e-05, 6.3035e-06, 2.6751e-04, 3.2188e-03, 4.2425e-06, 3.8816e-06,\n",
      "        6.1134e-03, 5.7536e-04, 5.0561e-05, 2.1479e-03, 2.2063e-03, 2.4266e-06,\n",
      "        1.7886e-03, 5.1308e-04, 9.7895e-01, 2.5472e-04, 3.4143e-05, 8.2162e-06,\n",
      "        4.9400e-06, 8.1957e-05, 4.4539e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.2920e-01, 5.1522e-02, 1.0168e-05, 1.1549e-05, 3.3739e-06, 1.6443e-02,\n",
      "        2.5280e-04, 8.2152e-07, 1.8552e-03, 6.5971e-01, 6.9714e-07, 1.8831e-06,\n",
      "        8.7441e-03, 2.0520e-04, 1.3934e-05, 4.4219e-03, 8.0989e-05, 3.3590e-06,\n",
      "        1.4289e-03, 2.0154e-02, 4.5295e-05, 3.9502e-03, 1.0398e-06, 1.1092e-04,\n",
      "        3.8413e-07, 1.8205e-03, 3.1406e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.3000e-04, 2.9221e-02, 3.0754e-03, 9.3028e-03, 3.1522e-04, 6.9903e-03,\n",
      "        9.8791e-04, 4.0624e-04, 1.0376e-05, 1.5491e-04, 2.1988e-06, 7.9753e-06,\n",
      "        3.3783e-04, 2.5050e-03, 1.8421e-02, 9.0993e-01, 5.4032e-04, 6.5811e-05,\n",
      "        3.1873e-04, 9.5689e-04, 2.6485e-03, 1.2942e-04, 1.2819e-02, 1.0540e-05,\n",
      "        1.2283e-05, 6.4638e-07, 1.0123e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.7151e-04, 9.5103e-06, 2.1697e-06, 2.6486e-05, 7.9402e-05, 9.9609e-07,\n",
      "        4.1433e-05, 1.9559e-05, 3.4534e-08, 9.4914e-06, 2.4345e-07, 1.0922e-05,\n",
      "        2.6941e-04, 2.0261e-04, 9.9761e-01, 1.1112e-06, 1.2019e-04, 7.0023e-07,\n",
      "        2.9711e-04, 4.1559e-04, 3.4182e-05, 6.6327e-04, 5.1771e-06, 2.3115e-06,\n",
      "        1.9821e-06, 1.5126e-08, 8.7101e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.9705e-01, 2.6868e-02, 8.7335e-07, 8.8817e-05, 6.2207e-04, 2.8748e-03,\n",
      "        2.1413e-05, 2.0740e-06, 1.9309e-06, 1.4735e-03, 1.4436e-07, 3.8544e-07,\n",
      "        2.0134e-04, 9.3323e-05, 3.2828e-05, 3.2796e-04, 2.9421e-06, 7.4941e-07,\n",
      "        4.5410e-06, 1.7011e-01, 5.9840e-05, 1.7441e-05, 2.8785e-07, 6.5763e-06,\n",
      "        2.3115e-07, 1.3676e-04, 4.7781e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([1.8989e-07, 1.9238e-01, 1.6965e-02, 1.4731e-02, 5.4787e-03, 1.7684e-02,\n",
      "        3.5543e-02, 3.5841e-03, 2.4724e-02, 8.7618e-02, 2.0565e-03, 7.8187e-04,\n",
      "        9.8211e-03, 2.0529e-02, 1.7561e-02, 2.9634e-01, 1.2469e-02, 5.3245e-04,\n",
      "        7.6262e-03, 2.6605e-02, 1.2953e-01, 1.1466e-02, 5.0740e-03, 5.9452e-02,\n",
      "        1.2747e-05, 1.4155e-03, 1.6777e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.0612e-02, 2.0441e-04, 1.1664e-04, 3.0993e-05, 4.5649e-03, 1.4797e-04,\n",
      "        1.3865e-02, 6.7861e-04, 1.4303e-04, 3.6468e-06, 1.3258e-06, 7.2164e-06,\n",
      "        8.7171e-04, 2.4265e-02, 4.3183e-01, 1.6127e-04, 6.6985e-04, 3.4383e-05,\n",
      "        3.4790e-04, 3.4935e-01, 1.4145e-01, 6.5485e-06, 3.7970e-04, 2.1779e-04,\n",
      "        4.4911e-05, 1.0073e-06, 5.9153e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.4263e-01, 9.4462e-05, 4.6284e-06, 2.1802e-05, 6.2956e-06, 9.2237e-05,\n",
      "        5.4358e-04, 3.9483e-06, 3.8018e-04, 3.7244e-05, 3.2871e-06, 1.0356e-06,\n",
      "        6.5645e-05, 1.3605e-04, 1.8095e-06, 3.6344e-06, 2.5901e-05, 3.8512e-06,\n",
      "        5.7376e-05, 2.5563e-01, 8.1949e-05, 8.1704e-05, 6.5158e-06, 5.7764e-05,\n",
      "        1.1178e-07, 2.7296e-05, 2.9075e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.6103e-07, 4.1284e-02, 3.1425e-02, 1.0172e-02, 6.6289e-03, 2.8377e-02,\n",
      "        1.3554e-02, 8.9770e-03, 5.0190e-02, 4.1210e-01, 3.0266e-03, 2.6607e-03,\n",
      "        7.0322e-03, 5.3217e-02, 2.9435e-02, 9.2053e-03, 3.3903e-02, 2.3751e-04,\n",
      "        2.4947e-02, 5.2673e-02, 3.5375e-02, 1.8448e-02, 7.9847e-03, 1.1453e-01,\n",
      "        3.4156e-06, 4.6061e-03, 1.3272e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.8363e-05, 8.4303e-02, 4.3779e-06, 3.8886e-07, 5.1919e-08, 4.3970e-02,\n",
      "        6.7319e-05, 2.9448e-06, 6.2040e-01, 6.6148e-03, 2.2897e-06, 1.1832e-05,\n",
      "        1.8544e-04, 2.8386e-05, 2.3180e-06, 1.9978e-01, 2.7788e-06, 3.0038e-06,\n",
      "        3.8979e-02, 7.4014e-05, 4.0439e-06, 4.1662e-03, 1.3980e-06, 4.3643e-04,\n",
      "        2.9936e-07, 8.9194e-04, 1.1453e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.0352e-05, 1.5288e-01, 6.7618e-07, 5.4962e-09, 2.1642e-07, 7.5261e-01,\n",
      "        6.2116e-07, 1.0784e-06, 6.4247e-06, 7.6619e-02, 1.1336e-06, 9.6378e-07,\n",
      "        2.1019e-05, 9.2837e-05, 5.1268e-05, 1.0684e-02, 1.4898e-06, 4.4226e-08,\n",
      "        4.2310e-03, 1.9424e-04, 2.7419e-06, 1.3276e-03, 3.5089e-08, 1.0711e-04,\n",
      "        1.9200e-06, 1.0716e-03, 5.9861e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.2581e-01, 2.1570e-04, 3.0051e-05, 7.4540e-06, 2.0226e-05, 7.0495e-04,\n",
      "        6.5205e-05, 4.2061e-04, 1.4363e-03, 3.4851e-02, 1.9105e-05, 7.1562e-05,\n",
      "        4.2668e-04, 6.4732e-02, 6.2448e-03, 4.6552e-04, 4.1832e-04, 2.8644e-06,\n",
      "        1.3082e-01, 1.3912e-02, 1.0524e-03, 1.4962e-05, 1.3324e-04, 9.2897e-04,\n",
      "        5.1984e-05, 1.1707e-01, 8.2142e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.8628e-01, 3.3657e-03, 2.2375e-04, 5.0608e-06, 2.6140e-05, 1.0061e-02,\n",
      "        8.9953e-05, 1.3636e-05, 1.4011e-05, 3.1532e-03, 3.3395e-06, 7.7848e-07,\n",
      "        1.6080e-04, 3.6566e-04, 1.1366e-04, 1.5755e-03, 7.9911e-04, 1.9670e-07,\n",
      "        1.2523e-03, 4.9211e-01, 2.9812e-05, 6.3625e-05, 7.0575e-06, 6.3515e-05,\n",
      "        7.8084e-07, 2.0881e-04, 5.7533e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.1793e-02, 1.1595e-03, 3.5843e-05, 1.0212e-04, 1.8871e-07, 9.6209e-01,\n",
      "        3.8368e-05, 3.4135e-06, 8.2402e-04, 1.4170e-02, 9.1466e-07, 1.1534e-05,\n",
      "        2.5968e-04, 5.9171e-04, 4.1180e-05, 1.8002e-03, 3.7804e-04, 3.8272e-07,\n",
      "        1.2278e-04, 4.7177e-05, 2.5336e-03, 3.6802e-04, 3.6230e-07, 1.8594e-04,\n",
      "        1.4003e-07, 3.4401e-03, 1.7883e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.3769e-02, 3.6964e-05, 6.6163e-05, 1.8907e-04, 9.9912e-04, 1.6374e-04,\n",
      "        1.6058e-04, 1.4462e-04, 8.6343e-05, 1.2254e-04, 2.6716e-06, 1.0304e-06,\n",
      "        9.7132e-01, 1.3341e-04, 8.3337e-05, 4.6113e-05, 3.0730e-05, 5.0874e-05,\n",
      "        8.2209e-03, 2.0626e-03, 1.3128e-04, 7.6634e-06, 3.8620e-04, 1.0282e-04,\n",
      "        4.4221e-05, 1.6273e-03, 5.6117e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.7197e-04, 1.7405e-05, 1.1579e-04, 4.3881e-05, 1.8738e-04, 5.1655e-04,\n",
      "        4.6008e-02, 1.4863e-05, 2.9059e-07, 4.8970e-04, 5.3788e-06, 4.2551e-06,\n",
      "        3.9763e-04, 1.4770e-05, 4.5734e-05, 2.2974e-04, 8.0352e-05, 2.1849e-06,\n",
      "        9.4064e-06, 2.0956e-04, 1.3474e-04, 4.8029e-04, 9.4986e-01, 6.7227e-05,\n",
      "        3.8803e-06, 6.7805e-04, 1.1412e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.3851e-05, 9.3484e-03, 7.7009e-07, 3.2137e-07, 6.9249e-07, 9.7843e-01,\n",
      "        4.3763e-06, 2.0365e-07, 3.1227e-07, 8.7892e-03, 1.2147e-07, 1.0412e-07,\n",
      "        2.4222e-06, 7.8987e-07, 2.1673e-06, 1.6433e-03, 3.6391e-07, 7.3361e-08,\n",
      "        6.6993e-06, 5.9810e-05, 2.0334e-05, 3.3356e-06, 1.6174e-07, 2.0358e-06,\n",
      "        7.1471e-08, 1.6742e-03, 6.6797e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.4972e-03, 9.1198e-06, 9.5073e-05, 6.1482e-05, 3.5469e-03, 3.1888e-06,\n",
      "        1.2296e-04, 1.2323e-05, 4.6036e-07, 5.1884e-06, 2.6305e-06, 5.4056e-07,\n",
      "        3.1754e-05, 1.8125e-04, 2.2342e-03, 9.3723e-07, 3.4240e-05, 6.1040e-07,\n",
      "        4.1490e-04, 9.8460e-01, 3.8457e-05, 2.5761e-06, 1.1386e-05, 3.9447e-05,\n",
      "        2.9343e-06, 4.5831e-05, 8.2319e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.7558e-01, 1.8956e-04, 1.8132e-05, 2.7748e-05, 7.8211e-07, 1.3051e-02,\n",
      "        1.9556e-04, 1.9815e-05, 2.5926e-04, 8.9466e-04, 2.7726e-07, 6.0450e-05,\n",
      "        8.6759e-06, 8.0188e-05, 4.3606e-05, 1.8189e-04, 1.6636e-04, 2.1226e-06,\n",
      "        2.8333e-06, 8.5919e-03, 2.4499e-04, 2.5167e-04, 7.8457e-07, 3.6916e-05,\n",
      "        5.1902e-08, 9.0861e-05, 2.0103e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5935e-07, 1.5800e-01, 5.5400e-02, 2.2768e-02, 1.7206e-02, 2.4755e-02,\n",
      "        3.6847e-02, 1.9507e-02, 4.1481e-02, 1.1515e-01, 2.3505e-03, 2.1520e-03,\n",
      "        9.5614e-03, 2.4544e-02, 6.8748e-02, 4.2792e-02, 5.5921e-02, 4.7816e-04,\n",
      "        9.8969e-03, 1.0172e-01, 9.5260e-02, 1.3954e-02, 3.0183e-03, 7.4475e-02,\n",
      "        8.3420e-06, 3.9925e-03, 2.1298e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.5009e-02, 2.1924e-04, 1.8980e-04, 3.4066e-05, 6.6918e-03, 2.4619e-04,\n",
      "        2.4958e-02, 7.5963e-04, 1.6551e-04, 6.8311e-06, 1.2022e-06, 1.2486e-05,\n",
      "        2.0665e-03, 3.6818e-02, 4.7440e-01, 2.7589e-04, 1.2341e-03, 6.0138e-05,\n",
      "        1.7139e-03, 2.7810e-01, 1.1633e-01, 1.1497e-05, 3.7732e-04, 2.5504e-04,\n",
      "        5.8141e-05, 3.3294e-06, 8.3370e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9844e-01, 7.0847e-06, 1.7857e-06, 1.1496e-04, 5.2637e-06, 1.0127e-04,\n",
      "        4.7350e-05, 4.4691e-07, 4.0908e-05, 6.1645e-06, 2.8623e-07, 2.1110e-06,\n",
      "        3.5771e-05, 4.0195e-04, 1.4768e-06, 1.8629e-06, 8.1615e-05, 7.4570e-07,\n",
      "        2.0351e-06, 4.1670e-04, 2.1156e-04, 4.8984e-05, 7.7105e-07, 2.1095e-05,\n",
      "        9.4712e-08, 5.2409e-06, 2.0261e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([4.3319e-07, 1.2558e-01, 1.8376e-02, 2.6237e-02, 3.9604e-02, 4.1151e-02,\n",
      "        1.7022e-02, 2.5701e-02, 2.4499e-02, 8.0623e-02, 5.9599e-03, 8.3777e-03,\n",
      "        2.2875e-02, 4.5332e-02, 1.0552e-01, 6.1769e-02, 5.3743e-02, 7.0550e-04,\n",
      "        3.5031e-02, 7.0307e-02, 1.2977e-01, 1.7243e-02, 1.1890e-02, 3.1297e-02,\n",
      "        3.2901e-05, 1.3340e-03, 2.1653e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1199e-07, 6.7526e-02, 1.7241e-05, 1.6677e-06, 7.6184e-07, 6.9809e-01,\n",
      "        2.1317e-06, 5.4732e-05, 1.9406e-04, 8.3934e-02, 1.0332e-06, 4.5287e-07,\n",
      "        1.2005e-04, 3.1921e-06, 2.1206e-04, 7.5665e-02, 8.3281e-07, 4.1290e-06,\n",
      "        2.3401e-05, 2.4234e-06, 1.3989e-06, 7.2227e-02, 3.9713e-06, 2.8924e-05,\n",
      "        2.8564e-06, 1.8834e-03, 8.4381e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.0698e-04, 2.2821e-01, 5.4078e-03, 4.4337e-02, 4.6765e-03, 1.1586e-03,\n",
      "        3.6447e-02, 1.6743e-01, 1.2598e-03, 3.0954e-03, 2.2298e-03, 1.0155e-04,\n",
      "        1.6054e-01, 3.1632e-02, 2.8250e-02, 9.7198e-04, 8.4512e-02, 2.4870e-02,\n",
      "        2.7046e-03, 9.0877e-02, 1.4081e-02, 5.0101e-04, 6.2946e-02, 1.8658e-03,\n",
      "        5.0490e-04, 4.1117e-04, 7.1719e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5058e-06, 7.7774e-01, 3.0768e-03, 9.3526e-06, 5.7833e-06, 2.0781e-02,\n",
      "        9.0593e-06, 1.5019e-05, 1.0037e-04, 4.7190e-02, 2.2281e-05, 1.7791e-07,\n",
      "        1.4507e-04, 2.5247e-04, 1.0223e-04, 1.1589e-01, 6.3870e-03, 6.7559e-07,\n",
      "        1.9928e-03, 6.7901e-05, 1.9688e-05, 2.5397e-02, 2.9242e-05, 5.7653e-05,\n",
      "        1.8641e-06, 6.7045e-04, 2.6766e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9875e-04, 2.1919e-04, 5.9590e-03, 7.9401e-03, 4.8204e-03, 6.1231e-04,\n",
      "        1.0509e-04, 2.1929e-02, 1.9584e-05, 4.5386e-01, 3.1174e-04, 2.1911e-03,\n",
      "        9.6553e-03, 3.7512e-03, 5.1858e-02, 1.6576e-04, 7.6493e-03, 8.1948e-06,\n",
      "        3.7700e-01, 3.1720e-03, 2.9547e-02, 1.1364e-02, 1.0544e-04, 3.7863e-04,\n",
      "        2.8222e-04, 6.0942e-03, 8.0300e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5675e-03, 2.6331e-04, 2.0607e-04, 3.7365e-04, 3.6614e-03, 1.0905e-03,\n",
      "        2.1037e-05, 1.5511e-03, 2.6559e-05, 1.2154e-05, 2.3660e-06, 9.3046e-05,\n",
      "        6.4933e-02, 1.1594e-03, 8.7451e-01, 1.3936e-03, 3.3660e-04, 2.5887e-05,\n",
      "        2.9949e-02, 6.8832e-03, 1.1736e-02, 4.1472e-05, 3.8169e-05, 1.9395e-06,\n",
      "        7.3776e-05, 3.6262e-07, 4.6551e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5170e-07, 2.2495e-01, 1.5793e-02, 2.6998e-03, 1.5917e-02, 1.7895e-02,\n",
      "        9.9528e-03, 7.3577e-03, 1.3659e-02, 1.7786e-01, 1.4576e-03, 9.2773e-04,\n",
      "        3.4963e-02, 4.6295e-02, 1.8743e-02, 1.7729e-01, 2.0373e-02, 1.1212e-03,\n",
      "        5.1225e-02, 7.4857e-02, 4.2912e-02, 1.5959e-02, 7.5207e-04, 2.5599e-02,\n",
      "        1.3379e-05, 1.3388e-03, 8.8484e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.4820e-05, 1.5698e-01, 8.0306e-06, 1.6555e-07, 5.0760e-08, 1.3798e-02,\n",
      "        6.5142e-05, 1.1371e-06, 5.2144e-01, 1.6921e-02, 2.9120e-07, 3.6164e-06,\n",
      "        1.1064e-04, 1.0487e-05, 9.5559e-06, 2.7156e-01, 3.1531e-06, 2.0810e-06,\n",
      "        1.2068e-02, 6.0175e-05, 1.2837e-05, 2.6894e-03, 4.8558e-07, 1.0534e-03,\n",
      "        1.0978e-07, 3.1503e-03, 9.0225e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.3935e-04, 2.3558e-01, 3.1349e-06, 5.8404e-08, 5.4610e-07, 4.8522e-01,\n",
      "        7.5135e-06, 1.1738e-06, 3.7743e-05, 1.4560e-01, 2.1579e-06, 8.0137e-07,\n",
      "        1.1753e-04, 2.6532e-04, 4.9814e-04, 7.6676e-02, 9.0636e-06, 2.8889e-07,\n",
      "        4.6342e-02, 6.1494e-04, 7.2675e-05, 7.2397e-03, 7.8071e-08, 2.8110e-04,\n",
      "        2.7436e-06, 7.9323e-04, 2.4124e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.2896e-03, 1.2360e-05, 2.9845e-05, 4.6397e-04, 2.4528e-04, 4.0930e-05,\n",
      "        1.1772e-04, 1.0862e-03, 1.0038e-04, 2.0396e-06, 3.1674e-06, 2.9777e-04,\n",
      "        6.0059e-03, 4.3539e-03, 6.4159e-01, 7.6298e-05, 8.5536e-05, 1.9726e-07,\n",
      "        8.1264e-03, 3.3264e-01, 2.9843e-03, 4.1507e-05, 5.2909e-05, 3.1999e-05,\n",
      "        1.1225e-04, 1.0196e-06, 2.1481e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.9506e-03, 1.3799e-04, 4.8889e-07, 1.3773e-04, 1.2744e-02, 2.1574e-04,\n",
      "        2.0463e-05, 9.0051e-01, 4.6340e-05, 5.5014e-05, 1.3932e-05, 7.6973e-02,\n",
      "        4.5380e-06, 2.5956e-06, 2.6606e-04, 3.0471e-05, 3.2412e-07, 2.5911e-06,\n",
      "        3.0462e-07, 7.1384e-04, 1.0662e-04, 3.1584e-05, 3.1993e-06, 8.4239e-07,\n",
      "        3.0258e-05, 1.7850e-06, 1.7148e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.8360e-01, 9.0034e-05, 1.1056e-05, 3.0597e-06, 1.2893e-04, 1.1710e-03,\n",
      "        1.2414e-05, 4.5062e-05, 1.2999e-03, 1.8913e-04, 2.9751e-06, 1.7431e-06,\n",
      "        9.9907e-04, 3.3531e-04, 8.8491e-05, 4.3315e-04, 1.9905e-05, 1.5783e-06,\n",
      "        8.9724e-06, 6.1117e-01, 1.5100e-04, 1.5824e-04, 1.3859e-05, 3.1427e-05,\n",
      "        2.4537e-06, 2.7447e-05, 2.1251e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9923e-01, 8.4230e-06, 1.1886e-06, 1.2612e-05, 5.0023e-08, 2.7631e-05,\n",
      "        4.8885e-05, 1.4987e-07, 1.1554e-04, 2.5132e-04, 4.2142e-08, 4.6697e-07,\n",
      "        4.7176e-07, 8.7802e-05, 3.1728e-06, 3.8642e-05, 6.6402e-06, 1.9360e-07,\n",
      "        2.8317e-06, 5.6041e-05, 8.1439e-05, 9.4070e-06, 8.2416e-09, 6.3510e-06,\n",
      "        1.6505e-08, 1.4209e-05, 2.5822e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.2231e-07, 2.1699e-01, 1.9294e-02, 2.5284e-02, 2.6205e-02, 1.0629e-02,\n",
      "        3.0071e-02, 9.8071e-03, 6.3526e-02, 8.0581e-02, 3.5317e-03, 2.5002e-03,\n",
      "        1.4104e-02, 3.3687e-02, 1.9434e-02, 1.2503e-01, 2.9007e-02, 8.6433e-04,\n",
      "        1.4769e-02, 5.3651e-02, 1.3503e-01, 1.4819e-02, 5.3903e-03, 6.4182e-02,\n",
      "        1.4091e-05, 1.5641e-03, 2.5026e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "ucinations had extraordinary vividness e <------ | ------> xception it themselves is remai things a\n",
      "Epoch 13   Time 63.334    Train Loss: 1.254\n",
      "Softmaxed: tensor([4.2956e-07, 2.0597e-01, 6.7506e-02, 5.5133e-02, 5.6131e-02, 4.7692e-02,\n",
      "        2.0831e-02, 1.7120e-02, 3.6403e-02, 8.2091e-02, 2.7090e-03, 2.8689e-03,\n",
      "        2.7758e-02, 4.5635e-02, 4.2693e-02, 2.8785e-02, 2.5253e-02, 1.7349e-03,\n",
      "        3.8798e-02, 4.7289e-02, 8.4642e-02, 2.0944e-02, 5.0335e-03, 3.5692e-02,\n",
      "        2.1742e-05, 1.2244e-03, 3.5720e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.5918e-07, 8.4785e-02, 7.4408e-05, 3.0239e-06, 2.8893e-05, 6.9826e-01,\n",
      "        2.9884e-06, 2.3401e-04, 6.0482e-05, 1.0576e-02, 5.3132e-05, 5.1879e-05,\n",
      "        1.2075e-02, 1.2006e-06, 1.0382e-04, 7.8059e-02, 2.3974e-05, 5.6810e-06,\n",
      "        1.9460e-02, 4.2828e-05, 5.4466e-05, 7.1782e-02, 1.5379e-05, 1.7306e-04,\n",
      "        1.0778e-05, 2.4059e-02, 5.8087e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.4887e-02, 5.3841e-02, 8.2530e-04, 1.9325e-01, 2.1371e-03, 1.8424e-01,\n",
      "        2.8377e-02, 2.0082e-02, 8.5095e-03, 1.0452e-01, 2.4265e-04, 4.0407e-04,\n",
      "        1.2213e-01, 5.5796e-04, 4.0224e-02, 1.4025e-03, 3.7157e-03, 8.6097e-04,\n",
      "        6.4678e-04, 3.5916e-02, 7.6442e-02, 1.3675e-03, 5.5670e-04, 1.6383e-02,\n",
      "        5.5798e-04, 7.8843e-03, 3.1064e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.1900e-08, 1.2281e-01, 3.8150e-02, 3.8908e-02, 1.0106e-01, 2.1828e-02,\n",
      "        2.3888e-02, 4.0352e-02, 6.2461e-03, 5.6762e-02, 2.9159e-03, 7.5835e-04,\n",
      "        5.0422e-02, 4.5312e-02, 1.8032e-02, 4.8145e-02, 9.7187e-02, 8.5010e-04,\n",
      "        6.4445e-02, 7.0838e-02, 7.8154e-02, 2.4837e-02, 1.0676e-02, 3.6106e-02,\n",
      "        8.3137e-05, 1.2168e-03, 9.5009e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4820e-03, 9.3476e-02, 8.1004e-04, 1.0085e-02, 5.0935e-03, 6.3924e-04,\n",
      "        2.5974e-02, 5.7529e-03, 1.1005e-03, 1.8798e-03, 5.7377e-04, 6.5103e-05,\n",
      "        3.9657e-02, 4.2217e-02, 7.4254e-02, 2.2836e-03, 4.2099e-03, 1.9324e-02,\n",
      "        2.2285e-02, 1.0201e-01, 1.9160e-02, 1.5493e-01, 9.6184e-02, 1.0652e-02,\n",
      "        2.3551e-01, 3.0200e-02, 1.9425e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1572e-03, 5.3313e-02, 3.9806e-05, 1.1764e-01, 1.0277e-05, 3.7059e-02,\n",
      "        3.2553e-03, 1.9884e-03, 3.9692e-03, 1.1368e-01, 2.8454e-04, 1.2748e-03,\n",
      "        3.4103e-03, 9.9081e-03, 1.1899e-05, 9.6486e-03, 3.4361e-01, 4.5411e-04,\n",
      "        4.6729e-03, 9.2509e-03, 2.6412e-01, 1.8182e-02, 2.7229e-04, 2.4593e-03,\n",
      "        1.5011e-04, 1.4247e-04, 4.1498e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4351e-03, 1.0097e-01, 1.1182e-05, 3.6373e-04, 4.1460e-06, 4.2266e-01,\n",
      "        6.7810e-04, 2.1225e-05, 1.8013e-02, 6.8099e-02, 1.2295e-05, 1.1681e-05,\n",
      "        7.1502e-03, 1.8121e-03, 4.5767e-05, 1.6840e-02, 1.0822e-03, 3.0020e-05,\n",
      "        3.5157e-01, 4.3823e-03, 1.0411e-04, 9.9595e-04, 5.2624e-06, 5.1737e-04,\n",
      "        1.7251e-05, 3.1095e-03, 4.9739e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([9.7202e-06, 5.3425e-01, 7.6435e-05, 6.8271e-05, 3.4289e-04, 7.4966e-02,\n",
      "        1.2808e-05, 1.4599e-04, 3.5542e-06, 2.4940e-01, 1.7861e-05, 4.3556e-05,\n",
      "        6.1492e-05, 2.2668e-03, 2.1400e-03, 1.0552e-01, 8.1901e-05, 4.0583e-06,\n",
      "        8.7388e-04, 1.3005e-05, 1.0576e-05, 2.6472e-02, 3.9098e-05, 8.1901e-06,\n",
      "        5.0390e-05, 3.1212e-03, 2.4317e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.7235e-04, 6.6582e-04, 1.6148e-02, 1.1059e-01, 3.0344e-01, 2.9286e-04,\n",
      "        1.4054e-03, 9.2910e-02, 9.0878e-06, 2.1447e-01, 1.5317e-03, 4.4252e-04,\n",
      "        2.9071e-02, 1.7276e-02, 6.5556e-02, 1.0565e-03, 5.2051e-03, 1.3968e-04,\n",
      "        3.2311e-02, 2.8800e-02, 3.6609e-02, 1.8136e-03, 1.5734e-02, 1.7432e-03,\n",
      "        9.0280e-04, 2.1130e-02, 5.7065e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.2904e-05, 1.8564e-03, 1.6024e-03, 9.6776e-03, 7.0417e-03, 5.0613e-03,\n",
      "        2.0451e-03, 1.1600e-03, 1.0079e-05, 2.7693e-04, 3.4811e-06, 2.7004e-05,\n",
      "        9.2146e-02, 1.3905e-03, 6.1004e-01, 9.4066e-03, 7.1482e-04, 3.4245e-04,\n",
      "        4.3820e-02, 1.5420e-01, 5.4948e-02, 5.4621e-04, 3.3835e-03, 1.5825e-05,\n",
      "        6.6395e-05, 2.0747e-05, 1.1404e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3915e-02, 1.2121e-02, 1.7623e-04, 6.5098e-03, 1.1542e-03, 6.2004e-01,\n",
      "        9.7114e-04, 1.0019e-02, 1.1029e-05, 1.7349e-02, 2.9340e-05, 7.1761e-06,\n",
      "        3.7147e-03, 1.5912e-03, 2.9634e-03, 5.5777e-03, 7.0449e-05, 4.8391e-05,\n",
      "        1.5477e-04, 1.7164e-01, 8.3872e-02, 7.6017e-03, 2.4648e-04, 6.3442e-05,\n",
      "        9.8151e-05, 4.3625e-05, 9.0701e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.5899e-01, 1.3629e-03, 2.7238e-03, 5.3913e-03, 7.0793e-01, 1.0878e-05,\n",
      "        1.0157e-03, 1.0217e-04, 1.1106e-05, 8.5827e-05, 8.3210e-06, 8.2555e-06,\n",
      "        3.8792e-03, 7.3534e-03, 1.1156e-03, 2.5165e-04, 3.9456e-04, 1.8505e-04,\n",
      "        2.3961e-02, 7.7761e-02, 5.8806e-03, 5.2773e-05, 8.4207e-04, 4.6144e-04,\n",
      "        1.1181e-04, 9.4455e-05, 1.6017e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7578e-01, 2.9594e-04, 1.9846e-05, 3.4368e-06, 7.5688e-06, 7.2262e-03,\n",
      "        2.0224e-05, 4.9688e-05, 1.5047e-05, 3.9315e-03, 2.9376e-07, 3.1180e-06,\n",
      "        5.0262e-03, 9.3845e-05, 8.0288e-05, 2.1241e-03, 9.6356e-07, 4.9203e-06,\n",
      "        1.0107e-05, 2.6159e-03, 5.2057e-05, 2.2779e-03, 5.6815e-06, 2.5193e-05,\n",
      "        1.4467e-06, 3.2596e-04, 4.7691e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.4047e-07, 1.4080e-01, 5.0750e-02, 4.8159e-02, 1.2299e-02, 1.0646e-02,\n",
      "        3.8179e-02, 1.4274e-02, 6.8774e-02, 8.1706e-02, 1.1825e-03, 1.8626e-03,\n",
      "        2.9772e-03, 1.4696e-02, 2.1107e-02, 3.1908e-02, 3.0787e-02, 1.0022e-03,\n",
      "        1.6360e-02, 5.4127e-02, 2.9868e-01, 1.0669e-02, 3.8538e-03, 4.0803e-02,\n",
      "        9.6033e-06, 4.3527e-03, 4.4860e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.9792e-05, 1.4413e-02, 8.4259e-06, 3.0041e-07, 1.3229e-07, 1.1242e-02,\n",
      "        1.0683e-04, 4.2900e-06, 4.6483e-01, 2.0072e-02, 9.1159e-07, 7.7303e-06,\n",
      "        2.6986e-04, 1.0793e-05, 8.5628e-06, 4.6882e-01, 9.3189e-07, 4.5454e-06,\n",
      "        1.2406e-02, 3.3999e-05, 9.2717e-06, 2.3758e-03, 4.8273e-07, 1.3599e-03,\n",
      "        2.2878e-07, 3.9584e-03, 1.6341e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.0713e-04, 2.4409e-01, 1.5826e-06, 3.2987e-09, 1.3070e-06, 6.3580e-01,\n",
      "        7.9623e-07, 7.1268e-07, 1.0806e-05, 5.8705e-02, 8.2861e-07, 4.4843e-07,\n",
      "        3.2115e-05, 4.7457e-05, 1.7103e-04, 2.7861e-02, 1.5790e-06, 6.4128e-08,\n",
      "        2.6246e-02, 2.1898e-04, 7.1567e-06, 6.0489e-03, 5.1227e-08, 1.1775e-04,\n",
      "        1.6655e-06, 4.3138e-04, 1.0620e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2703e-04, 3.7266e-07, 1.0749e-05, 7.5339e-06, 5.9884e-05, 2.7108e-06,\n",
      "        3.8883e-06, 1.7838e-05, 7.4690e-06, 3.1388e-04, 2.1982e-06, 7.6170e-04,\n",
      "        5.5150e-05, 2.2464e-04, 1.1762e-01, 1.5823e-06, 4.5613e-05, 8.6963e-09,\n",
      "        4.5184e-04, 1.5620e-03, 8.7835e-01, 4.6641e-05, 2.1625e-05, 1.0426e-04,\n",
      "        1.4234e-06, 8.0366e-05, 2.3570e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9764e-01, 2.5952e-06, 7.6258e-08, 8.3049e-07, 5.2878e-06, 5.0680e-04,\n",
      "        3.9577e-06, 4.7842e-07, 4.8633e-04, 3.4408e-04, 8.9334e-08, 1.9437e-05,\n",
      "        2.5342e-05, 2.6188e-06, 7.7838e-05, 7.0527e-06, 1.8926e-06, 1.5527e-07,\n",
      "        4.6288e-06, 6.4445e-04, 9.6589e-05, 1.0794e-04, 6.2581e-08, 1.3007e-05,\n",
      "        6.9143e-09, 9.7890e-06, 1.4800e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.2906e-07, 8.1978e-02, 2.4005e-02, 2.1880e-02, 3.4499e-02, 3.1588e-02,\n",
      "        2.1457e-02, 4.2624e-03, 7.1091e-02, 1.7000e-01, 5.1643e-03, 1.9937e-03,\n",
      "        1.1961e-02, 1.7847e-02, 3.3252e-02, 4.9011e-02, 1.4527e-02, 4.4777e-04,\n",
      "        2.0231e-02, 4.6283e-02, 2.4559e-01, 8.2973e-03, 6.8163e-03, 6.3715e-02,\n",
      "        4.4400e-06, 1.4054e-02, 5.3195e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.3679e-05, 2.6218e-03, 1.3150e-06, 1.5209e-07, 2.1822e-08, 5.7539e-03,\n",
      "        3.6062e-05, 1.2301e-06, 9.3045e-01, 2.3618e-03, 5.4821e-07, 6.2037e-06,\n",
      "        4.4711e-05, 7.3752e-06, 2.4752e-06, 5.4617e-02, 6.2632e-07, 1.3904e-06,\n",
      "        2.3772e-03, 9.0764e-06, 6.0484e-06, 9.8115e-04, 2.6012e-07, 4.1550e-04,\n",
      "        6.2708e-08, 2.5607e-04, 4.0844e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2850e-04, 1.0205e-01, 6.5747e-07, 5.1982e-09, 1.3043e-07, 7.9229e-01,\n",
      "        5.5950e-07, 6.3032e-07, 8.1811e-06, 7.5319e-02, 5.5276e-07, 2.8281e-07,\n",
      "        1.9117e-05, 2.2552e-05, 6.6790e-05, 2.0849e-02, 1.3018e-06, 3.7641e-08,\n",
      "        5.4528e-03, 9.5227e-05, 6.0213e-06, 3.3166e-03, 1.7454e-08, 6.9850e-05,\n",
      "        7.0254e-07, 3.0729e-04, 4.8072e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.7817e-01, 1.4432e-04, 2.3002e-05, 7.0646e-06, 1.5152e-05, 1.3234e-03,\n",
      "        8.8963e-05, 4.0988e-04, 1.2547e-03, 5.4812e-02, 2.0225e-05, 4.7077e-05,\n",
      "        4.6365e-04, 4.4860e-02, 1.2090e-02, 4.2903e-04, 4.5353e-04, 2.0685e-06,\n",
      "        1.1707e-01, 1.4054e-02, 1.1682e-03, 9.5934e-06, 7.9257e-05, 7.8227e-04,\n",
      "        2.9542e-05, 7.2106e-02, 9.4473e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.6418e-07, 4.7306e-02, 4.7457e-02, 1.0378e-01, 6.0407e-02, 3.6530e-02,\n",
      "        4.7177e-02, 4.6854e-02, 3.7888e-02, 3.8508e-02, 6.3416e-03, 3.1520e-03,\n",
      "        2.6154e-02, 6.7146e-02, 2.3534e-02, 5.3951e-02, 7.8183e-02, 6.2450e-03,\n",
      "        5.3957e-02, 1.0406e-01, 3.0918e-02, 1.9383e-02, 3.2462e-02, 2.6278e-02,\n",
      "        2.8110e-05, 2.2588e-03, 4.0313e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.1791e-06, 1.4223e-01, 3.3683e-05, 2.0973e-06, 1.9948e-06, 9.0996e-02,\n",
      "        1.9641e-05, 2.1946e-05, 1.4076e-01, 1.0794e-02, 1.8051e-05, 1.5336e-06,\n",
      "        4.2553e-02, 3.0680e-05, 5.2929e-05, 2.1166e-01, 1.3934e-03, 3.3380e-06,\n",
      "        3.0332e-01, 1.3075e-03, 8.2352e-04, 5.2941e-02, 1.6892e-05, 5.7123e-04,\n",
      "        6.4560e-05, 3.6087e-04, 1.2690e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.9182e-06, 2.2143e-02, 4.3365e-06, 6.4382e-07, 1.4328e-07, 4.6804e-02,\n",
      "        9.0257e-06, 5.7539e-07, 2.1168e-06, 8.4174e-01, 5.7081e-06, 6.9630e-09,\n",
      "        1.4991e-04, 9.3081e-06, 1.3321e-05, 1.7276e-02, 1.2688e-05, 6.4040e-08,\n",
      "        5.7574e-03, 2.5293e-04, 1.4538e-04, 1.2905e-03, 1.0303e-06, 1.8349e-04,\n",
      "        2.4187e-06, 6.4194e-02, 2.5785e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.2214e-06, 4.6024e-04, 1.0986e-04, 5.0826e-03, 8.8832e-04, 2.2632e-04,\n",
      "        2.3901e-04, 7.5189e-04, 2.8629e-05, 3.7075e-05, 2.3535e-05, 5.4131e-07,\n",
      "        9.4917e-01, 1.9542e-04, 2.1930e-02, 6.8941e-04, 9.8108e-05, 2.7026e-06,\n",
      "        2.2303e-03, 1.5162e-02, 2.3214e-03, 2.8462e-05, 7.2214e-05, 1.6647e-05,\n",
      "        3.9116e-05, 5.5551e-07, 1.9503e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1841e-03, 2.4690e-02, 2.1812e-04, 1.1740e-04, 1.7718e-03, 7.3573e-03,\n",
      "        1.7210e-03, 4.6649e-05, 1.1469e-04, 1.1523e-02, 2.3733e-06, 1.5029e-06,\n",
      "        8.4211e-03, 7.3860e-05, 3.1100e-05, 9.3561e-01, 3.6199e-05, 6.1666e-06,\n",
      "        3.7557e-05, 3.8203e-03, 9.2726e-04, 2.1641e-03, 3.8279e-05, 3.2214e-05,\n",
      "        3.3551e-06, 4.0484e-05, 7.9929e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.0710e-03, 9.5812e-05, 1.7872e-04, 1.5409e-03, 2.6146e-03, 3.4778e-04,\n",
      "        3.9266e-04, 1.4609e-03, 9.4294e-06, 1.5133e-04, 4.3721e-06, 7.6213e-06,\n",
      "        6.3632e-03, 5.7366e-03, 4.4698e-04, 3.9110e-03, 2.8830e-03, 1.3965e-05,\n",
      "        5.9060e-04, 9.6451e-01, 2.6116e-03, 5.9730e-04, 1.6396e-04, 2.0320e-03,\n",
      "        1.5807e-04, 3.2447e-06, 1.0153e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.2206e-04, 1.1046e-04, 6.0090e-05, 4.5866e-05, 1.4110e-06, 1.2054e-03,\n",
      "        1.1415e-04, 4.4381e-06, 2.0501e-03, 3.1616e-03, 3.4741e-07, 4.7130e-06,\n",
      "        2.2635e-06, 1.5742e-03, 4.3490e-05, 9.8781e-01, 6.9076e-04, 1.3616e-05,\n",
      "        2.7360e-05, 3.1857e-04, 1.9924e-03, 9.1889e-06, 1.1209e-06, 9.4471e-05,\n",
      "        4.8154e-07, 3.8197e-05, 3.3300e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.7622e-04, 6.6485e-06, 2.0620e-03, 2.5199e-03, 9.6530e-04, 2.5374e-06,\n",
      "        1.7756e-03, 2.3339e-04, 1.5737e-05, 6.3107e-05, 3.1001e-05, 4.9320e-05,\n",
      "        1.0005e-04, 3.7389e-03, 1.5555e-03, 4.2158e-05, 9.8048e-01, 1.1337e-04,\n",
      "        2.0555e-04, 1.5279e-03, 1.4505e-04, 2.2131e-03, 8.4516e-04, 3.3240e-04,\n",
      "        5.3329e-05, 2.6053e-06, 4.6683e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.3753e-04, 9.5688e-04, 1.3249e-05, 1.7526e-05, 2.1620e-05, 1.3815e-02,\n",
      "        3.9959e-06, 4.5409e-06, 9.7707e-01, 2.3602e-04, 1.7332e-05, 1.0004e-05,\n",
      "        1.9872e-04, 7.9312e-05, 7.3330e-06, 3.2240e-03, 7.8211e-04, 2.2326e-05,\n",
      "        1.4228e-03, 5.5597e-04, 1.2242e-04, 1.2875e-04, 8.1221e-06, 1.5828e-04,\n",
      "        3.3250e-05, 2.1906e-04, 3.2677e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.1710e-03, 3.2973e-03, 8.8339e-05, 2.2420e-06, 6.8448e-06, 4.4007e-01,\n",
      "        8.3930e-05, 1.2174e-05, 2.3397e-05, 1.0476e-01, 5.3156e-06, 1.5828e-07,\n",
      "        4.7006e-04, 4.8945e-05, 1.1377e-04, 3.8395e-03, 2.7601e-05, 7.1097e-07,\n",
      "        3.9826e-04, 1.9044e-03, 1.4069e-04, 1.5413e-04, 1.8014e-06, 1.3314e-04,\n",
      "        6.4912e-06, 4.4223e-01, 9.3567e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.3975e-03, 1.2302e-04, 1.6291e-04, 2.0060e-03, 3.3660e-03, 4.8093e-05,\n",
      "        1.4139e-04, 1.0350e-04, 1.9586e-04, 3.7286e-05, 5.0966e-06, 1.8575e-06,\n",
      "        1.4679e-03, 2.1130e-03, 7.1726e-03, 1.0902e-04, 3.5062e-04, 9.5411e-06,\n",
      "        9.1807e-01, 5.7398e-02, 3.2882e-03, 2.0355e-05, 1.5175e-04, 6.2165e-05,\n",
      "        7.1127e-05, 9.3330e-05, 3.6946e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.5234e-02, 1.3865e-03, 2.6372e-04, 4.8734e-03, 7.2959e-05, 3.1783e-02,\n",
      "        1.3241e-03, 3.1916e-05, 8.4836e-03, 4.4138e-03, 1.0000e-05, 3.0415e-04,\n",
      "        1.6076e-02, 1.5221e-03, 2.1875e-03, 7.3082e-03, 2.6375e-02, 4.6665e-04,\n",
      "        2.7747e-04, 2.3610e-02, 7.9149e-01, 6.4201e-04, 6.6194e-05, 1.3200e-03,\n",
      "        9.7999e-06, 3.8220e-04, 9.0728e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.5150e-01, 3.0825e-02, 9.4907e-06, 1.7112e-06, 1.8196e-05, 1.8062e-03,\n",
      "        4.0951e-04, 2.2008e-06, 1.4957e-03, 1.7844e-02, 2.2142e-06, 4.3727e-06,\n",
      "        3.1382e-03, 3.2822e-04, 8.8841e-05, 4.5642e-03, 7.6700e-05, 1.7826e-05,\n",
      "        1.5814e-03, 7.1583e-02, 4.5555e-06, 4.8351e-04, 5.8112e-06, 5.5171e-04,\n",
      "        6.9321e-06, 1.3611e-02, 3.7008e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.1887e-07, 1.9556e-01, 6.8249e-02, 2.3222e-02, 4.1895e-02, 2.3051e-02,\n",
      "        5.9293e-02, 9.3116e-03, 6.0099e-02, 5.4756e-02, 2.0847e-03, 1.2999e-03,\n",
      "        5.1838e-03, 2.4621e-02, 1.4747e-02, 1.2874e-01, 5.7553e-02, 3.2223e-03,\n",
      "        3.0870e-02, 3.5360e-02, 1.0643e-01, 1.2858e-02, 2.5251e-03, 3.7099e-02,\n",
      "        9.0933e-06, 1.8859e-03, 8.3815e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5629e-04, 6.8169e-02, 2.4337e-05, 4.4200e-05, 5.2411e-08, 7.6800e-02,\n",
      "        4.5399e-04, 4.0637e-07, 4.3608e-05, 7.4402e-02, 2.3778e-06, 1.1779e-07,\n",
      "        1.9132e-02, 2.2769e-06, 6.9108e-06, 4.7682e-01, 4.3625e-06, 1.9933e-05,\n",
      "        2.5189e-01, 3.1442e-07, 1.0383e-04, 3.1457e-02, 8.7223e-05, 2.7912e-04,\n",
      "        1.2725e-05, 8.0238e-05, 2.0148e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.9185e-05, 1.2258e-01, 9.7713e-06, 1.0010e-02, 1.0209e-04, 7.3186e-01,\n",
      "        3.2219e-05, 6.5184e-04, 3.2476e-04, 5.2262e-03, 6.8148e-06, 4.0489e-05,\n",
      "        6.6995e-02, 2.6187e-03, 6.0062e-03, 1.5344e-04, 1.2584e-04, 5.2389e-05,\n",
      "        1.7272e-02, 3.1310e-03, 2.9970e-02, 2.8819e-05, 5.9180e-05, 1.0571e-03,\n",
      "        1.3786e-03, 2.2882e-04, 2.4984e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.9096e-03, 1.3675e-04, 4.7216e-05, 8.7304e-04, 2.0149e-02, 6.7528e-05,\n",
      "        8.2489e-05, 1.2902e-04, 7.7449e-05, 7.7565e-04, 4.5119e-06, 6.1995e-04,\n",
      "        9.2041e-01, 9.4896e-04, 7.9078e-03, 6.0333e-05, 8.3357e-04, 7.7811e-06,\n",
      "        8.8489e-03, 3.3354e-04, 2.7822e-02, 3.9566e-05, 2.0372e-04, 4.6446e-03,\n",
      "        5.4116e-05, 1.8609e-06, 1.4107e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.5381e-01, 2.4448e-03, 1.1459e-03, 7.4084e-05, 2.4935e-03, 1.2291e-02,\n",
      "        2.2430e-03, 2.9357e-05, 4.0718e-06, 5.4712e-01, 1.0479e-06, 6.9326e-05,\n",
      "        2.8629e-03, 2.2703e-04, 1.3826e-03, 2.8965e-02, 7.0245e-04, 2.0221e-05,\n",
      "        3.8307e-04, 1.2593e-01, 2.5689e-03, 6.8347e-03, 7.3826e-04, 2.2653e-03,\n",
      "        4.6521e-05, 5.2833e-03, 6.4072e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "th good and evil with evil and actually  <------ | ------> be extrained that the philosophest feeli\n",
      "Epoch 14   Time 62.984    Train Loss: 1.242\n",
      "Softmaxed: tensor([9.4383e-01, 8.4945e-04, 1.2543e-04, 1.5027e-06, 4.2465e-04, 1.2358e-02,\n",
      "        4.2033e-05, 5.3487e-04, 7.8156e-04, 2.4359e-04, 5.8809e-06, 4.9246e-07,\n",
      "        4.3452e-03, 2.0851e-03, 1.0494e-03, 6.9585e-05, 1.0450e-05, 2.9979e-06,\n",
      "        3.0640e-04, 3.0122e-02, 9.9582e-05, 1.1834e-03, 2.8814e-05, 1.4838e-04,\n",
      "        4.7576e-06, 1.3302e-03, 1.2830e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.9934e-08, 1.0573e-01, 8.5267e-02, 2.3496e-02, 2.2596e-02, 3.2081e-02,\n",
      "        5.4113e-02, 1.8265e-02, 3.2155e-02, 6.4160e-02, 3.4215e-03, 1.7019e-03,\n",
      "        7.8179e-03, 3.2748e-02, 1.0876e-02, 3.6947e-02, 8.3720e-02, 7.3300e-04,\n",
      "        1.4855e-02, 5.4298e-02, 2.5050e-01, 1.2427e-02, 4.8059e-03, 4.1428e-02,\n",
      "        1.3028e-05, 5.7839e-03, 5.8124e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.9085e-05, 6.0214e-02, 2.9679e-04, 2.7242e-06, 3.5899e-05, 4.2016e-01,\n",
      "        2.4319e-05, 2.5977e-04, 2.1947e-04, 3.2705e-02, 1.0613e-04, 6.0976e-05,\n",
      "        1.2773e-02, 1.1988e-06, 4.3096e-04, 8.5763e-02, 8.8580e-05, 7.4791e-06,\n",
      "        3.3178e-02, 1.5174e-04, 2.7197e-05, 2.1309e-01, 4.8146e-05, 2.2494e-04,\n",
      "        3.0930e-05, 1.4007e-01, 1.5909e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([9.7991e-01, 1.0373e-03, 3.1689e-04, 3.2142e-04, 1.6003e-04, 1.0720e-04,\n",
      "        7.2116e-04, 7.4952e-05, 4.4665e-04, 2.5565e-03, 4.5099e-05, 3.1671e-05,\n",
      "        5.1105e-04, 1.3397e-04, 4.8851e-04, 3.6295e-03, 2.4934e-03, 2.1939e-04,\n",
      "        7.9698e-04, 2.4726e-03, 2.2267e-03, 5.1987e-04, 1.7912e-04, 5.6573e-04,\n",
      "        2.1046e-05, 2.5011e-06, 1.3644e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.3249e-07, 5.7224e-02, 1.5963e-02, 1.6098e-02, 4.6727e-02, 1.6941e-02,\n",
      "        1.9991e-02, 8.6903e-03, 3.4275e-02, 3.2435e-02, 6.3831e-03, 1.2170e-03,\n",
      "        8.3827e-03, 1.0820e-01, 4.2864e-02, 1.6174e-02, 6.5635e-02, 2.6085e-03,\n",
      "        1.4438e-02, 5.5703e-02, 3.6182e-01, 8.7395e-03, 1.6279e-02, 4.1758e-02,\n",
      "        7.1403e-05, 1.3587e-03, 1.6388e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8773e-05, 2.4206e-01, 5.0408e-04, 4.2494e-07, 4.4135e-07, 4.5778e-01,\n",
      "        2.6330e-05, 1.0267e-06, 1.6696e-04, 7.3923e-02, 4.0121e-06, 7.8049e-07,\n",
      "        2.1635e-06, 8.9018e-05, 2.1690e-05, 1.2269e-01, 9.0942e-04, 5.6783e-06,\n",
      "        3.1034e-04, 9.2530e-05, 4.7621e-07, 3.1476e-02, 1.4016e-05, 2.7619e-04,\n",
      "        2.5682e-06, 6.9621e-02, 5.0524e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.7508e-03, 1.1741e-05, 1.3086e-03, 5.1222e-03, 6.6893e-02, 6.9980e-05,\n",
      "        1.1147e-03, 2.3963e-02, 8.8871e-05, 1.0426e-02, 3.1126e-03, 1.0747e-01,\n",
      "        1.4932e-02, 4.3287e-03, 4.3501e-01, 5.4311e-06, 1.2328e-03, 2.3849e-05,\n",
      "        2.9618e-02, 6.1212e-02, 6.4174e-02, 5.7354e-04, 1.2664e-03, 1.4459e-03,\n",
      "        1.5677e-03, 1.5715e-01, 3.1225e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.0839e-03, 1.1162e-04, 3.1241e-05, 3.5867e-05, 1.4716e-05, 8.6225e-01,\n",
      "        6.7732e-05, 1.4818e-04, 1.9046e-05, 1.0613e-01, 9.4099e-06, 6.7294e-05,\n",
      "        7.7165e-05, 1.7243e-05, 2.1202e-02, 5.9704e-04, 7.3867e-05, 1.8139e-05,\n",
      "        1.5104e-04, 1.4997e-04, 2.5812e-05, 1.4163e-04, 3.6910e-06, 9.4800e-04,\n",
      "        8.9966e-06, 3.6150e-03, 3.0241e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.2628e-01, 2.5735e-05, 1.1371e-04, 4.2413e-05, 2.0961e-03, 6.2003e-06,\n",
      "        5.2213e-04, 6.3731e-07, 1.9817e-05, 2.7856e-05, 1.3400e-06, 5.0403e-07,\n",
      "        2.4806e-04, 4.1971e-05, 2.7816e-03, 3.3295e-05, 2.0413e-04, 3.2789e-06,\n",
      "        1.8278e-02, 4.8298e-02, 4.3260e-04, 1.2945e-06, 4.9125e-05, 4.0107e-04,\n",
      "        9.7178e-06, 7.0713e-05, 6.3852e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.4103e-07, 1.0934e-01, 7.2509e-02, 1.9066e-02, 1.7287e-02, 2.5728e-02,\n",
      "        3.6928e-02, 1.1181e-02, 4.2556e-02, 4.3506e-02, 3.9802e-03, 7.1627e-03,\n",
      "        8.8463e-03, 1.5873e-02, 1.6605e-02, 6.7829e-02, 2.3768e-02, 8.3962e-04,\n",
      "        7.8676e-03, 1.7600e-02, 3.8406e-01, 2.0429e-02, 6.1476e-03, 3.6584e-02,\n",
      "        1.7781e-05, 4.2452e-03, 4.0634e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.4000e-05, 6.2302e-03, 3.0911e-06, 8.7781e-08, 2.9532e-08, 5.6003e-03,\n",
      "        6.9851e-05, 1.6385e-06, 6.6524e-01, 8.0389e-03, 3.7521e-07, 4.2250e-06,\n",
      "        3.6188e-05, 3.0909e-06, 2.2855e-06, 3.0618e-01, 2.8203e-07, 2.1030e-06,\n",
      "        6.6777e-03, 6.1121e-06, 2.6800e-06, 5.4831e-04, 4.8901e-07, 7.1389e-04,\n",
      "        6.4604e-08, 6.2863e-04, 5.6840e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.2953e-01, 4.8875e-04, 3.5766e-05, 1.7568e-05, 2.3357e-03, 2.2491e-03,\n",
      "        1.4183e-04, 3.6251e-03, 8.5793e-04, 6.5043e-04, 8.1054e-06, 6.3229e-04,\n",
      "        7.9135e-04, 6.4680e-04, 1.0602e-03, 4.2108e-02, 3.1596e-05, 1.5639e-06,\n",
      "        2.2780e-03, 7.6303e-04, 7.0065e-05, 2.8485e-03, 1.4708e-04, 8.3391e-03,\n",
      "        3.2693e-04, 8.5290e-06, 2.1900e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.5119e-07, 6.7797e-02, 1.1820e-01, 3.3256e-02, 4.1853e-02, 3.4701e-02,\n",
      "        3.1740e-02, 2.4783e-02, 9.1166e-02, 3.0878e-02, 3.9397e-03, 2.5296e-03,\n",
      "        2.9567e-02, 3.6031e-02, 6.3432e-03, 3.1550e-02, 5.0965e-02, 7.7815e-04,\n",
      "        2.8483e-02, 1.1993e-01, 1.5424e-01, 9.1541e-03, 6.1889e-03, 3.9366e-02,\n",
      "        5.7761e-05, 6.4892e-03, 1.4304e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.8673e-05, 1.2026e-01, 2.2377e-05, 3.8510e-06, 1.8652e-06, 1.1515e-01,\n",
      "        4.2254e-05, 1.6049e-05, 1.0742e-01, 1.2328e-02, 1.8774e-05, 4.4733e-06,\n",
      "        8.6183e-02, 1.6239e-05, 6.0583e-05, 1.4196e-01, 2.5308e-03, 3.6879e-06,\n",
      "        3.6870e-01, 1.5005e-03, 7.0400e-04, 4.1844e-02, 2.1280e-05, 7.1379e-04,\n",
      "        6.0185e-05, 3.3913e-04, 1.4492e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0472e-06, 4.3883e-01, 3.0903e-05, 2.5497e-05, 7.7601e-06, 4.9099e-01,\n",
      "        1.1839e-05, 2.2821e-06, 2.1879e-05, 3.2782e-02, 1.4990e-04, 4.5071e-06,\n",
      "        2.3586e-04, 1.3608e-05, 2.0565e-06, 1.9317e-02, 1.9527e-05, 2.5135e-06,\n",
      "        9.1122e-05, 2.7395e-04, 3.2148e-04, 4.4513e-03, 2.1095e-05, 1.5088e-04,\n",
      "        1.0553e-05, 1.2219e-02, 9.2412e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.0826e-05, 6.1337e-04, 3.5892e-02, 1.6515e-02, 5.5442e-03, 8.1211e-04,\n",
      "        3.5265e-03, 6.4373e-03, 8.6789e-05, 2.1134e-02, 5.8535e-04, 8.4740e-03,\n",
      "        5.4930e-03, 9.8454e-03, 1.7382e-02, 2.0839e-02, 6.5618e-02, 6.0261e-05,\n",
      "        2.7630e-02, 1.3202e-01, 4.8755e-02, 2.0917e-01, 7.2387e-02, 2.5416e-01,\n",
      "        1.5974e-02, 6.8000e-03, 1.4203e-02], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.1628e-04, 1.2011e-02, 7.2347e-04, 2.3427e-04, 4.0207e-04, 2.8065e-02,\n",
      "        4.0018e-05, 1.4878e-04, 6.2397e-05, 7.7245e-01, 9.3480e-04, 3.0035e-03,\n",
      "        6.7566e-02, 6.9543e-05, 2.5619e-04, 3.3750e-02, 6.7543e-05, 1.7454e-05,\n",
      "        1.3545e-03, 7.0000e-03, 3.9632e-03, 2.4836e-02, 4.9044e-05, 1.1907e-03,\n",
      "        5.1880e-05, 4.1322e-02, 1.1330e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.7366e-03, 4.1751e-03, 1.3570e-03, 2.4582e-01, 1.1846e-02, 2.8012e-02,\n",
      "        5.7231e-03, 8.1284e-03, 5.1829e-05, 8.9933e-05, 1.7750e-04, 7.9868e-04,\n",
      "        1.3377e-01, 4.7176e-03, 8.9078e-02, 2.5984e-03, 5.0873e-04, 1.8225e-03,\n",
      "        5.1753e-05, 1.6847e-02, 3.9256e-01, 1.0482e-03, 4.4885e-02, 6.1884e-05,\n",
      "        1.7032e-03, 9.9176e-06, 2.4251e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.5470e-06, 3.5416e-02, 2.3240e-06, 7.1050e-07, 1.4547e-05, 5.9729e-01,\n",
      "        1.2394e-05, 1.2964e-05, 9.4465e-07, 2.5970e-01, 2.0489e-07, 1.1438e-07,\n",
      "        6.5739e-04, 2.6904e-05, 1.8449e-05, 1.0285e-01, 6.0517e-06, 6.5427e-07,\n",
      "        4.2436e-05, 1.4668e-04, 2.8821e-05, 1.4085e-03, 6.8919e-07, 1.5068e-05,\n",
      "        6.6272e-07, 2.3477e-03, 1.2215e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3337e-02, 1.1451e-03, 2.5814e-04, 9.7493e-04, 3.1111e-01, 7.3131e-05,\n",
      "        5.3754e-04, 2.2993e-05, 5.8390e-06, 5.7586e-04, 1.4705e-05, 1.0583e-05,\n",
      "        3.7771e-02, 3.3374e-03, 1.5270e-01, 1.4746e-05, 1.7399e-03, 2.7633e-05,\n",
      "        2.5473e-01, 1.7887e-01, 1.1992e-03, 2.3481e-04, 7.0091e-04, 4.9345e-04,\n",
      "        8.1169e-05, 2.7471e-05, 3.5121e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.2339e-08, 1.0560e-01, 5.8689e-02, 3.8214e-02, 4.1515e-02, 7.1018e-02,\n",
      "        1.8749e-02, 1.8543e-02, 4.3159e-02, 5.7450e-02, 3.2874e-03, 6.2777e-03,\n",
      "        6.4193e-03, 1.7814e-02, 2.6594e-02, 4.8706e-02, 5.9481e-02, 1.2313e-03,\n",
      "        6.4000e-03, 5.7895e-02, 2.5622e-01, 1.3623e-02, 5.4928e-03, 3.4058e-02,\n",
      "        1.7748e-05, 3.4845e-03, 5.6025e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8789e-05, 1.9871e-02, 6.0282e-06, 1.7989e-07, 1.1828e-07, 1.7751e-02,\n",
      "        7.6867e-05, 2.9343e-06, 5.6828e-01, 3.7725e-02, 5.4826e-07, 6.9890e-06,\n",
      "        1.0287e-04, 5.9379e-06, 1.0244e-05, 3.3486e-01, 8.0853e-07, 2.8356e-06,\n",
      "        1.3533e-02, 3.3407e-05, 5.1612e-06, 1.4610e-03, 7.7066e-07, 1.0825e-03,\n",
      "        1.8000e-07, 5.1582e-03, 1.2125e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.2002e-01, 8.2083e-04, 5.5154e-05, 3.1962e-05, 4.6585e-03, 2.4310e-03,\n",
      "        2.1204e-04, 5.1764e-03, 7.1281e-04, 9.7036e-04, 1.2288e-05, 7.9862e-04,\n",
      "        1.8201e-03, 1.5485e-03, 1.9187e-03, 4.0712e-02, 5.2691e-05, 2.3583e-06,\n",
      "        2.0250e-03, 1.2001e-03, 1.0895e-04, 3.4718e-03, 2.8440e-04, 1.0338e-02,\n",
      "        6.0086e-04, 1.0544e-05, 3.7781e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.6107e-07, 6.5575e-02, 1.1058e-01, 3.3029e-02, 4.4198e-02, 2.7905e-02,\n",
      "        3.6328e-02, 2.1175e-02, 6.7499e-02, 3.3884e-02, 3.6921e-03, 2.9286e-03,\n",
      "        2.5461e-02, 2.9272e-02, 7.8613e-03, 2.6728e-02, 5.9444e-02, 7.1565e-04,\n",
      "        2.0853e-02, 1.3512e-01, 1.8581e-01, 6.7052e-03, 5.4639e-03, 4.4193e-02,\n",
      "        4.5255e-05, 5.5153e-03, 1.4538e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.1613e-05, 4.1620e-02, 1.3744e-05, 5.7183e-07, 2.8036e-07, 3.9514e-02,\n",
      "        7.7986e-05, 3.3520e-05, 7.8505e-01, 9.1986e-03, 2.3408e-06, 1.0349e-04,\n",
      "        6.9806e-04, 6.2808e-05, 5.0240e-06, 3.6735e-02, 3.1629e-06, 4.3690e-06,\n",
      "        7.0024e-02, 4.9304e-05, 7.9780e-06, 1.2550e-02, 4.4787e-06, 3.6691e-03,\n",
      "        7.0301e-07, 5.2471e-04, 3.9985e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.5570e-05, 3.6359e-02, 3.0557e-07, 4.2058e-09, 9.5119e-08, 9.0473e-01,\n",
      "        5.0154e-07, 4.5406e-07, 5.4166e-06, 4.4484e-02, 7.0181e-07, 3.1344e-07,\n",
      "        5.5556e-06, 1.6156e-05, 1.0546e-05, 1.0851e-02, 4.6034e-07, 3.7294e-08,\n",
      "        2.1160e-03, 1.9845e-05, 4.9528e-06, 9.9857e-04, 2.6579e-08, 5.8979e-05,\n",
      "        3.8227e-07, 2.9686e-04, 4.9325e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([3.3821e-03, 1.6753e-05, 2.6470e-05, 9.2612e-04, 1.5285e-04, 3.2407e-03,\n",
      "        2.7581e-04, 2.1549e-02, 1.7258e-04, 5.9795e-06, 6.5891e-06, 3.9202e-04,\n",
      "        5.3350e-03, 6.9978e-03, 3.8024e-01, 1.5354e-04, 4.7294e-05, 1.3585e-07,\n",
      "        1.1924e-02, 5.6356e-01, 6.4781e-04, 7.4629e-05, 1.8292e-04, 1.9812e-04,\n",
      "        3.0973e-04, 2.1516e-06, 1.8091e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.8010e-01, 1.1763e-04, 5.1296e-06, 1.0715e-04, 3.3490e-05, 1.0709e-02,\n",
      "        7.8422e-04, 5.2925e-04, 1.7099e-03, 5.2234e-04, 7.5012e-07, 2.1168e-03,\n",
      "        7.6720e-06, 5.4862e-04, 2.6193e-04, 3.5060e-04, 2.6017e-04, 3.1319e-06,\n",
      "        4.9918e-05, 1.3023e-03, 3.6923e-04, 2.8007e-05, 2.6137e-05, 3.5872e-05,\n",
      "        1.5672e-06, 1.1447e-05, 8.2667e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([5.8422e-07, 1.1133e-01, 2.5346e-02, 6.6363e-02, 7.5257e-02, 1.1619e-01,\n",
      "        4.6740e-02, 1.5445e-02, 4.7502e-02, 8.7292e-02, 5.7104e-03, 7.2060e-03,\n",
      "        3.0601e-02, 5.6316e-02, 3.5786e-02, 2.4633e-02, 6.2931e-02, 1.8022e-03,\n",
      "        3.1273e-02, 4.8307e-02, 3.4802e-02, 8.6013e-03, 1.5721e-02, 4.3736e-02,\n",
      "        1.6961e-05, 1.0510e-03, 4.1246e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.8758e-03, 1.3033e-01, 1.2510e-04, 2.9271e-02, 2.6778e-06, 3.7889e-01,\n",
      "        7.8940e-04, 5.6199e-04, 4.2146e-02, 6.1927e-02, 3.4176e-05, 7.1996e-03,\n",
      "        1.0500e-02, 3.9807e-03, 8.4779e-04, 6.6274e-02, 4.1786e-02, 7.3038e-04,\n",
      "        2.3650e-04, 2.6491e-04, 8.4243e-02, 1.0830e-01, 2.7174e-05, 3.9956e-03,\n",
      "        1.7979e-05, 2.0627e-02, 9.6332e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.9970e-03, 1.3257e-02, 1.3158e-03, 5.1900e-02, 3.8027e-03, 2.5375e-01,\n",
      "        7.7917e-03, 2.2468e-03, 7.6514e-04, 3.2550e-03, 8.3961e-05, 1.1723e-04,\n",
      "        1.4369e-01, 2.2563e-02, 2.3990e-01, 2.5261e-03, 5.0401e-03, 4.8768e-03,\n",
      "        1.5204e-01, 2.9574e-03, 2.2160e-02, 4.7426e-04, 3.2070e-02, 1.8673e-03,\n",
      "        2.2608e-02, 1.8880e-03, 5.7125e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.7954e-03, 3.5856e-03, 1.6851e-03, 1.7982e-02, 3.6946e-04, 4.8761e-02,\n",
      "        1.8432e-02, 3.7498e-04, 7.0476e-03, 4.9241e-01, 7.0466e-05, 4.3953e-03,\n",
      "        1.1015e-03, 1.0919e-02, 7.1647e-03, 1.3404e-02, 2.8564e-02, 3.6410e-05,\n",
      "        1.5560e-02, 9.3190e-03, 1.2126e-02, 1.9899e-03, 2.9341e-01, 6.6020e-03,\n",
      "        1.8260e-04, 6.7636e-04, 3.5375e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3480e-02, 3.1815e-01, 5.8280e-05, 9.7401e-06, 5.8115e-06, 8.6753e-03,\n",
      "        4.1096e-03, 2.2170e-06, 4.4561e-02, 5.6011e-01, 4.7336e-06, 9.6702e-05,\n",
      "        1.8882e-04, 6.5476e-04, 5.3336e-06, 1.4185e-02, 2.3827e-04, 9.7936e-06,\n",
      "        1.5986e-02, 6.2414e-03, 1.3456e-04, 5.3513e-03, 6.8241e-05, 5.3201e-03,\n",
      "        3.1499e-06, 2.2613e-03, 8.6374e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0263e-03, 1.0338e-02, 3.0272e-03, 2.6908e-01, 2.5569e-03, 8.3250e-03,\n",
      "        3.3320e-02, 2.3757e-03, 1.0642e-04, 9.7781e-05, 3.2608e-05, 8.1436e-04,\n",
      "        4.1011e-03, 1.4270e-01, 3.1555e-01, 1.2942e-02, 5.7891e-02, 2.2162e-03,\n",
      "        2.9435e-03, 3.3336e-02, 6.7534e-02, 1.1612e-04, 2.5779e-02, 5.2906e-04,\n",
      "        1.9459e-03, 1.2155e-07, 1.3115e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.0264e-04, 3.4157e-02, 1.3598e-05, 3.0326e-01, 2.5747e-02, 4.3617e-03,\n",
      "        1.3130e-04, 5.3287e-01, 1.9538e-04, 1.4338e-02, 2.0629e-04, 1.8430e-02,\n",
      "        1.2570e-05, 2.9906e-04, 1.1835e-03, 9.4259e-04, 5.2685e-06, 3.8280e-04,\n",
      "        3.0006e-05, 9.9495e-04, 5.1591e-03, 5.5499e-02, 8.3693e-05, 1.4498e-04,\n",
      "        8.8696e-04, 2.3034e-04, 2.7859e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.9517e-05, 1.1159e-03, 4.2679e-05, 3.7720e-04, 1.5834e-05, 1.9597e-02,\n",
      "        2.6967e-05, 3.7626e-05, 7.4045e-04, 4.5076e-02, 2.9326e-06, 1.7769e-04,\n",
      "        8.9866e-04, 2.8173e-05, 2.0861e-05, 4.8537e-04, 6.8535e-06, 3.0543e-05,\n",
      "        2.9950e-04, 7.2454e-04, 9.2985e-01, 3.4769e-04, 1.9050e-06, 1.0343e-05,\n",
      "        6.3402e-07, 6.0854e-05, 5.2495e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.9252e-01, 4.2807e-03, 6.0008e-05, 1.1856e-06, 1.4994e-06, 4.4718e-03,\n",
      "        3.9723e-03, 2.2164e-06, 5.3702e-04, 7.3625e-01, 1.5631e-06, 1.7210e-06,\n",
      "        6.4795e-03, 2.0044e-04, 1.5438e-05, 3.9178e-03, 5.2520e-05, 3.7950e-06,\n",
      "        1.4653e-03, 1.3401e-02, 2.8387e-05, 2.9830e-02, 4.2290e-06, 3.6417e-04,\n",
      "        4.4180e-07, 2.1348e-03, 5.7470e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2090e-03, 7.6956e-03, 1.0877e-02, 5.8073e-02, 8.2006e-04, 2.0098e-03,\n",
      "        1.5434e-02, 6.9620e-04, 1.1463e-05, 2.7482e-04, 7.3819e-06, 6.6967e-06,\n",
      "        1.1157e-03, 4.5091e-03, 1.8764e-02, 7.5522e-01, 1.0791e-03, 2.7302e-04,\n",
      "        3.0966e-04, 1.7266e-03, 1.1047e-02, 1.3866e-04, 1.0844e-01, 5.8925e-05,\n",
      "        2.2472e-05, 4.8417e-07, 1.8692e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2964e-04, 1.2433e-06, 2.2283e-06, 5.0199e-05, 6.0994e-05, 2.7149e-07,\n",
      "        3.1518e-05, 6.9359e-06, 6.6399e-09, 2.6598e-06, 1.2517e-07, 3.0020e-06,\n",
      "        2.8952e-04, 7.7316e-05, 9.9808e-01, 2.4408e-07, 2.3723e-05, 6.2325e-07,\n",
      "        4.1341e-04, 3.1053e-04, 2.9393e-05, 4.7693e-04, 1.4799e-06, 1.5003e-06,\n",
      "        1.5651e-06, 3.7074e-09, 7.5919e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.3745e-01, 1.7789e-02, 1.1729e-06, 2.9940e-04, 6.6769e-04, 5.3139e-03,\n",
      "        1.7479e-05, 2.8546e-06, 4.7639e-06, 1.1567e-03, 2.6184e-07, 1.7197e-06,\n",
      "        3.3687e-04, 8.2324e-05, 3.6598e-05, 2.5187e-04, 1.6780e-06, 2.0917e-06,\n",
      "        3.8433e-06, 1.3631e-01, 9.7439e-05, 2.2121e-05, 2.6872e-07, 7.1196e-06,\n",
      "        3.9616e-07, 1.3809e-04, 9.4185e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "ir source but rather in the lap of being <------ | ------>  by make to plobive to this sertinction \n",
      "Epoch 15   Time 62.860    Train Loss: 1.234\n",
      "Softmaxed: tensor([7.5057e-08, 1.7487e-01, 3.5512e-02, 1.3030e-02, 6.7308e-03, 9.7314e-03,\n",
      "        4.8239e-02, 5.8228e-03, 3.2314e-02, 1.0656e-01, 1.3266e-03, 3.6071e-04,\n",
      "        1.8239e-03, 2.5025e-02, 7.6156e-03, 2.3901e-01, 1.8415e-02, 1.3982e-03,\n",
      "        1.5763e-02, 6.2302e-02, 7.1180e-02, 1.6280e-02, 3.8672e-03, 9.6864e-02,\n",
      "        1.3069e-05, 5.8699e-03, 7.7853e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([7.0094e-05, 4.5130e-02, 8.8205e-06, 1.1850e-05, 3.5445e-08, 1.6650e-02,\n",
      "        1.9944e-04, 1.3040e-07, 9.9630e-06, 3.0260e-02, 1.6616e-06, 4.3221e-08,\n",
      "        5.2033e-03, 8.3453e-07, 3.9320e-06, 7.7259e-01, 1.5391e-06, 3.5811e-06,\n",
      "        1.0999e-01, 1.8892e-07, 2.9970e-05, 1.9592e-02, 8.2718e-05, 9.9346e-05,\n",
      "        4.0354e-06, 5.2301e-05, 1.0258e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5327e-06, 1.1656e-02, 1.3626e-05, 1.1629e-04, 1.6157e-05, 1.9093e-01,\n",
      "        4.2834e-06, 2.5683e-06, 6.3017e-05, 1.2019e-01, 1.8659e-05, 1.2800e-06,\n",
      "        1.6922e-04, 1.0921e-04, 1.1652e-04, 6.6850e-01, 7.0749e-08, 5.5928e-06,\n",
      "        3.8198e-03, 3.2340e-06, 1.8137e-04, 2.6701e-03, 1.0874e-03, 1.1074e-04,\n",
      "        3.7935e-05, 1.6889e-04, 4.8026e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.1801e-04, 4.3934e-02, 6.6822e-05, 7.1390e-03, 2.5281e-03, 8.2086e-01,\n",
      "        8.1734e-05, 1.6629e-03, 2.1038e-03, 2.7290e-02, 3.1732e-04, 5.3985e-03,\n",
      "        1.4335e-02, 8.9949e-03, 4.8615e-02, 7.4510e-05, 7.7112e-04, 1.5026e-04,\n",
      "        6.9200e-05, 4.3342e-03, 2.7652e-03, 1.2781e-04, 2.2819e-04, 6.3553e-03,\n",
      "        3.5176e-04, 4.7640e-04, 5.1348e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0522e-02, 3.7105e-02, 9.6238e-03, 1.7979e-03, 1.6074e-01, 4.5811e-02,\n",
      "        3.2457e-02, 7.2279e-04, 2.8570e-05, 2.0691e-01, 3.8398e-04, 1.2138e-03,\n",
      "        3.7060e-02, 1.1743e-03, 1.8886e-04, 1.0171e-01, 1.2325e-03, 4.0416e-04,\n",
      "        8.4339e-04, 2.5481e-01, 7.2268e-02, 1.9888e-03, 9.5884e-04, 1.0981e-02,\n",
      "        7.4769e-05, 8.6780e-03, 3.1628e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.4659e-01, 8.6060e-04, 1.9386e-04, 3.1174e-04, 4.3889e-04, 4.2168e-04,\n",
      "        2.2153e-04, 2.4096e-04, 1.7149e-05, 2.6860e-04, 8.4126e-06, 1.4936e-05,\n",
      "        8.5265e-04, 3.8529e-03, 3.8422e-03, 2.5763e-04, 3.7805e-04, 8.1577e-06,\n",
      "        1.2109e-04, 3.6770e-02, 4.1989e-03, 1.2288e-05, 1.9673e-05, 7.6685e-05,\n",
      "        7.7681e-06, 4.4816e-06, 1.2277e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.4619e-07, 1.6200e-01, 3.3664e-02, 4.4044e-02, 3.5917e-02, 2.9420e-02,\n",
      "        2.2490e-02, 5.1392e-03, 1.9410e-02, 1.3893e-01, 5.7670e-03, 4.1873e-03,\n",
      "        2.6554e-02, 4.1959e-02, 2.8763e-02, 1.0502e-01, 2.7053e-02, 2.4150e-03,\n",
      "        1.3269e-02, 9.9477e-02, 8.8099e-02, 1.9153e-02, 6.2858e-03, 3.4301e-02,\n",
      "        1.9909e-05, 6.6027e-03, 6.2500e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.1511e-02, 2.9552e-04, 8.3248e-05, 2.4689e-05, 1.0094e-02, 3.2957e-04,\n",
      "        2.7221e-02, 4.5234e-03, 2.5451e-04, 1.2187e-05, 2.3913e-06, 2.3302e-05,\n",
      "        5.4480e-03, 5.8637e-02, 6.7593e-01, 1.3744e-04, 4.1775e-04, 9.5893e-05,\n",
      "        1.2458e-03, 7.3683e-02, 1.1880e-01, 2.5817e-05, 5.5438e-04, 4.9564e-04,\n",
      "        1.4333e-04, 4.9389e-06, 9.1588e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3935e-01, 6.9058e-03, 2.3673e-04, 3.5950e-02, 1.0565e-01, 1.1569e-03,\n",
      "        2.5486e-02, 1.9007e-03, 6.8213e-04, 6.0961e-04, 8.4305e-03, 4.5198e-05,\n",
      "        1.8917e-03, 1.4774e-03, 7.2615e-03, 4.0511e-04, 6.8546e-05, 1.6387e-03,\n",
      "        5.0009e-04, 9.6643e-02, 1.2197e-01, 1.4005e-03, 3.8155e-02, 1.5167e-03,\n",
      "        5.5666e-04, 1.1207e-04, 2.0431e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3515e-08, 1.1347e-01, 1.2210e-02, 2.6496e-02, 1.2654e-02, 5.1027e-02,\n",
      "        1.1117e-02, 1.3414e-02, 6.5182e-02, 4.9844e-02, 6.1699e-03, 5.2065e-04,\n",
      "        1.4334e-02, 2.3310e-02, 1.0044e-02, 4.4467e-02, 3.1903e-02, 5.2139e-03,\n",
      "        2.9402e-02, 7.8423e-02, 3.2280e-01, 1.2435e-02, 1.3996e-02, 5.0193e-02,\n",
      "        4.8003e-05, 1.2693e-03, 6.2943e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.6186e-01, 2.6889e-05, 5.0172e-03, 2.5803e-02, 1.6585e-02, 1.3455e-05,\n",
      "        1.2100e-02, 1.9647e-02, 7.8300e-04, 5.1502e-04, 2.8099e-05, 1.5480e-03,\n",
      "        2.4153e-01, 8.4527e-03, 9.5306e-02, 3.0449e-06, 4.9319e-03, 1.8785e-04,\n",
      "        1.2934e-02, 3.6702e-02, 4.4101e-02, 4.5235e-03, 6.6057e-04, 6.3086e-03,\n",
      "        1.7312e-04, 2.3521e-04, 2.0386e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.6261e-08, 1.6013e-03, 3.7541e-02, 8.3710e-02, 5.9046e-02, 8.4350e-04,\n",
      "        5.5697e-02, 7.5862e-02, 4.6480e-02, 9.5297e-04, 2.9257e-03, 2.6005e-03,\n",
      "        5.5073e-02, 8.8582e-02, 6.6833e-02, 2.6132e-03, 9.0085e-02, 1.0609e-02,\n",
      "        7.1528e-02, 1.0898e-01, 6.6761e-02, 2.2917e-03, 2.8682e-02, 4.0447e-02,\n",
      "        1.4569e-04, 6.9695e-05, 4.2262e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.1495e-05, 1.0617e-01, 3.2783e-05, 2.6658e-06, 1.1325e-06, 2.3028e-01,\n",
      "        6.3316e-05, 1.2562e-05, 1.4508e-01, 1.4546e-02, 2.7159e-05, 2.0389e-06,\n",
      "        7.0311e-02, 2.4088e-05, 1.3907e-04, 1.2438e-01, 3.1382e-03, 4.0630e-06,\n",
      "        2.5366e-01, 2.2174e-03, 2.8054e-03, 4.5375e-02, 2.2882e-05, 1.4335e-03,\n",
      "        7.0675e-05, 1.4865e-04, 1.4578e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1902e-07, 2.2152e-02, 1.6429e-05, 3.9237e-05, 6.0233e-06, 3.6469e-01,\n",
      "        5.3830e-06, 1.1706e-06, 2.3055e-05, 1.4585e-01, 1.6902e-05, 1.0273e-07,\n",
      "        1.0897e-05, 3.2922e-06, 9.4257e-06, 4.5954e-01, 6.2012e-07, 3.5280e-07,\n",
      "        1.4789e-04, 8.4507e-05, 7.6532e-05, 1.8151e-03, 5.8372e-05, 1.0709e-04,\n",
      "        9.1888e-06, 5.3353e-03, 4.2853e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8572e-03, 2.9690e-02, 9.0327e-03, 7.5115e-02, 3.7569e-02, 3.4650e-03,\n",
      "        4.1067e-02, 1.2433e-02, 2.8502e-03, 3.3074e-03, 3.2161e-02, 6.4915e-05,\n",
      "        8.0396e-03, 5.3219e-03, 4.1854e-03, 8.3352e-04, 1.4099e-02, 2.0550e-03,\n",
      "        1.3173e-04, 5.2468e-01, 3.4368e-02, 1.4364e-04, 1.3789e-01, 1.6135e-02,\n",
      "        8.5727e-04, 1.3349e-03, 3.1158e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([1.6046e-03, 1.1193e-02, 3.2855e-04, 3.7005e-03, 4.4645e-06, 7.9457e-01,\n",
      "        7.3385e-05, 2.8261e-05, 2.7937e-03, 3.9747e-02, 1.5948e-05, 3.1122e-04,\n",
      "        7.2048e-05, 2.6452e-03, 6.4696e-05, 1.3966e-02, 2.8237e-02, 1.3736e-04,\n",
      "        2.9493e-05, 3.0356e-02, 8.9081e-03, 5.8422e-02, 7.8241e-06, 2.6195e-03,\n",
      "        5.3312e-06, 1.3522e-04, 2.6569e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.8417e-05, 4.8543e-03, 2.1525e-02, 5.6686e-03, 1.5756e-02, 7.2891e-04,\n",
      "        4.1332e-03, 4.1586e-03, 9.1949e-06, 6.0087e-03, 1.9744e-05, 5.4300e-06,\n",
      "        2.4868e-02, 3.6073e-01, 3.9444e-02, 3.3779e-03, 3.2430e-01, 4.0452e-05,\n",
      "        1.5115e-01, 2.5356e-02, 1.3242e-03, 4.6148e-04, 5.4582e-03, 1.4710e-04,\n",
      "        3.1474e-04, 1.5097e-06, 1.1066e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.5437e-04, 4.0173e-02, 3.6949e-05, 3.1858e-03, 9.3787e-01, 2.3773e-03,\n",
      "        1.5384e-04, 4.2823e-03, 1.7582e-05, 6.7660e-03, 6.8012e-05, 1.8096e-04,\n",
      "        2.2017e-04, 6.6357e-06, 6.9937e-04, 4.8277e-05, 2.2852e-05, 6.2896e-06,\n",
      "        1.0939e-04, 1.3049e-03, 1.9863e-03, 4.7564e-05, 4.1135e-05, 9.1510e-05,\n",
      "        1.3040e-05, 3.0296e-05, 9.5958e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.6401e-02, 1.2270e-01, 1.8841e-04, 4.2905e-04, 4.6219e-05, 1.5846e-01,\n",
      "        3.4769e-04, 1.6703e-04, 4.0285e-04, 2.4761e-01, 2.6242e-06, 7.6138e-07,\n",
      "        4.7281e-02, 1.5743e-03, 1.1672e-03, 9.5441e-02, 8.8056e-05, 2.5900e-05,\n",
      "        1.5807e-02, 2.1865e-01, 4.3461e-04, 1.1374e-02, 3.8943e-05, 9.8212e-04,\n",
      "        9.2110e-06, 3.5809e-04, 1.1967e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2555e-04, 9.3430e-06, 1.7050e-02, 1.0907e-02, 5.7663e-03, 1.1801e-06,\n",
      "        2.8044e-04, 6.4942e-03, 3.1664e-05, 1.4364e-02, 4.9389e-05, 1.7888e-04,\n",
      "        1.1321e-01, 5.4359e-02, 4.0890e-01, 4.2691e-05, 3.7439e-04, 1.1414e-05,\n",
      "        2.6795e-01, 8.9063e-04, 7.1628e-02, 1.4888e-02, 1.0429e-02, 2.4869e-04,\n",
      "        8.6044e-05, 1.1860e-03, 5.3481e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4302e-02, 1.0868e-03, 7.1284e-05, 2.7337e-01, 7.5799e-03, 2.1524e-03,\n",
      "        4.7438e-05, 1.8884e-02, 9.7650e-04, 1.6995e-02, 2.1375e-05, 3.7498e-04,\n",
      "        2.7904e-04, 3.7146e-04, 7.7460e-03, 7.9065e-04, 7.8617e-06, 5.1155e-04,\n",
      "        9.9128e-05, 1.4290e-02, 6.3831e-01, 9.7057e-04, 7.9985e-05, 1.7951e-04,\n",
      "        9.7911e-05, 3.8190e-04, 2.1911e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.6516e-01, 1.1252e-02, 8.3933e-05, 2.1905e-06, 1.9578e-04, 7.7968e-02,\n",
      "        1.8966e-04, 4.2898e-05, 1.2807e-04, 6.6789e-04, 8.4688e-07, 3.8293e-08,\n",
      "        1.9557e-01, 1.7347e-02, 1.7276e-04, 3.0898e-03, 2.1769e-05, 8.3458e-07,\n",
      "        4.4258e-03, 1.9127e-02, 3.3724e-05, 4.3094e-03, 3.3452e-05, 2.0219e-05,\n",
      "        1.1179e-05, 1.2732e-04, 1.0090e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1350e-04, 3.1971e-04, 1.0831e-05, 2.1805e-07, 4.5045e-07, 1.7714e-02,\n",
      "        1.5786e-04, 2.7132e-08, 9.4983e-08, 6.8663e-03, 7.2519e-08, 3.3599e-09,\n",
      "        3.6821e-06, 2.4370e-06, 7.2260e-07, 3.2723e-04, 1.9778e-07, 1.2345e-08,\n",
      "        3.9101e-06, 2.1843e-05, 4.8964e-06, 5.0606e-04, 1.0117e-05, 1.4845e-06,\n",
      "        4.8935e-08, 9.7393e-01, 2.2346e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([9.9972e-01, 1.1326e-05, 2.0209e-06, 1.1723e-07, 8.1469e-08, 9.5832e-06,\n",
      "        1.7520e-06, 2.8744e-07, 1.9306e-07, 2.8707e-05, 7.6116e-09, 3.2316e-09,\n",
      "        1.1635e-05, 1.7866e-05, 1.6144e-05, 4.1167e-06, 6.8206e-07, 1.7942e-08,\n",
      "        6.9594e-07, 1.4188e-04, 1.5667e-06, 2.5029e-05, 9.6141e-08, 1.8814e-06,\n",
      "        2.1342e-07, 4.1727e-07, 4.2122e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([1.5439e-07, 2.7224e-01, 3.7924e-02, 3.1354e-02, 2.6036e-02, 4.5387e-02,\n",
      "        2.2713e-02, 7.6879e-03, 4.4243e-02, 9.0204e-02, 1.7700e-03, 1.7923e-03,\n",
      "        2.1646e-02, 6.1336e-02, 2.5411e-02, 4.7270e-02, 2.5258e-02, 1.0679e-03,\n",
      "        2.1966e-02, 6.8580e-02, 7.4063e-02, 8.3763e-03, 2.5063e-03, 5.8268e-02,\n",
      "        7.6038e-06, 2.8689e-03, 2.6798e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.7308e-05, 1.2373e-01, 1.8966e-05, 2.1321e-05, 4.9759e-08, 8.3740e-02,\n",
      "        3.3247e-04, 2.8705e-07, 2.4133e-05, 9.7844e-02, 2.0043e-06, 1.2918e-07,\n",
      "        2.6582e-02, 1.7092e-06, 5.2967e-06, 4.6745e-01, 4.2038e-06, 1.3770e-05,\n",
      "        1.6131e-01, 1.5075e-07, 6.3836e-05, 3.8314e-02, 9.6866e-05, 2.6062e-04,\n",
      "        1.0342e-05, 8.4206e-05, 2.1359e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.8460e-07, 1.4673e-02, 1.7492e-05, 9.6049e-05, 1.5458e-05, 1.3907e-01,\n",
      "        4.8917e-06, 2.6979e-06, 6.7128e-05, 1.1456e-01, 1.4431e-05, 8.7536e-07,\n",
      "        3.2059e-04, 1.4225e-04, 4.4359e-05, 7.2021e-01, 9.5318e-08, 6.9987e-06,\n",
      "        3.2053e-03, 2.6921e-06, 1.7666e-04, 6.3443e-03, 6.9181e-04, 7.5490e-05,\n",
      "        3.5278e-05, 2.1425e-04, 4.6494e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0810e-03, 2.2445e-04, 7.0877e-04, 9.0898e-05, 3.3326e-03, 5.9688e-05,\n",
      "        9.8999e-04, 7.9910e-04, 1.5522e-05, 1.0462e-04, 2.2969e-05, 3.6144e-04,\n",
      "        2.2632e-03, 9.6395e-01, 4.3437e-03, 1.4084e-03, 2.9705e-04, 8.9615e-06,\n",
      "        8.9842e-04, 2.5240e-04, 2.5962e-03, 7.5038e-03, 2.5122e-03, 3.3331e-03,\n",
      "        1.7815e-03, 1.6453e-05, 4.1403e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9283e-01, 4.9251e-04, 3.4320e-04, 9.4857e-07, 4.8127e-04, 1.9582e-05,\n",
      "        7.2569e-05, 6.8391e-07, 1.7574e-06, 2.1096e-05, 6.9019e-07, 7.9622e-07,\n",
      "        1.2558e-04, 1.1569e-03, 2.5748e-04, 1.4958e-05, 9.2692e-04, 1.3549e-07,\n",
      "        3.5508e-05, 3.0990e-03, 8.4289e-05, 2.7762e-06, 2.4399e-06, 2.9155e-05,\n",
      "        4.4536e-07, 2.1380e-06, 1.3840e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([2.1715e-07, 1.8807e-01, 1.2208e-02, 1.4653e-02, 3.2063e-02, 1.6812e-02,\n",
      "        1.5153e-02, 5.0309e-03, 4.3048e-02, 6.0778e-02, 4.5507e-03, 4.3970e-03,\n",
      "        1.3011e-02, 1.8397e-02, 1.2051e-02, 2.4256e-02, 1.8779e-02, 1.6266e-03,\n",
      "        6.7703e-03, 7.2885e-02, 3.3523e-01, 3.3504e-03, 6.2415e-03, 8.5549e-02,\n",
      "        1.0133e-05, 5.0416e-03, 3.7807e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.9972e-06, 2.0919e-03, 8.7296e-07, 7.2432e-08, 1.9966e-08, 1.3725e-03,\n",
      "        1.0921e-05, 3.7840e-06, 9.7125e-01, 1.5255e-03, 2.0453e-07, 7.9277e-06,\n",
      "        4.6175e-05, 3.8277e-06, 8.6332e-07, 1.5876e-02, 2.1490e-07, 1.4365e-06,\n",
      "        6.6297e-03, 6.9254e-06, 2.4799e-06, 2.4834e-04, 1.5535e-07, 7.2143e-04,\n",
      "        3.4422e-08, 1.9795e-04, 6.4254e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5442e-05, 3.5211e-02, 3.0704e-07, 1.1993e-09, 1.5920e-07, 9.0425e-01,\n",
      "        2.3131e-07, 1.2603e-07, 6.5504e-06, 3.9510e-02, 2.5735e-07, 1.2858e-07,\n",
      "        1.1035e-05, 5.2778e-06, 1.6885e-05, 1.4645e-02, 2.4098e-07, 2.6890e-08,\n",
      "        4.6189e-03, 2.3606e-05, 5.3984e-06, 1.4564e-03, 1.0741e-08, 3.6130e-05,\n",
      "        2.1296e-07, 1.6850e-04, 2.6702e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.6658e-01, 5.0691e-05, 7.5713e-06, 3.3582e-06, 5.0499e-06, 1.5279e-03,\n",
      "        6.3856e-05, 2.7153e-04, 1.8678e-03, 4.0572e-02, 1.1965e-05, 1.4279e-05,\n",
      "        2.5110e-04, 3.6421e-02, 7.3597e-03, 1.9637e-04, 2.4412e-04, 1.7691e-06,\n",
      "        8.5135e-03, 1.6720e-02, 5.2577e-04, 2.9125e-06, 6.1341e-05, 6.8433e-04,\n",
      "        1.2432e-05, 1.7984e-02, 4.9801e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.0154e-06, 5.2747e-02, 2.4657e-02, 1.0964e-01, 5.9723e-02, 3.9856e-02,\n",
      "        5.4310e-02, 3.9977e-02, 3.9240e-02, 4.7513e-02, 6.6892e-03, 4.8547e-03,\n",
      "        3.0092e-02, 8.4610e-02, 2.4043e-02, 5.2453e-02, 6.1518e-02, 6.3565e-03,\n",
      "        2.6282e-02, 1.0560e-01, 3.4065e-02, 1.5796e-02, 2.9030e-02, 4.7871e-02,\n",
      "        2.5197e-05, 3.0018e-03, 4.3573e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.1481e-07, 1.6859e-01, 2.6917e-06, 2.1750e-05, 1.8167e-06, 2.5065e-02,\n",
      "        1.8009e-05, 2.9990e-06, 7.7752e-02, 2.4504e-02, 3.8577e-06, 3.0013e-03,\n",
      "        7.9599e-02, 5.7461e-06, 7.7343e-06, 5.3376e-01, 1.1193e-05, 2.9874e-04,\n",
      "        4.3287e-02, 5.2661e-05, 7.7644e-04, 4.2382e-02, 1.4258e-05, 9.2511e-05,\n",
      "        9.2995e-06, 7.3677e-04, 1.0039e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.9363e-04, 1.6473e-04, 1.7420e-05, 2.6101e-04, 2.2495e-03, 5.0763e-05,\n",
      "        3.3733e-04, 3.8888e-03, 1.0532e-05, 8.2363e-04, 1.0375e-05, 5.5013e-04,\n",
      "        2.2109e-02, 1.4881e-01, 7.2938e-01, 3.2321e-04, 1.9357e-03, 3.4981e-04,\n",
      "        3.1607e-02, 6.1960e-03, 3.0115e-05, 4.1961e-02, 6.0015e-03, 1.4166e-03,\n",
      "        8.1327e-04, 2.1067e-06, 8.0529e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.5992e-03, 1.9807e-04, 3.3695e-04, 1.9344e-01, 1.6632e-01, 6.6697e-03,\n",
      "        5.2619e-02, 7.2043e-03, 6.1892e-05, 2.9426e-03, 4.8161e-03, 2.6282e-04,\n",
      "        1.7653e-03, 7.1272e-04, 1.2571e-02, 9.4833e-05, 1.6696e-03, 9.4167e-03,\n",
      "        1.8234e-04, 2.1947e-01, 2.7586e-01, 2.2814e-04, 3.9508e-02, 8.5604e-04,\n",
      "        1.3677e-04, 9.6268e-06, 4.2925e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.2328e-05, 7.8902e-03, 2.6275e-04, 4.3851e-01, 5.1654e-07, 1.9142e-01,\n",
      "        1.6205e-04, 4.6737e-06, 6.9890e-04, 1.2049e-01, 2.9131e-05, 4.0667e-05,\n",
      "        1.0125e-02, 4.2856e-04, 6.6309e-05, 3.1420e-03, 2.3838e-02, 3.8294e-04,\n",
      "        9.0520e-06, 1.8816e-03, 1.7165e-01, 2.7999e-02, 1.8487e-05, 2.8312e-04,\n",
      "        1.7398e-06, 5.9161e-04, 2.4311e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.9867e-06, 1.9541e-02, 1.0938e-06, 4.8560e-06, 2.1619e-07, 6.1318e-03,\n",
      "        3.1959e-06, 4.8289e-07, 1.8062e-04, 9.3638e-01, 4.0391e-07, 1.2141e-05,\n",
      "        2.5247e-05, 1.3165e-06, 1.5753e-07, 5.4988e-03, 1.9990e-06, 1.8902e-05,\n",
      "        5.9950e-03, 2.7256e-05, 8.1200e-06, 2.2851e-02, 1.0994e-06, 3.1427e-07,\n",
      "        3.4006e-07, 3.3107e-03, 4.1066e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.6287e-05, 6.4847e-02, 2.1408e-03, 4.2530e-03, 2.4343e-04, 4.1318e-01,\n",
      "        4.1605e-04, 5.5767e-05, 5.0325e-06, 9.1953e-04, 1.8509e-06, 7.9056e-06,\n",
      "        5.2786e-03, 9.5122e-04, 5.7320e-03, 4.7962e-01, 3.7846e-03, 1.0184e-04,\n",
      "        2.8040e-04, 2.9420e-03, 9.7394e-03, 1.0889e-03, 4.1887e-03, 7.1224e-06,\n",
      "        3.3771e-05, 1.4351e-06, 9.5352e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "ys more rapidly the history of language  <------ | ------> frely in a presundangly from the conscio\n",
      "Epoch 16   Time 62.842    Train Loss: 1.224\n",
      "Softmaxed: tensor([1.3532e-06, 3.9381e-02, 3.3933e-02, 7.2894e-02, 4.0914e-02, 6.2420e-02,\n",
      "        7.3923e-02, 3.1313e-02, 5.1646e-02, 4.5608e-02, 9.0637e-03, 4.7191e-03,\n",
      "        2.2940e-02, 5.2427e-02, 3.3366e-02, 2.7886e-02, 9.9503e-02, 2.4346e-03,\n",
      "        2.3035e-02, 1.1988e-01, 2.2761e-02, 1.6344e-02, 2.5817e-02, 8.5601e-02,\n",
      "        2.2428e-05, 2.1094e-03, 6.1117e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.5689e-06, 1.5212e-01, 2.5360e-05, 1.3433e-06, 1.5241e-06, 1.2163e-01,\n",
      "        1.6874e-05, 2.0879e-05, 1.4286e-01, 1.0490e-02, 1.9214e-05, 1.2828e-06,\n",
      "        3.4723e-02, 2.3792e-05, 3.4241e-05, 1.7735e-01, 1.0759e-03, 1.7954e-06,\n",
      "        2.7882e-01, 1.3687e-03, 4.2568e-04, 7.7791e-02, 1.3822e-05, 6.6559e-04,\n",
      "        6.8626e-05, 4.3311e-04, 1.4051e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2828e-06, 2.0622e-02, 3.4088e-06, 2.7116e-07, 8.5793e-08, 5.5827e-02,\n",
      "        7.3675e-06, 4.1176e-07, 1.6150e-06, 8.0332e-01, 6.5690e-06, 7.4081e-09,\n",
      "        1.0445e-04, 8.8188e-06, 7.9908e-06, 1.8305e-02, 1.3687e-05, 5.0308e-08,\n",
      "        7.8846e-03, 2.1128e-04, 9.2890e-05, 2.0707e-03, 7.0016e-07, 2.0385e-04,\n",
      "        2.2650e-06, 9.1297e-02, 2.6267e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([6.7587e-07, 2.3426e-04, 3.7989e-05, 1.7632e-03, 3.9145e-04, 1.7981e-04,\n",
      "        1.0560e-04, 3.2011e-04, 2.0150e-05, 1.7723e-05, 1.8106e-05, 3.1756e-07,\n",
      "        9.5959e-01, 1.5660e-04, 1.8940e-02, 3.6460e-04, 7.9362e-05, 1.1366e-06,\n",
      "        1.2648e-03, 1.5574e-02, 7.0067e-04, 1.8070e-05, 1.8087e-05, 7.6615e-06,\n",
      "        4.1546e-05, 2.8899e-07, 1.5807e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.8676e-04, 6.4827e-02, 1.4776e-04, 8.0366e-05, 1.0480e-03, 1.0243e-02,\n",
      "        8.2901e-04, 2.5223e-05, 8.6428e-05, 1.9450e-02, 2.2946e-06, 7.8828e-07,\n",
      "        6.3916e-03, 2.9593e-05, 1.8153e-05, 8.9209e-01, 2.3034e-05, 6.3765e-06,\n",
      "        3.7077e-05, 1.2875e-03, 4.9192e-04, 2.6282e-03, 1.7536e-05, 1.5189e-05,\n",
      "        3.8027e-06, 2.5490e-05, 3.4897e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3097e-03, 8.9024e-05, 2.1415e-04, 3.2219e-03, 2.1461e-03, 3.2180e-04,\n",
      "        5.8511e-04, 1.2852e-03, 1.0724e-05, 2.8873e-04, 4.8182e-06, 5.5766e-06,\n",
      "        1.1494e-02, 6.0922e-03, 5.6801e-04, 6.3359e-03, 1.7652e-03, 9.7447e-06,\n",
      "        9.3913e-04, 9.5509e-01, 2.6172e-03, 4.3333e-04, 1.0114e-04, 2.7083e-03,\n",
      "        2.8458e-04, 9.0693e-07, 7.9686e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([6.3599e-04, 9.9439e-05, 5.3904e-05, 4.2826e-05, 5.1025e-07, 1.1619e-03,\n",
      "        9.4245e-05, 1.5633e-06, 3.0667e-03, 3.5091e-03, 2.1911e-07, 2.1997e-06,\n",
      "        9.4775e-07, 1.9263e-03, 1.9739e-05, 9.8648e-01, 6.6728e-04, 8.7028e-06,\n",
      "        2.5531e-05, 3.7209e-04, 1.7273e-03, 6.6005e-06, 4.1076e-07, 7.5602e-05,\n",
      "        4.8833e-07, 2.0270e-05, 1.8250e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.3192e-03, 1.7654e-05, 1.8235e-03, 5.5119e-03, 9.7255e-04, 4.9235e-06,\n",
      "        1.4508e-03, 1.9282e-04, 1.9632e-05, 2.4814e-04, 5.4217e-05, 5.4401e-05,\n",
      "        2.0731e-04, 4.1893e-03, 1.3428e-03, 9.3013e-05, 9.7455e-01, 1.5187e-04,\n",
      "        7.0209e-04, 3.2447e-03, 1.2223e-04, 2.6823e-03, 3.5313e-04, 5.0873e-04,\n",
      "        1.0720e-04, 3.5480e-06, 7.1175e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3393e-04, 9.0518e-04, 5.5136e-06, 7.7744e-06, 9.5530e-06, 3.0567e-02,\n",
      "        2.2304e-06, 2.3064e-06, 9.6215e-01, 3.2362e-04, 8.0000e-06, 3.1660e-06,\n",
      "        1.1801e-04, 4.5524e-05, 3.2275e-06, 1.7697e-03, 4.5972e-04, 1.1151e-05,\n",
      "        2.1049e-03, 6.5998e-04, 4.6809e-05, 1.1741e-04, 2.1235e-06, 1.2425e-04,\n",
      "        2.7349e-05, 1.6574e-04, 2.1942e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([1.0222e-03, 4.8180e-03, 4.3324e-05, 9.4370e-07, 3.1245e-06, 6.2694e-01,\n",
      "        5.4196e-05, 4.7856e-06, 1.1250e-05, 1.4249e-01, 2.3222e-06, 6.2130e-08,\n",
      "        2.7751e-04, 4.6258e-05, 1.0510e-04, 2.2713e-03, 2.0387e-05, 1.8906e-07,\n",
      "        5.4347e-04, 1.9962e-03, 4.9404e-05, 1.1935e-04, 4.6677e-07, 1.0493e-04,\n",
      "        4.5867e-06, 2.1907e-01, 5.6880e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.6457e-03, 1.2981e-02, 8.7509e-04, 5.5492e-01, 7.5857e-04, 8.8577e-03,\n",
      "        4.4063e-03, 4.0789e-03, 1.1860e-03, 1.3275e-05, 1.5774e-05, 8.7787e-06,\n",
      "        1.7776e-02, 4.8383e-04, 1.5071e-01, 5.7411e-02, 1.8810e-03, 6.6462e-05,\n",
      "        1.0063e-02, 1.3510e-01, 1.9874e-02, 2.0185e-04, 9.7744e-04, 1.0127e-04,\n",
      "        3.5713e-03, 3.1410e-06, 1.2041e-02], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.4035e-02, 9.0534e-01, 4.6107e-06, 1.4263e-04, 8.6515e-05, 1.8366e-02,\n",
      "        5.7201e-06, 3.6127e-05, 1.7788e-02, 1.5756e-02, 1.6356e-06, 4.5783e-04,\n",
      "        1.9460e-04, 9.3235e-06, 2.6044e-04, 1.3289e-02, 3.9048e-06, 6.7388e-05,\n",
      "        1.3231e-03, 5.1671e-03, 5.1193e-03, 1.3077e-03, 2.6556e-06, 1.9235e-05,\n",
      "        2.2930e-05, 9.7151e-04, 2.2286e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.4957e-03, 3.3752e-06, 9.2468e-04, 2.9641e-04, 8.0124e-05, 5.8802e-07,\n",
      "        3.3527e-06, 1.4239e-04, 1.5794e-06, 3.2186e-04, 5.5573e-06, 1.8523e-05,\n",
      "        9.6946e-01, 2.0297e-04, 6.3248e-03, 4.9640e-05, 3.8187e-05, 1.4229e-06,\n",
      "        1.3586e-03, 3.5117e-03, 1.5571e-02, 8.7416e-05, 7.5041e-06, 3.0454e-06,\n",
      "        7.9405e-06, 5.3601e-05, 3.0826e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.4440e-01, 6.5458e-05, 6.4784e-05, 1.4411e-04, 3.1447e-05, 1.9090e-04,\n",
      "        9.6207e-05, 2.4086e-06, 1.0396e-05, 4.2970e-03, 6.0028e-07, 5.0004e-06,\n",
      "        2.8500e-02, 9.9891e-05, 1.7466e-04, 4.4299e-04, 4.4918e-06, 3.4293e-06,\n",
      "        1.1154e-04, 2.0700e-02, 2.5078e-05, 1.5244e-04, 5.6463e-05, 6.3438e-05,\n",
      "        8.5991e-06, 3.2464e-04, 2.7198e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0638e-06, 4.4968e-02, 2.1150e-02, 6.3074e-02, 4.1647e-02, 9.7593e-03,\n",
      "        1.1780e-01, 8.9165e-03, 1.6281e-02, 5.3481e-02, 5.7044e-03, 1.6045e-03,\n",
      "        1.2650e-02, 6.2153e-02, 2.4296e-02, 8.3746e-02, 5.7506e-02, 2.2635e-03,\n",
      "        2.0386e-02, 1.7383e-01, 3.5375e-02, 2.3046e-02, 2.5498e-02, 8.7814e-02,\n",
      "        8.0760e-05, 4.7236e-03, 2.2402e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.7445e-06, 5.9170e-04, 7.2567e-04, 5.2245e-04, 7.4029e-05, 2.0380e-03,\n",
      "        1.6019e-04, 9.1528e-05, 9.8361e-05, 1.3567e-03, 8.4651e-07, 2.1985e-06,\n",
      "        1.6487e-02, 1.2658e-03, 3.9980e-01, 2.5963e-05, 1.6131e-01, 6.5412e-06,\n",
      "        2.2719e-03, 3.8244e-01, 3.0492e-02, 2.4283e-05, 3.0642e-06, 1.9442e-04,\n",
      "        1.6919e-05, 1.3439e-06, 2.7010e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.6340e-02, 2.8701e-02, 2.3396e-03, 1.0011e-03, 1.1215e-04, 7.3297e-01,\n",
      "        6.3053e-03, 1.4731e-05, 3.9672e-04, 7.8224e-02, 7.6807e-06, 1.0496e-04,\n",
      "        5.5969e-03, 1.0468e-02, 6.5306e-04, 1.5067e-02, 6.3648e-03, 1.7642e-05,\n",
      "        4.6250e-04, 1.1408e-02, 3.0918e-02, 1.9137e-02, 1.3347e-05, 6.4764e-04,\n",
      "        2.7181e-06, 2.7212e-03, 3.4193e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.6956e-01, 7.0188e-03, 5.6454e-03, 2.7577e-02, 9.7133e-02, 5.6018e-04,\n",
      "        7.1707e-02, 7.6943e-04, 3.6476e-04, 1.6518e-03, 4.2649e-05, 8.3410e-07,\n",
      "        2.3285e-02, 1.9968e-02, 7.4287e-03, 3.8732e-03, 4.1042e-04, 1.8679e-03,\n",
      "        2.3063e-02, 2.6814e-01, 5.4676e-02, 4.4916e-04, 7.3131e-03, 5.3033e-03,\n",
      "        7.3731e-04, 1.4421e-03, 1.0557e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.3747e-01, 1.4366e-04, 9.2868e-06, 2.2039e-04, 6.2184e-07, 2.3882e-05,\n",
      "        8.4154e-04, 3.7992e-07, 9.2259e-04, 1.7293e-03, 3.2889e-07, 1.1411e-05,\n",
      "        9.1799e-05, 1.0879e-03, 9.0072e-06, 3.2538e-04, 7.9243e-03, 6.2929e-06,\n",
      "        7.4105e-06, 3.1485e-03, 4.3992e-02, 1.2151e-03, 2.4059e-06, 7.7750e-04,\n",
      "        1.5163e-07, 3.2229e-05, 4.8130e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([5.2793e-08, 2.7744e-01, 1.2449e-02, 6.8452e-03, 8.1931e-03, 1.5119e-02,\n",
      "        2.5897e-02, 4.4319e-03, 1.0703e-01, 1.0991e-01, 2.1707e-03, 3.1202e-03,\n",
      "        3.7836e-03, 3.3653e-02, 2.5820e-03, 1.5922e-01, 2.0088e-02, 9.8524e-04,\n",
      "        1.0697e-02, 3.0162e-02, 6.9050e-02, 3.3814e-03, 2.7557e-03, 8.9279e-02,\n",
      "        6.9896e-06, 1.7478e-03, 1.8404e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.8888e-04, 4.3402e-05, 1.4855e-02, 1.4916e-03, 1.6963e-03, 1.2507e-04,\n",
      "        6.0933e-01, 4.6020e-04, 1.9509e-04, 5.6183e-05, 6.1644e-05, 3.8387e-04,\n",
      "        5.2560e-03, 1.1455e-03, 1.3828e-01, 3.3167e-04, 2.0719e-02, 1.0134e-04,\n",
      "        6.6759e-02, 3.1920e-05, 4.1007e-03, 8.9266e-02, 1.2461e-02, 3.2596e-02,\n",
      "        5.0596e-05, 5.2654e-06, 9.0240e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.3342e-01, 2.7881e-03, 3.6357e-04, 3.8506e-03, 4.5319e-02, 2.1982e-03,\n",
      "        8.0320e-03, 2.1829e-02, 7.4423e-05, 6.7639e-02, 6.8947e-05, 1.4825e-04,\n",
      "        5.2077e-04, 1.2432e-03, 1.7806e-03, 2.3927e-04, 2.5373e-04, 9.4080e-06,\n",
      "        2.7579e-03, 2.9136e-03, 2.1250e-03, 5.4139e-05, 8.0034e-04, 3.4891e-04,\n",
      "        3.7729e-06, 1.2082e-03, 1.2473e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([5.5029e-08, 1.6842e-01, 2.6022e-02, 2.5549e-02, 2.7290e-02, 3.9576e-02,\n",
      "        4.6865e-02, 1.5913e-02, 4.6603e-02, 9.4477e-02, 8.1208e-03, 1.5102e-03,\n",
      "        4.2963e-02, 3.5632e-02, 2.8926e-02, 1.1663e-01, 3.3590e-02, 1.2444e-03,\n",
      "        1.5213e-02, 3.6375e-02, 1.2546e-01, 8.9535e-03, 3.6737e-03, 5.0117e-02,\n",
      "        1.9440e-05, 8.3110e-04, 2.3152e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.3034e-02, 7.9851e-02, 1.1425e-04, 2.0620e-02, 6.1409e-07, 1.6299e-01,\n",
      "        1.5048e-03, 5.4775e-04, 1.0495e-01, 4.9945e-02, 3.9677e-05, 6.0613e-03,\n",
      "        7.3348e-03, 3.8293e-03, 2.7792e-04, 1.6141e-01, 7.3479e-02, 1.0357e-03,\n",
      "        3.9359e-04, 3.6140e-04, 1.0631e-01, 1.5047e-01, 4.0424e-05, 7.4345e-03,\n",
      "        1.9111e-05, 3.7929e-02, 1.6881e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.3968e-04, 7.7768e-03, 1.4231e-01, 3.0986e-01, 2.4071e-02, 3.5333e-03,\n",
      "        7.7646e-02, 1.1384e-02, 3.8174e-04, 1.6880e-02, 1.2220e-03, 6.1109e-04,\n",
      "        8.5039e-03, 3.8554e-02, 2.1704e-02, 2.1253e-03, 1.5505e-01, 1.2798e-04,\n",
      "        1.1711e-01, 5.2737e-02, 1.3982e-03, 5.5805e-04, 3.4501e-03, 6.9734e-04,\n",
      "        1.3027e-03, 3.1718e-05, 3.3051e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([9.2273e-04, 3.9656e-03, 1.6991e-02, 1.9857e-02, 2.6354e-02, 5.9307e-01,\n",
      "        1.7730e-02, 9.7761e-03, 2.6655e-03, 2.6415e-02, 2.5842e-03, 1.9431e-04,\n",
      "        3.7610e-03, 2.2393e-02, 3.0526e-03, 6.0848e-04, 1.3835e-01, 2.9400e-05,\n",
      "        9.1110e-02, 1.2041e-02, 1.2189e-03, 9.1559e-05, 3.7830e-03, 2.6386e-03,\n",
      "        3.6033e-04, 2.2521e-05, 1.3717e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.3143e-01, 2.6685e-03, 1.9463e-03, 9.5644e-04, 9.8804e-03, 4.1203e-05,\n",
      "        3.1333e-02, 1.2507e-05, 1.1078e-04, 4.8086e-05, 1.7521e-04, 3.5562e-07,\n",
      "        3.7210e-02, 7.1823e-04, 1.2834e-03, 3.4379e-04, 3.0177e-04, 2.2049e-04,\n",
      "        2.0965e-02, 1.5735e-01, 5.0017e-04, 3.6064e-06, 1.3474e-04, 2.1756e-03,\n",
      "        1.5657e-04, 2.5117e-05, 7.3426e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.3214e-08, 1.2739e-01, 1.4029e-02, 4.5603e-02, 1.7262e-02, 1.2365e-02,\n",
      "        2.4406e-02, 1.1845e-02, 1.1876e-01, 6.8638e-02, 1.4728e-03, 3.4977e-03,\n",
      "        1.5954e-02, 2.7093e-02, 6.0879e-03, 1.9981e-02, 6.4975e-02, 1.7606e-03,\n",
      "        1.0076e-02, 1.5891e-01, 1.1836e-01, 2.3695e-02, 8.9630e-04, 1.0386e-01,\n",
      "        3.0685e-05, 2.9867e-03, 6.2445e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.0655e-06, 5.7443e-01, 1.8323e-05, 2.2388e-07, 2.0886e-08, 1.8053e-01,\n",
      "        1.8530e-05, 2.9700e-07, 2.4860e-06, 1.1800e-01, 3.0448e-07, 9.3086e-09,\n",
      "        1.3892e-04, 1.8489e-05, 5.3685e-06, 1.0909e-01, 5.5579e-05, 2.0113e-07,\n",
      "        2.9212e-04, 5.6232e-05, 5.7274e-06, 1.4973e-02, 3.2856e-07, 6.0896e-05,\n",
      "        1.5352e-07, 2.2832e-03, 8.1795e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999997615814209\n",
      "Softmaxed: tensor([4.5492e-01, 1.3299e-01, 6.8587e-04, 4.3466e-03, 2.3552e-03, 2.3797e-03,\n",
      "        1.3463e-03, 4.6451e-04, 3.0676e-04, 3.7090e-02, 2.3342e-05, 4.6544e-05,\n",
      "        1.4182e-01, 6.9737e-03, 6.5488e-02, 2.2916e-03, 2.9931e-03, 6.6426e-05,\n",
      "        1.1971e-01, 1.7787e-02, 3.4012e-03, 9.7768e-05, 8.4760e-04, 4.4322e-04,\n",
      "        2.2581e-04, 8.8044e-04, 2.2522e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.9917e-07, 4.2701e-02, 1.3940e-02, 4.7654e-02, 6.0431e-02, 3.6110e-02,\n",
      "        4.0166e-02, 9.9237e-03, 6.3946e-02, 1.1945e-01, 1.2805e-03, 3.1560e-02,\n",
      "        4.9604e-02, 6.6024e-02, 3.1503e-02, 2.1243e-02, 2.1447e-02, 5.7650e-04,\n",
      "        2.8461e-02, 7.8200e-02, 2.1031e-02, 6.4045e-03, 4.6213e-03, 2.0345e-01,\n",
      "        4.2153e-05, 1.9608e-04, 3.5068e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8225e-05, 2.2305e-01, 3.5318e-06, 8.4353e-07, 6.6456e-09, 1.1916e-01,\n",
      "        1.6499e-06, 1.5454e-06, 1.1791e-01, 3.4227e-01, 3.3131e-07, 3.6095e-06,\n",
      "        8.8859e-05, 6.3248e-05, 2.1282e-05, 1.8986e-01, 1.1947e-07, 5.0901e-07,\n",
      "        7.1330e-03, 1.1424e-05, 1.5705e-05, 1.2376e-04, 1.8398e-08, 5.0040e-05,\n",
      "        1.1397e-06, 1.9846e-04, 2.4313e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.2349e-04, 1.2747e-03, 4.0168e-05, 4.1825e-03, 2.7420e-03, 5.2502e-05,\n",
      "        2.5290e-04, 1.3593e-04, 1.3525e-04, 4.8052e-06, 7.2414e-07, 1.1339e-04,\n",
      "        6.2717e-01, 3.5661e-04, 1.1131e-02, 1.4238e-04, 3.5702e-04, 2.3981e-05,\n",
      "        1.5119e-03, 2.6156e-01, 8.7207e-02, 8.2544e-06, 3.2559e-04, 1.5502e-05,\n",
      "        3.9507e-04, 9.6106e-07, 2.3077e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.3158e-05, 1.6391e-03, 8.1137e-05, 1.4295e-04, 2.0725e-02, 4.9499e-03,\n",
      "        5.3876e-04, 6.6128e-05, 3.8300e-05, 1.2763e-04, 2.1432e-06, 1.4017e-04,\n",
      "        9.6706e-01, 9.0145e-05, 4.8204e-05, 2.6739e-04, 3.4522e-05, 3.3379e-05,\n",
      "        9.6162e-05, 2.9152e-03, 6.8232e-04, 6.1449e-05, 1.3796e-04, 1.8489e-05,\n",
      "        9.7369e-06, 2.8437e-06, 1.1670e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.8643e-01, 1.6665e-04, 9.4473e-06, 6.9534e-07, 8.2335e-05, 1.0313e-03,\n",
      "        1.4196e-04, 7.4614e-07, 2.2530e-06, 2.7985e-04, 3.2769e-07, 5.3909e-07,\n",
      "        5.8389e-04, 3.5458e-05, 1.1549e-05, 2.6115e-03, 5.8244e-07, 1.5990e-06,\n",
      "        2.6906e-05, 2.9434e-03, 2.0626e-05, 7.2993e-05, 3.2146e-05, 7.7630e-04,\n",
      "        3.8923e-06, 4.7336e-03, 1.7526e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5364e-07, 1.0741e-01, 1.0794e-01, 1.2426e-02, 5.3644e-02, 1.0192e-02,\n",
      "        5.1227e-02, 2.1240e-02, 2.0176e-02, 7.0426e-02, 3.7174e-03, 2.3134e-03,\n",
      "        2.1791e-02, 2.3504e-02, 4.0922e-02, 1.2136e-01, 4.7191e-02, 7.2047e-04,\n",
      "        2.8126e-02, 7.0873e-02, 9.3861e-02, 2.0411e-02, 6.0751e-03, 5.6281e-02,\n",
      "        2.5007e-05, 8.0714e-03, 8.1848e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8221e-05, 1.4376e-02, 6.9214e-05, 1.7487e-06, 1.5294e-05, 7.7805e-01,\n",
      "        7.0712e-06, 3.3322e-04, 1.2834e-04, 3.2344e-03, 6.6315e-05, 1.0875e-04,\n",
      "        6.6441e-03, 6.1289e-07, 2.3356e-04, 3.6853e-02, 5.8060e-05, 3.9108e-06,\n",
      "        2.8695e-02, 8.8988e-05, 4.6042e-05, 1.0441e-01, 2.9459e-05, 8.6110e-05,\n",
      "        1.4024e-05, 2.6419e-02, 9.0945e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([8.2885e-01, 4.2322e-03, 2.0512e-04, 4.5700e-02, 2.0951e-04, 5.1912e-03,\n",
      "        3.4943e-02, 8.7164e-03, 5.7461e-03, 1.4146e-02, 3.3068e-05, 5.0888e-05,\n",
      "        1.3015e-02, 5.8925e-05, 5.3094e-03, 2.4504e-04, 5.7778e-04, 2.4663e-04,\n",
      "        1.5072e-04, 5.2789e-03, 2.0374e-02, 4.3597e-04, 1.5090e-04, 2.6414e-03,\n",
      "        4.5149e-05, 3.4353e-03, 1.4347e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.4780e-08, 1.3693e-01, 3.2653e-02, 3.3110e-02, 7.3956e-02, 3.3062e-02,\n",
      "        6.2807e-02, 6.2858e-02, 2.0559e-02, 5.6246e-02, 4.0450e-03, 2.3457e-03,\n",
      "        4.5761e-02, 4.8914e-02, 2.1663e-02, 4.2759e-02, 8.4371e-02, 8.1218e-04,\n",
      "        4.4993e-02, 4.6782e-02, 8.1162e-02, 1.5636e-02, 8.2446e-03, 3.8843e-02,\n",
      "        5.4317e-05, 1.4272e-03, 7.3375e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1435e-05, 2.8716e-02, 1.3789e-04, 4.9657e-06, 2.1654e-06, 2.3642e-01,\n",
      "        1.6114e-05, 1.9428e-03, 2.3339e-03, 4.5272e-02, 5.7194e-06, 6.9173e-07,\n",
      "        3.4231e-02, 4.3278e-05, 1.7383e-04, 2.8628e-01, 3.9912e-06, 1.2959e-06,\n",
      "        3.2394e-01, 7.9136e-05, 3.6385e-06, 4.0033e-02, 4.6402e-06, 1.1391e-04,\n",
      "        1.2969e-05, 2.0239e-04, 3.7934e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "hat is most difficult for us men of the  <------ | ------> philosophical uses or sure he will be ge\n",
      "Epoch 17   Time 62.817    Train Loss: 1.216\n",
      "Softmaxed: tensor([8.4090e-04, 5.0881e-03, 2.8372e-04, 5.2882e-01, 5.9856e-07, 6.2838e-02,\n",
      "        5.5207e-04, 1.5415e-05, 1.1669e-03, 2.2450e-01, 3.0886e-05, 9.6515e-05,\n",
      "        5.2188e-03, 1.7114e-03, 9.7654e-05, 6.2752e-03, 3.9806e-02, 4.4445e-04,\n",
      "        4.3388e-06, 7.5988e-03, 8.0465e-02, 3.0670e-02, 3.2762e-05, 4.9576e-04,\n",
      "        3.1739e-06, 2.9236e-03, 1.5000e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.7515e-06, 2.4510e-02, 2.4688e-06, 5.7845e-06, 1.3528e-07, 7.5733e-03,\n",
      "        2.8246e-06, 6.4788e-07, 5.0125e-04, 9.1904e-01, 5.4780e-07, 1.1666e-05,\n",
      "        9.4700e-06, 9.8241e-07, 1.1234e-07, 7.1631e-03, 1.9482e-06, 3.1131e-05,\n",
      "        1.2241e-02, 8.0468e-05, 7.7338e-06, 2.3097e-02, 1.1400e-06, 6.6353e-07,\n",
      "        4.1991e-07, 5.7155e-03, 5.0041e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.6518e-04, 5.5026e-02, 3.9358e-03, 4.6570e-03, 4.0283e-04, 3.2444e-01,\n",
      "        4.2985e-04, 7.7775e-05, 5.4195e-06, 1.3340e-03, 1.7074e-06, 1.1849e-05,\n",
      "        1.0332e-02, 1.4266e-03, 5.9450e-03, 5.4453e-01, 1.0194e-02, 1.0570e-04,\n",
      "        6.3159e-04, 3.8001e-03, 2.4470e-02, 2.6053e-03, 5.2662e-03, 1.0326e-05,\n",
      "        5.0180e-05, 1.1867e-06, 1.4555e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.7900e-03, 1.0339e-03, 1.9105e-04, 2.4819e-03, 2.1176e-03, 3.0683e-03,\n",
      "        2.5625e-03, 8.3741e-05, 1.7221e-05, 5.7413e-03, 3.2404e-06, 6.0539e-05,\n",
      "        9.3579e-04, 2.4397e-03, 8.9003e-01, 8.6533e-05, 2.0408e-04, 1.4145e-04,\n",
      "        2.8844e-03, 2.8163e-02, 4.3187e-02, 1.4859e-03, 2.1863e-03, 6.8014e-03,\n",
      "        1.8224e-04, 4.8137e-05, 7.6316e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.9365e-04, 1.1187e-03, 2.8810e-05, 8.7555e-01, 9.2486e-04, 4.4738e-03,\n",
      "        5.8579e-04, 1.3766e-04, 4.5893e-06, 1.1840e-03, 2.4563e-05, 4.5964e-05,\n",
      "        7.2849e-05, 1.1884e-05, 1.5240e-05, 3.5308e-04, 9.2398e-07, 1.3013e-04,\n",
      "        1.5526e-06, 1.2380e-03, 1.1022e-01, 2.8364e-03, 4.6906e-04, 6.6030e-05,\n",
      "        2.1152e-05, 5.5072e-05, 3.1853e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.5882e-06, 2.1016e-03, 7.3459e-07, 3.2620e-05, 2.2448e-07, 9.7894e-01,\n",
      "        1.1374e-06, 1.3324e-06, 2.2886e-04, 1.3408e-02, 1.4307e-07, 4.3314e-05,\n",
      "        7.9541e-04, 9.9761e-07, 2.4311e-06, 3.0227e-05, 8.0121e-08, 4.8797e-06,\n",
      "        1.5786e-04, 4.1182e-04, 8.4374e-04, 9.9534e-04, 7.7609e-07, 2.0695e-06,\n",
      "        2.6688e-07, 1.9881e-03, 2.3782e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.9995e-01, 5.7158e-05, 6.0672e-05, 6.2708e-06, 1.6589e-02, 4.5561e-06,\n",
      "        8.9691e-04, 2.8409e-06, 7.8781e-07, 6.1506e-05, 2.3536e-07, 5.9166e-07,\n",
      "        3.8422e-04, 1.1151e-03, 2.6005e-04, 1.0520e-05, 8.0611e-05, 4.6899e-06,\n",
      "        3.9021e-04, 7.9303e-02, 2.3948e-04, 2.3076e-05, 4.7926e-04, 2.8178e-05,\n",
      "        1.4038e-05, 3.4388e-05, 2.7857e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.5622e-08, 1.3123e-01, 2.4827e-02, 2.6694e-02, 1.3753e-02, 1.2417e-02,\n",
      "        3.7351e-02, 4.9502e-03, 3.9775e-02, 8.6122e-02, 8.1447e-04, 8.4022e-04,\n",
      "        1.2816e-02, 3.4434e-02, 1.0964e-02, 2.0255e-01, 1.3255e-02, 1.7740e-03,\n",
      "        1.1725e-02, 3.1428e-02, 2.1578e-01, 1.0813e-02, 5.2141e-03, 6.8440e-02,\n",
      "        9.2810e-06, 1.9761e-03, 5.0519e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.7590e-05, 1.3995e-05, 4.1235e-03, 1.3169e-03, 3.2590e-04, 1.7366e-05,\n",
      "        8.5236e-01, 1.7462e-04, 4.5648e-05, 1.9015e-05, 1.2052e-05, 1.6012e-05,\n",
      "        2.5233e-03, 2.0565e-04, 5.0664e-02, 7.3394e-05, 6.8234e-03, 1.7777e-05,\n",
      "        5.1386e-02, 1.5252e-05, 5.4605e-03, 1.4465e-02, 3.5433e-03, 6.3474e-03,\n",
      "        1.0331e-05, 1.0934e-06, 3.5746e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9554e-01, 6.5887e-06, 5.4037e-06, 4.1968e-05, 8.9501e-06, 1.0114e-04,\n",
      "        2.0814e-03, 1.4375e-06, 1.9182e-06, 2.1398e-06, 4.9092e-06, 2.6650e-06,\n",
      "        1.1974e-04, 1.4196e-04, 2.4133e-07, 3.8972e-06, 4.2506e-05, 1.1681e-06,\n",
      "        1.3641e-05, 1.6550e-06, 1.8240e-03, 2.3867e-06, 2.9340e-05, 1.9103e-05,\n",
      "        1.7206e-07, 2.5715e-06, 7.5941e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.7124e-07, 9.7989e-02, 1.2776e-02, 3.2468e-02, 2.4946e-02, 3.5679e-02,\n",
      "        2.0847e-02, 1.4706e-02, 5.9614e-02, 4.4769e-02, 3.7235e-03, 7.5498e-03,\n",
      "        2.9844e-02, 5.2590e-02, 1.2723e-02, 3.6357e-02, 2.6982e-02, 5.1649e-04,\n",
      "        4.4471e-02, 5.9159e-02, 3.2167e-01, 3.4720e-03, 1.5088e-02, 3.5614e-02,\n",
      "        5.3048e-05, 6.2793e-03, 1.1160e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.5342e-05, 2.1746e-04, 3.1708e-03, 5.5093e-04, 6.6024e-04, 1.4491e-03,\n",
      "        4.7128e-05, 3.2774e-04, 2.5250e-04, 2.1779e-03, 2.0638e-06, 2.8608e-05,\n",
      "        8.6457e-02, 1.1101e-02, 6.8521e-01, 5.5681e-06, 5.6563e-02, 3.6271e-06,\n",
      "        1.7023e-03, 8.8251e-02, 6.1117e-02, 8.0159e-06, 2.5988e-06, 5.9694e-04,\n",
      "        6.5414e-05, 1.2056e-05, 5.7078e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4174e-02, 3.6050e-02, 9.6262e-03, 3.9561e-02, 4.3179e-01, 2.2133e-02,\n",
      "        1.5172e-02, 9.2450e-03, 1.5555e-02, 1.3779e-01, 8.5018e-03, 1.0007e-02,\n",
      "        2.7230e-02, 3.7998e-04, 4.3972e-02, 2.3575e-03, 2.7092e-03, 1.6511e-03,\n",
      "        2.4077e-02, 8.2203e-03, 1.1885e-01, 4.9841e-04, 2.3074e-03, 5.9951e-03,\n",
      "        7.3018e-04, 1.3565e-03, 6.4292e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.8690e-04, 5.1900e-03, 5.3088e-03, 2.5811e-03, 5.7096e-02, 8.6590e-03,\n",
      "        6.4857e-02, 2.8228e-02, 8.9786e-04, 4.4805e-05, 1.2910e-04, 9.2304e-04,\n",
      "        1.6649e-02, 9.8828e-02, 1.4501e-02, 1.4163e-03, 1.4985e-02, 1.8030e-02,\n",
      "        2.5996e-02, 5.6914e-02, 4.1986e-01, 1.5884e-03, 1.5392e-01, 6.5603e-04,\n",
      "        1.6576e-03, 1.7706e-06, 3.0088e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4106e-02, 9.6740e-02, 1.3953e-03, 5.9781e-03, 6.7750e-06, 2.2155e-02,\n",
      "        1.1992e-01, 9.2418e-06, 6.1969e-04, 1.7188e-01, 1.6800e-04, 2.7709e-04,\n",
      "        7.6720e-02, 5.1698e-04, 6.5963e-04, 9.4174e-02, 5.8541e-05, 2.1556e-03,\n",
      "        1.6454e-02, 9.2304e-05, 3.0423e-01, 4.2756e-02, 1.8978e-02, 7.6746e-03,\n",
      "        6.1424e-04, 1.5023e-03, 1.6049e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.5128e-04, 1.3606e-04, 2.6286e-03, 4.1217e-01, 1.6688e-02, 5.6655e-04,\n",
      "        1.5209e-03, 1.6772e-03, 3.3734e-04, 1.6540e-01, 4.5541e-04, 8.0910e-03,\n",
      "        2.2529e-02, 5.6057e-03, 1.3049e-04, 7.4288e-05, 1.3357e-03, 1.7906e-03,\n",
      "        1.0413e-02, 9.5747e-03, 9.1397e-03, 2.4427e-03, 3.0871e-01, 5.5021e-03,\n",
      "        7.0114e-04, 1.0971e-02, 5.6266e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.0854e-06, 4.7489e-02, 1.9965e-06, 9.5192e-06, 4.1108e-07, 2.4565e-01,\n",
      "        4.4511e-06, 3.9201e-06, 8.5252e-06, 4.1271e-01, 1.3566e-06, 4.7161e-06,\n",
      "        3.4278e-04, 9.5626e-06, 1.5066e-05, 2.6890e-01, 2.3312e-05, 4.1467e-06,\n",
      "        6.1554e-05, 2.3573e-04, 9.5096e-06, 8.9524e-04, 4.3545e-07, 2.4737e-05,\n",
      "        3.3968e-06, 2.3581e-02, 2.8058e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3145e-02, 4.1325e-03, 1.2093e-03, 1.0111e-02, 7.0586e-03, 7.2366e-03,\n",
      "        8.7526e-04, 1.0279e-05, 1.1902e-03, 2.6868e-02, 6.0757e-05, 2.3616e-06,\n",
      "        6.4265e-02, 2.7719e-03, 1.6050e-02, 1.7079e-03, 2.5422e-04, 4.2445e-04,\n",
      "        4.3845e-01, 3.8899e-01, 1.1584e-03, 1.0487e-03, 5.8832e-03, 1.6873e-03,\n",
      "        7.5634e-04, 4.6122e-03, 4.2079e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7165e-01, 1.7887e-04, 1.7880e-04, 4.1778e-04, 1.0906e-06, 1.6799e-03,\n",
      "        7.5517e-05, 9.5345e-05, 1.4174e-04, 6.8263e-03, 1.7124e-06, 4.9261e-05,\n",
      "        7.0573e-03, 1.2476e-03, 1.1651e-03, 5.5002e-04, 7.4580e-05, 3.4123e-06,\n",
      "        5.2765e-04, 1.2195e-03, 5.4011e-03, 1.2378e-03, 2.4691e-05, 7.5423e-05,\n",
      "        1.1187e-05, 1.5754e-06, 1.0753e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.5790e-07, 1.3719e-01, 8.2186e-02, 1.9661e-02, 1.1284e-02, 7.0267e-03,\n",
      "        2.3572e-02, 1.7661e-02, 5.8069e-02, 1.3135e-01, 5.1261e-04, 1.8091e-03,\n",
      "        1.0774e-02, 1.5985e-02, 1.9330e-02, 1.2454e-01, 2.4010e-02, 7.4453e-04,\n",
      "        1.9269e-02, 2.9523e-02, 1.7879e-01, 2.2314e-02, 3.1612e-03, 5.5314e-02,\n",
      "        6.4552e-06, 5.8731e-03, 5.5003e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.5524e-02, 4.4505e-05, 2.2475e-02, 2.4433e-02, 3.5173e-03, 1.0018e-05,\n",
      "        1.5824e-02, 1.2180e-02, 1.4578e-04, 5.7151e-04, 1.0676e-05, 8.3043e-05,\n",
      "        7.3047e-02, 9.4679e-03, 4.6134e-01, 1.5733e-05, 1.3710e-02, 5.2920e-05,\n",
      "        6.2779e-02, 1.3468e-01, 7.1181e-02, 1.7620e-03, 1.2143e-03, 5.4741e-03,\n",
      "        1.3431e-04, 3.0237e-04, 1.8849e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.4650e-03, 7.3210e-01, 1.2044e-03, 7.3287e-05, 1.4253e-03, 1.1678e-01,\n",
      "        1.0443e-04, 1.5751e-03, 4.7032e-03, 1.7412e-03, 3.4497e-05, 3.8956e-05,\n",
      "        6.4453e-04, 1.6993e-03, 1.0688e-03, 7.3995e-02, 3.1256e-04, 1.4402e-04,\n",
      "        5.1672e-02, 1.4804e-03, 2.6223e-04, 4.8233e-03, 1.3360e-04, 3.6992e-04,\n",
      "        6.0355e-05, 4.3953e-05, 3.8715e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.1398e-01, 2.6500e-02, 9.2968e-04, 9.8974e-05, 7.6136e-03, 1.0271e-02,\n",
      "        1.9183e-02, 1.0827e-06, 3.3532e-04, 2.9851e-04, 1.5615e-05, 8.8033e-06,\n",
      "        3.6232e-03, 1.2885e-02, 1.4546e-02, 7.8522e-03, 3.0834e-03, 1.0611e-04,\n",
      "        1.7696e-02, 6.2366e-01, 6.5674e-03, 4.0820e-05, 2.7302e-02, 2.4343e-03,\n",
      "        7.5377e-04, 1.0251e-04, 1.1173e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.1824e-08, 8.0646e-02, 2.3492e-02, 6.7668e-03, 8.9082e-03, 1.2721e-02,\n",
      "        4.9220e-02, 2.4493e-03, 2.1204e-02, 4.9462e-02, 4.8588e-04, 4.4927e-04,\n",
      "        8.6257e-03, 3.3520e-02, 9.7801e-03, 1.2699e-01, 3.9854e-02, 7.4875e-04,\n",
      "        5.4644e-03, 4.4142e-02, 3.9277e-01, 1.2377e-02, 4.0620e-03, 6.5053e-02,\n",
      "        2.2646e-05, 7.0218e-04, 8.4526e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8712e-05, 6.4135e-03, 2.6099e-06, 1.1240e-07, 1.2703e-08, 3.5339e-03,\n",
      "        4.0189e-05, 1.6646e-06, 7.6726e-01, 4.0772e-03, 3.3446e-07, 4.5754e-06,\n",
      "        4.4928e-05, 6.3155e-06, 2.1308e-06, 2.0857e-01, 4.3592e-07, 1.4674e-06,\n",
      "        7.6613e-03, 1.0880e-05, 5.8018e-06, 9.8555e-04, 2.1422e-07, 9.8686e-04,\n",
      "        6.3278e-08, 3.6186e-04, 4.2211e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.1974e-05, 2.0376e-01, 1.1145e-06, 1.2999e-09, 4.8836e-07, 6.9586e-01,\n",
      "        4.9279e-07, 3.5424e-07, 4.3980e-06, 6.1184e-02, 4.0376e-07, 1.5700e-07,\n",
      "        1.8462e-05, 2.7352e-05, 7.3330e-05, 1.0852e-02, 1.3087e-06, 3.7407e-08,\n",
      "        1.9182e-02, 1.1679e-04, 2.9815e-06, 8.4332e-03, 1.5262e-08, 8.9073e-05,\n",
      "        7.9108e-07, 2.9033e-04, 5.9822e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.8816e-01, 5.6529e-05, 2.0592e-05, 3.3641e-06, 1.5460e-05, 1.1581e-03,\n",
      "        7.7080e-05, 4.7782e-04, 1.2530e-03, 3.5948e-02, 1.3492e-05, 1.5604e-05,\n",
      "        3.7249e-04, 6.1305e-02, 1.1594e-02, 2.6356e-04, 4.3194e-04, 1.0041e-06,\n",
      "        1.0087e-01, 1.2020e-02, 5.9757e-04, 4.1039e-06, 4.5330e-05, 5.6794e-04,\n",
      "        2.8770e-05, 8.4657e-02, 4.8622e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.1266e-07, 3.4888e-02, 5.5596e-02, 8.3624e-02, 6.9398e-02, 4.6647e-02,\n",
      "        5.0567e-02, 4.4830e-02, 4.4984e-02, 4.0720e-02, 3.3063e-03, 3.0869e-03,\n",
      "        4.7754e-02, 6.7698e-02, 2.2262e-02, 4.3674e-02, 5.4325e-02, 4.0115e-03,\n",
      "        4.1588e-02, 1.0928e-01, 4.9419e-02, 1.6795e-02, 1.9327e-02, 4.2942e-02,\n",
      "        2.4066e-05, 3.2031e-03, 4.7485e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.3038e-06, 2.9065e-05, 6.6586e-02, 7.1482e-03, 1.1687e-02, 3.6896e-03,\n",
      "        3.3996e-02, 2.9452e-03, 1.4360e-04, 4.3205e-05, 1.8807e-04, 7.9225e-04,\n",
      "        2.5728e-01, 1.3723e-03, 1.6360e-01, 9.2794e-04, 1.0239e-01, 2.5353e-05,\n",
      "        1.6121e-01, 1.6248e-05, 1.1483e-01, 3.9434e-02, 1.0742e-02, 2.0790e-02,\n",
      "        9.4610e-05, 2.0250e-05, 1.0987e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9843e-03, 3.7778e-03, 1.0855e-03, 7.1942e-03, 3.3027e-04, 2.6073e-01,\n",
      "        6.5891e-04, 7.8292e-05, 9.4838e-03, 1.8577e-01, 1.5477e-04, 1.4459e-04,\n",
      "        4.0504e-03, 3.3543e-04, 2.5201e-04, 9.1738e-04, 4.8758e-01, 3.6014e-05,\n",
      "        1.6307e-03, 2.2106e-02, 9.9928e-03, 7.7014e-04, 1.1278e-04, 5.6912e-04,\n",
      "        1.1161e-05, 2.1021e-04, 4.0842e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.7665e-03, 4.1670e-02, 1.3009e-03, 4.1109e-03, 4.9549e-02, 4.0455e-04,\n",
      "        9.5706e-04, 6.0923e-06, 1.0640e-03, 4.6206e-04, 1.2571e-05, 5.1865e-07,\n",
      "        4.3487e-03, 1.5325e-03, 2.9902e-01, 6.3803e-03, 5.1970e-04, 6.8216e-05,\n",
      "        5.6273e-01, 1.5855e-02, 4.7208e-03, 6.1039e-06, 4.4679e-05, 1.7750e-04,\n",
      "        1.4570e-04, 1.4080e-04, 2.2733e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.5754e-02, 5.6265e-01, 1.6358e-04, 2.7591e-04, 8.2415e-05, 8.9435e-03,\n",
      "        3.6762e-03, 1.5124e-05, 5.5182e-04, 2.5086e-01, 1.3301e-06, 7.6047e-06,\n",
      "        4.8429e-03, 1.7407e-03, 4.8900e-03, 7.0654e-02, 6.1277e-05, 3.9445e-06,\n",
      "        8.5400e-04, 8.9783e-03, 1.5309e-03, 1.5881e-03, 3.2103e-04, 4.0373e-04,\n",
      "        1.4357e-05, 3.1127e-02, 2.2729e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.5742e-04, 3.8186e-05, 2.5887e-02, 6.1464e-03, 5.7749e-04, 8.2067e-06,\n",
      "        3.5097e-04, 2.2470e-03, 6.3033e-06, 2.5452e-03, 2.2920e-05, 1.8984e-05,\n",
      "        9.5089e-03, 2.1686e-03, 4.1742e-02, 1.3708e-05, 6.2485e-03, 6.6611e-06,\n",
      "        3.1478e-03, 1.1671e-03, 8.9313e-01, 3.5628e-03, 5.2352e-04, 3.5396e-05,\n",
      "        8.7101e-06, 5.8423e-05, 7.3206e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.7814e-03, 3.0825e-03, 1.8903e-05, 3.5594e-05, 1.2587e-06, 4.3062e-01,\n",
      "        9.2228e-05, 2.5210e-07, 6.6789e-04, 5.3266e-01, 8.2270e-07, 3.3533e-06,\n",
      "        2.7869e-04, 3.6188e-05, 1.6163e-03, 2.5036e-02, 1.7608e-05, 7.0631e-06,\n",
      "        5.1117e-04, 5.8159e-04, 5.0682e-04, 2.1637e-03, 2.8093e-06, 8.5437e-05,\n",
      "        5.1876e-08, 1.7448e-04, 1.4011e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8373e-04, 1.0111e-02, 2.7863e-03, 4.1376e-03, 1.2518e-03, 9.0373e-03,\n",
      "        1.3888e-03, 7.6853e-05, 3.7005e-06, 6.5053e-05, 1.8911e-06, 1.2095e-06,\n",
      "        6.7433e-04, 8.2481e-04, 2.0691e-02, 9.0286e-01, 6.6052e-05, 4.1007e-05,\n",
      "        1.1435e-04, 1.3137e-03, 2.4609e-03, 2.1627e-05, 4.1388e-02, 1.3077e-05,\n",
      "        3.9359e-06, 8.5598e-07, 2.8120e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.4506e-04, 1.7110e-06, 5.9332e-07, 1.7387e-05, 2.9389e-05, 8.2568e-08,\n",
      "        2.0879e-05, 9.6797e-06, 2.7671e-09, 5.9510e-07, 4.4825e-08, 1.8676e-06,\n",
      "        1.4676e-04, 1.1229e-04, 9.9868e-01, 1.1422e-07, 1.7395e-05, 3.8721e-07,\n",
      "        1.4279e-04, 3.7640e-04, 5.5218e-05, 2.3824e-04, 2.1227e-07, 4.2578e-07,\n",
      "        2.0475e-06, 4.2199e-09, 1.1568e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.4665e-01, 1.0166e-02, 4.8064e-07, 1.0624e-04, 8.6483e-04, 6.8690e-04,\n",
      "        9.6361e-06, 7.1167e-07, 2.3479e-06, 3.4557e-04, 6.8770e-08, 9.3517e-07,\n",
      "        9.5309e-05, 8.1081e-05, 2.4192e-05, 7.9929e-05, 1.8999e-06, 1.7814e-06,\n",
      "        4.8415e-07, 4.4064e-01, 1.8239e-04, 8.9091e-06, 1.4510e-07, 4.1451e-06,\n",
      "        2.3126e-07, 4.9272e-05, 1.2952e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9745e-01, 2.7260e-04, 3.6985e-06, 2.3161e-05, 1.9379e-07, 7.8192e-04,\n",
      "        1.5574e-04, 7.5874e-08, 1.3978e-04, 2.0475e-04, 2.0055e-07, 1.0150e-06,\n",
      "        5.9007e-05, 2.4630e-04, 1.3158e-05, 1.5615e-04, 1.5642e-05, 3.1905e-07,\n",
      "        1.2406e-06, 7.8091e-05, 1.9561e-04, 1.4387e-04, 1.9448e-07, 3.3396e-05,\n",
      "        1.6922e-08, 2.6687e-05, 3.0255e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.0696e-07, 1.8603e-01, 3.0006e-02, 1.6118e-02, 3.9847e-03, 4.8688e-03,\n",
      "        3.9327e-02, 2.4175e-03, 6.8005e-02, 1.0426e-01, 6.8946e-04, 3.0319e-04,\n",
      "        7.8713e-03, 7.7620e-03, 1.0786e-02, 2.2513e-01, 6.5831e-03, 5.9312e-04,\n",
      "        4.5015e-03, 5.8929e-02, 1.2972e-01, 7.5437e-03, 2.0986e-03, 8.0343e-02,\n",
      "        5.7171e-06, 2.1246e-03, 1.0759e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.1090e-02, 1.8007e-05, 1.4227e-02, 1.1893e-02, 2.1981e-03, 1.8434e-06,\n",
      "        1.3844e-02, 5.5997e-03, 6.5562e-05, 2.1988e-04, 9.7970e-06, 2.3926e-05,\n",
      "        2.3316e-02, 2.7608e-03, 7.6780e-01, 4.8750e-06, 5.0658e-03, 2.9592e-05,\n",
      "        5.3498e-02, 3.2797e-02, 3.1334e-02, 3.4060e-04, 1.0955e-03, 2.6176e-03,\n",
      "        8.7828e-05, 5.1473e-05, 1.4048e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      " and a species of involuntary and uncons <------ | ------> cience of unifavey age the operations an\n",
      "Epoch 18   Time 62.582    Train Loss: 1.209\n",
      "Softmaxed: tensor([1.1053e-03, 5.5372e-05, 7.8038e-04, 2.7681e-03, 2.8291e-02, 1.2964e-03,\n",
      "        1.2932e-03, 1.3221e-01, 2.0501e-05, 3.6352e-06, 5.8485e-06, 9.0810e-05,\n",
      "        5.8646e-03, 1.9854e-01, 1.3988e-02, 2.5585e-05, 3.6608e-03, 4.9679e-05,\n",
      "        2.5556e-03, 4.6109e-01, 1.4540e-01, 4.4949e-06, 3.8125e-04, 2.9741e-05,\n",
      "        3.5949e-04, 2.2218e-07, 1.2615e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.2536e-04, 3.7798e-06, 4.0800e-07, 2.8390e-05, 1.3769e-04, 2.0154e-04,\n",
      "        4.8268e-05, 7.3921e-04, 9.9625e-01, 2.3670e-05, 4.1362e-06, 1.2262e-04,\n",
      "        1.9561e-05, 3.1409e-05, 3.4945e-05, 1.2482e-04, 1.2339e-05, 2.3394e-06,\n",
      "        7.4296e-04, 6.4121e-04, 1.3908e-04, 4.3739e-06, 4.4829e-06, 1.3489e-05,\n",
      "        1.9958e-06, 3.2196e-08, 3.7187e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.0857e-01, 6.5494e-04, 8.4141e-04, 2.9559e-06, 5.6515e-05, 4.4532e-01,\n",
      "        1.3343e-03, 4.9935e-05, 2.9763e-04, 7.2548e-03, 5.5097e-06, 3.1531e-06,\n",
      "        1.6218e-01, 7.7497e-04, 2.4522e-04, 1.0980e-02, 3.1994e-04, 1.2366e-06,\n",
      "        2.7318e-03, 2.0024e-02, 3.5520e-02, 1.2294e-04, 2.5078e-05, 1.1636e-03,\n",
      "        4.7275e-06, 1.2839e-03, 2.3572e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9742e-08, 5.6996e-02, 1.0972e-02, 8.0793e-02, 1.9288e-02, 8.0094e-03,\n",
      "        9.4419e-02, 4.2612e-03, 1.1884e-01, 3.8978e-02, 1.9475e-03, 9.0968e-04,\n",
      "        1.1581e-02, 3.2462e-02, 2.6987e-02, 5.2154e-02, 4.7505e-02, 2.1188e-03,\n",
      "        1.2919e-03, 1.9466e-01, 1.5072e-01, 2.7798e-03, 2.6023e-03, 3.7575e-02,\n",
      "        2.2530e-05, 2.0603e-03, 6.9759e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.7029e-02, 9.1960e-02, 3.5366e-04, 7.5874e-02, 2.8090e-06, 7.5344e-02,\n",
      "        2.2131e-03, 5.0956e-04, 2.6635e-02, 9.3288e-02, 4.3902e-05, 3.3991e-03,\n",
      "        2.1444e-02, 8.9830e-03, 9.7272e-04, 2.1947e-01, 1.1455e-01, 1.7499e-03,\n",
      "        4.6476e-04, 4.5915e-04, 1.3172e-01, 8.6587e-02, 5.0639e-05, 5.9531e-03,\n",
      "        4.2406e-05, 2.0887e-02, 1.9761e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.6007e-04, 3.0424e-01, 1.4066e-05, 5.4085e-05, 1.6157e-06, 1.9611e-02,\n",
      "        5.8554e-04, 1.0439e-06, 8.0047e-04, 1.6867e-01, 4.8956e-05, 2.3041e-06,\n",
      "        1.4096e-04, 6.5421e-04, 1.8450e-05, 5.1318e-02, 1.1273e-04, 1.8423e-05,\n",
      "        4.2206e-01, 8.6626e-04, 2.0491e-05, 1.8011e-02, 9.7217e-05, 7.7151e-04,\n",
      "        5.4691e-06, 1.1502e-02, 1.1009e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.7630e-07, 1.6747e-01, 1.5124e-04, 1.7898e-04, 2.1491e-05, 3.4898e-01,\n",
      "        2.0650e-05, 3.8720e-04, 9.5330e-04, 1.7189e-01, 8.2465e-05, 1.3770e-04,\n",
      "        1.6552e-03, 3.2969e-04, 1.4080e-04, 1.8636e-01, 4.1363e-04, 5.6021e-05,\n",
      "        3.0810e-04, 9.2802e-06, 4.6925e-05, 1.1601e-01, 5.9390e-04, 5.8475e-05,\n",
      "        7.0605e-05, 3.6675e-03, 1.2966e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.0750e-05, 3.1400e-04, 1.7806e-03, 1.4989e-02, 1.5931e-03, 8.0929e-04,\n",
      "        2.6179e-03, 5.7276e-02, 1.6395e-04, 1.9209e-02, 2.6812e-04, 7.2910e-02,\n",
      "        2.6762e-03, 2.3078e-02, 7.4313e-01, 1.1676e-02, 3.5142e-03, 1.3617e-04,\n",
      "        2.6412e-03, 1.0814e-02, 9.9966e-03, 8.4505e-03, 4.1479e-03, 4.5829e-03,\n",
      "        9.2956e-04, 1.4359e-03, 8.3685e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.3531e-05, 2.2428e-05, 8.4944e-06, 1.0015e-03, 1.4909e-03, 6.0074e-04,\n",
      "        3.1156e-05, 9.8815e-01, 1.1752e-04, 1.1414e-03, 4.0689e-05, 4.6586e-03,\n",
      "        7.6031e-05, 8.4868e-06, 1.1416e-04, 1.1267e-04, 2.1389e-06, 8.0683e-05,\n",
      "        2.4662e-07, 1.1908e-03, 7.1050e-04, 2.7941e-05, 7.5020e-05, 1.4099e-05,\n",
      "        7.8414e-06, 2.5614e-04, 1.5888e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.1308e-01, 1.6131e-02, 3.9694e-04, 8.1351e-06, 3.4435e-04, 2.6119e-01,\n",
      "        5.9159e-05, 7.2523e-04, 1.5597e-02, 6.8817e-03, 1.4824e-05, 7.6647e-06,\n",
      "        5.6408e-03, 2.0753e-03, 7.6192e-04, 1.4664e-03, 3.8703e-05, 9.8866e-06,\n",
      "        3.8966e-03, 6.4993e-02, 2.2367e-04, 4.7025e-03, 2.8444e-06, 7.0590e-04,\n",
      "        3.5216e-05, 9.8096e-04, 3.3536e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.1464e-08, 2.8353e-01, 6.3762e-02, 3.6413e-02, 1.4416e-02, 7.2630e-03,\n",
      "        3.0937e-02, 4.8401e-03, 4.1731e-02, 8.4469e-02, 1.5482e-03, 4.8322e-04,\n",
      "        4.2571e-03, 4.8604e-02, 1.3457e-02, 3.4248e-02, 7.9568e-02, 2.4749e-03,\n",
      "        1.4049e-02, 6.8199e-02, 9.0758e-02, 4.8955e-02, 2.2726e-03, 1.8633e-02,\n",
      "        3.8116e-05, 4.9766e-03, 1.2097e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3101e-05, 3.2605e-01, 3.5133e-04, 8.2283e-08, 5.3788e-08, 1.9295e-01,\n",
      "        1.9000e-05, 1.6307e-07, 3.2591e-05, 7.3732e-02, 1.1971e-06, 6.9134e-08,\n",
      "        1.6956e-06, 1.3477e-05, 2.0473e-05, 2.9135e-01, 7.2138e-04, 3.5638e-06,\n",
      "        9.4999e-05, 2.3741e-04, 1.1872e-07, 7.4168e-02, 4.0050e-06, 7.8121e-05,\n",
      "        1.4219e-06, 4.0128e-02, 1.9551e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.3413e-03, 1.2070e-05, 1.8978e-03, 4.4884e-03, 3.7217e-02, 1.8805e-05,\n",
      "        1.3475e-03, 8.7810e-03, 2.5154e-05, 6.7802e-03, 2.9306e-03, 3.3949e-02,\n",
      "        5.9370e-03, 2.9279e-03, 7.0621e-01, 7.1918e-06, 3.2359e-04, 2.1259e-05,\n",
      "        1.7409e-02, 3.2656e-02, 4.7531e-02, 1.5831e-03, 5.9232e-04, 7.8512e-04,\n",
      "        1.7310e-03, 7.9967e-02, 2.5254e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.2166e-01, 2.2198e-03, 1.7296e-04, 1.1060e-03, 8.0054e-04, 1.7728e-03,\n",
      "        6.8844e-03, 1.0473e-02, 3.2849e-03, 1.2675e-01, 1.3729e-03, 1.4210e-01,\n",
      "        5.1792e-04, 2.3286e-05, 5.5321e-02, 2.3431e-04, 1.8446e-05, 2.2333e-04,\n",
      "        9.6494e-05, 2.8387e-03, 1.6862e-02, 1.7164e-03, 1.4939e-05, 2.4831e-03,\n",
      "        9.3481e-04, 2.0009e-01, 3.7058e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.8882e-07, 1.9918e-01, 2.1718e-02, 4.3526e-02, 1.7671e-02, 1.0795e-02,\n",
      "        3.5501e-02, 5.4384e-03, 5.8355e-02, 2.0298e-01, 2.6565e-03, 4.3096e-04,\n",
      "        4.1056e-02, 1.7695e-02, 9.6907e-03, 6.6366e-02, 2.2599e-02, 6.1562e-04,\n",
      "        3.2967e-03, 1.2217e-01, 5.4605e-02, 8.2203e-03, 1.3502e-03, 5.1332e-02,\n",
      "        1.3903e-05, 2.7179e-03, 2.4945e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2221e-05, 2.9719e-01, 2.2438e-05, 1.2396e-07, 6.8250e-08, 3.3296e-01,\n",
      "        3.6939e-05, 2.3323e-06, 7.1756e-06, 2.6061e-01, 4.2204e-07, 2.2311e-08,\n",
      "        7.6558e-05, 1.7772e-05, 6.3875e-06, 5.1969e-02, 6.1257e-05, 7.8532e-07,\n",
      "        5.5659e-04, 1.2346e-04, 1.0120e-05, 4.7142e-02, 1.1154e-06, 1.3779e-04,\n",
      "        2.8813e-07, 9.0458e-03, 1.2912e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9107e-03, 3.4511e-05, 1.5504e-02, 1.7071e-03, 3.0140e-02, 2.1004e-05,\n",
      "        1.2757e-03, 8.5949e-04, 4.8707e-06, 6.4866e-03, 2.9317e-05, 6.8759e-05,\n",
      "        7.2365e-04, 5.0784e-03, 4.3819e-02, 6.1360e-06, 3.4131e-02, 1.5426e-05,\n",
      "        3.1576e-02, 4.7891e-01, 6.2725e-03, 4.4854e-03, 3.3392e-01, 4.3561e-04,\n",
      "        1.5095e-04, 1.1873e-03, 1.2376e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.2266e-04, 2.0799e-04, 1.0559e-05, 4.8587e-06, 5.3191e-06, 9.3225e-01,\n",
      "        1.2704e-03, 3.4876e-05, 2.0471e-05, 4.8231e-02, 4.3802e-07, 3.5209e-05,\n",
      "        1.5202e-05, 1.5623e-05, 7.4377e-04, 6.1664e-03, 1.2195e-03, 3.7579e-06,\n",
      "        1.7927e-04, 7.2683e-05, 4.4112e-05, 4.2884e-06, 3.2241e-06, 9.1577e-05,\n",
      "        1.8227e-06, 8.9396e-03, 8.6987e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9878e-01, 8.6514e-07, 6.0674e-06, 3.4575e-07, 3.9204e-05, 5.4008e-07,\n",
      "        9.8770e-05, 4.8967e-07, 1.6237e-07, 4.6646e-06, 2.3078e-08, 4.1585e-08,\n",
      "        1.2009e-05, 3.6798e-07, 3.0779e-04, 1.6381e-07, 2.8079e-06, 1.5360e-07,\n",
      "        7.3014e-05, 6.1348e-04, 1.2772e-06, 9.7262e-08, 3.7979e-06, 4.4621e-05,\n",
      "        3.4751e-07, 1.2737e-05, 7.6162e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.1626e-07, 1.1454e-01, 1.1585e-01, 2.2491e-02, 3.2978e-02, 3.0817e-02,\n",
      "        4.9044e-02, 1.0534e-02, 4.2521e-02, 4.6311e-02, 4.9926e-03, 1.3988e-02,\n",
      "        2.1160e-02, 1.4757e-02, 4.3913e-02, 2.8580e-02, 4.2027e-02, 6.9807e-04,\n",
      "        1.4997e-02, 5.7940e-02, 1.9753e-01, 3.5212e-02, 1.2565e-02, 3.5662e-02,\n",
      "        1.8630e-05, 1.0797e-02, 7.3029e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.4541e-05, 3.7563e-02, 2.7172e-06, 4.3473e-08, 2.6106e-08, 1.6618e-02,\n",
      "        4.8369e-05, 3.8017e-07, 2.7093e-01, 2.0199e-02, 5.5174e-07, 2.5207e-06,\n",
      "        8.4322e-05, 2.1335e-06, 3.0543e-06, 5.5898e-01, 1.2184e-07, 1.2932e-06,\n",
      "        8.9132e-02, 1.4034e-05, 1.5520e-06, 2.5190e-03, 7.1739e-07, 1.9801e-03,\n",
      "        1.4478e-07, 1.8767e-03, 1.0830e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.5447e-01, 1.4770e-03, 8.0606e-05, 1.9877e-05, 3.1835e-03, 4.6084e-03,\n",
      "        1.7733e-04, 4.4061e-03, 9.3007e-04, 2.3458e-03, 1.5751e-05, 8.7784e-04,\n",
      "        2.9082e-03, 1.8006e-03, 1.7928e-03, 7.3854e-02, 3.0981e-05, 1.2256e-06,\n",
      "        1.4463e-02, 1.0509e-03, 1.1724e-04, 1.5407e-02, 1.0378e-04, 1.5049e-02,\n",
      "        8.1224e-04, 1.2332e-05, 6.4031e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.4177e-07, 7.5606e-02, 1.4511e-01, 6.1383e-02, 4.8222e-02, 3.6165e-02,\n",
      "        2.1638e-02, 2.0123e-02, 3.7169e-02, 2.8234e-02, 3.4908e-03, 3.2202e-03,\n",
      "        4.4696e-02, 5.9285e-02, 7.9734e-03, 2.8399e-02, 7.7385e-02, 9.7461e-04,\n",
      "        3.3311e-02, 1.0992e-01, 1.0443e-01, 9.1298e-03, 3.4590e-03, 3.6625e-02,\n",
      "        6.3170e-05, 3.9637e-03, 1.0556e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3277e-05, 4.8257e-02, 7.6206e-06, 6.0495e-07, 2.7767e-07, 3.4981e-02,\n",
      "        6.1716e-05, 3.0870e-05, 7.8180e-01, 7.2033e-03, 1.8498e-06, 8.8148e-05,\n",
      "        1.2232e-03, 8.8459e-05, 4.6293e-06, 1.8008e-02, 2.0145e-06, 3.1232e-06,\n",
      "        9.3729e-02, 1.0006e-04, 7.8724e-06, 6.6930e-03, 2.5391e-06, 7.0932e-03,\n",
      "        6.6742e-07, 5.7628e-04, 5.1184e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.5638e-05, 6.2369e-02, 2.3605e-07, 4.5007e-09, 9.8392e-08, 8.1152e-01,\n",
      "        5.0642e-07, 6.3021e-07, 3.5138e-06, 9.7010e-02, 8.2978e-07, 2.6983e-07,\n",
      "        2.8652e-06, 3.3555e-05, 2.4295e-05, 2.5672e-02, 3.8843e-07, 6.2392e-08,\n",
      "        1.4137e-03, 1.8690e-05, 4.7420e-06, 1.5706e-03, 1.7549e-08, 5.1323e-05,\n",
      "        6.2696e-07, 2.6857e-04, 6.2617e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.0074e-04, 2.8391e-07, 7.2342e-06, 7.9509e-06, 4.4541e-05, 6.6171e-06,\n",
      "        2.3014e-06, 6.4405e-05, 9.2978e-06, 2.1728e-04, 7.6149e-06, 7.1457e-04,\n",
      "        4.4749e-05, 3.6788e-04, 9.3340e-02, 1.1574e-06, 8.0245e-05, 1.1576e-08,\n",
      "        8.6031e-04, 1.4417e-03, 9.0221e-01, 2.9329e-05, 1.9907e-05, 2.1674e-04,\n",
      "        6.5652e-06, 4.4604e-05, 5.7050e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9418e-01, 1.6283e-06, 1.2822e-07, 2.8331e-06, 3.2552e-06, 5.6576e-04,\n",
      "        6.7958e-06, 1.2672e-06, 4.1117e-03, 9.8871e-05, 3.5954e-07, 9.5401e-06,\n",
      "        1.3726e-05, 2.6542e-06, 5.7893e-05, 9.1040e-06, 2.3689e-06, 3.4785e-07,\n",
      "        2.2602e-05, 3.7452e-04, 4.5885e-04, 3.8617e-05, 2.9242e-07, 3.2166e-05,\n",
      "        1.3628e-08, 1.2695e-06, 1.4429e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([8.9016e-08, 1.2572e-01, 1.1888e-02, 6.3504e-02, 2.7282e-02, 5.1349e-02,\n",
      "        1.3207e-02, 8.1932e-03, 6.2168e-02, 2.0494e-01, 7.9799e-03, 4.0672e-03,\n",
      "        2.1666e-02, 3.6610e-02, 2.0167e-02, 2.2283e-02, 2.5547e-02, 5.8892e-04,\n",
      "        1.5496e-02, 2.3274e-02, 1.7067e-01, 4.4878e-03, 5.5938e-03, 6.5690e-02,\n",
      "        3.8027e-06, 7.5843e-03, 4.5199e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.7480e-01, 1.6291e-05, 8.6039e-03, 6.6508e-02, 8.5283e-03, 3.9992e-05,\n",
      "        5.3823e-03, 1.6828e-02, 1.6442e-04, 3.9821e-04, 5.2604e-05, 3.7939e-04,\n",
      "        2.4197e-01, 1.2868e-02, 1.7967e-01, 2.2272e-06, 1.6790e-02, 5.2078e-05,\n",
      "        6.1109e-02, 1.2750e-01, 6.4645e-02, 1.3132e-03, 3.3046e-03, 8.4192e-03,\n",
      "        2.8251e-04, 3.5159e-04, 2.5297e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.7559e-03, 9.0856e-01, 3.9216e-05, 3.3974e-04, 1.4273e-05, 1.9480e-02,\n",
      "        3.0493e-05, 8.4476e-04, 9.4591e-03, 3.3240e-03, 1.6040e-05, 3.5221e-02,\n",
      "        7.9539e-05, 5.0816e-03, 6.2482e-03, 4.7105e-04, 1.4800e-03, 3.6211e-04,\n",
      "        2.9482e-04, 3.0563e-03, 1.1148e-03, 1.3979e-04, 1.8283e-05, 4.5371e-04,\n",
      "        5.9516e-05, 3.7233e-05, 1.5092e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.5308e-01, 2.2178e-01, 2.1170e-04, 4.5645e-04, 1.3057e-03, 1.5100e-04,\n",
      "        2.1231e-03, 1.0420e-02, 3.8866e-04, 3.0838e-03, 1.4491e-05, 1.5379e-04,\n",
      "        2.8373e-03, 8.5551e-03, 3.0264e-01, 6.6983e-03, 6.3923e-04, 1.0299e-03,\n",
      "        6.9151e-02, 8.2523e-03, 4.9687e-04, 1.0122e-04, 1.4597e-03, 2.6087e-03,\n",
      "        1.5683e-03, 5.0790e-04, 2.8544e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.2881e-08, 2.0210e-01, 3.2361e-02, 3.1022e-02, 1.0823e-02, 1.6235e-02,\n",
      "        1.0099e-02, 1.8159e-02, 3.9170e-02, 1.2719e-01, 2.6314e-03, 5.3046e-03,\n",
      "        9.4956e-03, 2.0156e-02, 1.6184e-02, 1.8845e-01, 2.8045e-02, 1.6972e-03,\n",
      "        8.8850e-03, 6.3611e-02, 7.2313e-02, 2.9621e-02, 1.2012e-03, 6.3418e-02,\n",
      "        1.6487e-05, 1.7667e-03, 4.8563e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.0831e-06, 2.1754e-01, 1.4693e-06, 2.3830e-04, 3.8541e-07, 1.6756e-01,\n",
      "        4.0120e-06, 3.2660e-05, 1.6476e-04, 1.6526e-02, 5.7403e-06, 8.6202e-06,\n",
      "        6.1367e-05, 6.4271e-07, 3.0603e-05, 5.9525e-01, 2.8195e-07, 2.0406e-06,\n",
      "        7.2360e-04, 1.1559e-07, 1.3562e-04, 1.2838e-03, 7.2778e-06, 3.1398e-04,\n",
      "        5.5574e-06, 9.8440e-05, 1.4278e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.2592e-02, 3.6004e-05, 3.8090e-02, 1.5578e-03, 1.0157e-04, 3.4150e-05,\n",
      "        1.4741e-03, 1.4608e-04, 7.6706e-05, 4.1693e-03, 2.0518e-05, 3.6040e-04,\n",
      "        1.2279e-04, 1.9495e-03, 5.9677e-03, 1.2687e-04, 5.8755e-04, 4.1526e-06,\n",
      "        3.4618e-02, 1.3339e-04, 7.1792e-01, 2.3386e-03, 3.0018e-03, 9.4299e-02,\n",
      "        2.3417e-04, 2.0188e-05, 1.4592e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.7197e-01, 7.7999e-04, 1.0437e-05, 4.5823e-07, 4.7836e-05, 2.6286e-03,\n",
      "        6.0125e-05, 2.0707e-07, 1.0293e-01, 6.2749e-03, 1.0245e-05, 2.0567e-05,\n",
      "        1.0384e-03, 1.7604e-04, 1.3322e-04, 3.9892e-03, 1.8821e-05, 3.5229e-05,\n",
      "        2.3282e-04, 8.1139e-03, 4.2547e-04, 1.4441e-04, 1.1622e-05, 7.9706e-04,\n",
      "        7.0881e-07, 6.6232e-05, 8.9449e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.3815e-07, 1.1038e-01, 8.6300e-02, 7.6112e-02, 2.8511e-02, 3.8298e-02,\n",
      "        3.8150e-02, 7.2807e-03, 4.4484e-02, 2.6741e-02, 5.3616e-03, 2.2294e-02,\n",
      "        3.9817e-02, 1.7113e-02, 9.6223e-03, 4.7168e-02, 6.2793e-02, 1.4189e-03,\n",
      "        1.5545e-02, 2.9196e-02, 2.5617e-01, 8.6879e-03, 4.8955e-03, 1.7480e-02,\n",
      "        2.1380e-05, 6.0978e-03, 5.8642e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.8759e-05, 1.7887e-02, 5.3478e-06, 6.9280e-08, 3.5746e-08, 1.2962e-02,\n",
      "        6.3388e-05, 1.9606e-06, 6.8547e-01, 1.4987e-02, 6.7883e-07, 6.9224e-06,\n",
      "        8.8725e-05, 7.6355e-06, 2.0792e-06, 2.3717e-01, 1.9437e-07, 1.8666e-06,\n",
      "        2.6267e-02, 8.6034e-06, 2.0383e-06, 2.0050e-03, 4.0371e-07, 1.7812e-03,\n",
      "        8.9809e-08, 1.2657e-03, 6.9383e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.7176e-01, 7.8581e-04, 4.4223e-05, 1.5682e-05, 6.7232e-03, 2.2126e-03,\n",
      "        1.8284e-04, 5.2756e-03, 8.8733e-04, 1.6518e-03, 1.5623e-05, 2.2022e-03,\n",
      "        2.1634e-03, 7.1697e-04, 2.3400e-03, 7.3364e-02, 3.2139e-05, 1.9342e-06,\n",
      "        4.1865e-03, 5.4415e-04, 1.3167e-04, 8.0162e-03, 2.6220e-04, 1.5613e-02,\n",
      "        8.4558e-04, 2.0989e-05, 4.1100e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.9958e-07, 6.8188e-02, 1.3741e-01, 5.4146e-02, 6.2223e-02, 2.9924e-02,\n",
      "        2.5304e-02, 3.0286e-02, 4.2381e-02, 2.6069e-02, 3.6670e-03, 4.2190e-03,\n",
      "        3.8437e-02, 5.9902e-02, 8.2870e-03, 2.3386e-02, 7.6125e-02, 9.6370e-04,\n",
      "        2.6799e-02, 8.8878e-02, 1.3405e-01, 7.5278e-03, 4.0656e-03, 4.3990e-02,\n",
      "        5.0760e-05, 3.7040e-03, 1.2109e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.2741e-03, 2.2197e-01, 1.7221e-04, 3.7787e-02, 2.7813e-06, 9.4332e-02,\n",
      "        6.1556e-04, 2.3585e-04, 4.4483e-02, 3.5062e-02, 3.6986e-05, 3.1801e-02,\n",
      "        3.1824e-02, 1.6923e-02, 1.0977e-03, 6.1551e-02, 2.0288e-01, 2.3783e-03,\n",
      "        1.4443e-04, 6.8561e-05, 9.7927e-02, 8.7152e-02, 5.9661e-05, 4.7403e-03,\n",
      "        3.6832e-05, 2.1434e-02, 1.5910e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "sted the first rule of reason a still hi <------ | ------> gh strong man have to that awe not to su\n",
      "Epoch 19   Time 62.905    Train Loss: 1.201\n",
      "Softmaxed: tensor([9.0321e-01, 1.3487e-02, 7.1414e-06, 1.2250e-04, 3.8575e-05, 6.3383e-04,\n",
      "        7.1608e-05, 6.8123e-05, 3.5325e-04, 1.4727e-04, 7.4165e-06, 6.3599e-06,\n",
      "        5.3485e-02, 8.5214e-04, 2.5534e-03, 2.6378e-05, 3.3454e-05, 2.2055e-06,\n",
      "        2.2249e-02, 1.0985e-03, 1.1533e-03, 3.7268e-05, 1.5331e-04, 7.8593e-05,\n",
      "        6.7535e-05, 4.0311e-05, 1.7742e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1183e-07, 2.5524e-01, 4.2044e-03, 1.0102e-01, 1.8058e-02, 5.2665e-02,\n",
      "        1.8035e-02, 4.7112e-02, 8.0983e-02, 6.8487e-02, 1.3623e-03, 1.8604e-02,\n",
      "        3.8189e-02, 3.7911e-02, 4.7991e-02, 4.7138e-02, 1.4617e-02, 1.9239e-03,\n",
      "        1.2344e-02, 3.5396e-02, 1.0623e-02, 8.2689e-03, 3.9996e-03, 7.4919e-02,\n",
      "        3.1685e-05, 8.6699e-04, 1.3614e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([2.6295e-02, 1.8090e-01, 7.8774e-05, 8.0259e-03, 5.1592e-07, 1.7331e-01,\n",
      "        2.4002e-04, 4.6668e-04, 1.0449e-01, 3.3735e-02, 1.9109e-05, 1.0211e-02,\n",
      "        5.0180e-03, 7.3958e-03, 3.7948e-04, 1.8803e-01, 7.3950e-02, 9.8938e-04,\n",
      "        2.6072e-04, 9.6262e-05, 6.7100e-02, 7.3850e-02, 3.2384e-05, 3.2545e-03,\n",
      "        1.9205e-05, 4.1847e-02, 5.9014e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.7095e-03, 5.4907e-03, 1.5664e-01, 1.8770e-01, 1.0948e-02, 3.7451e-03,\n",
      "        3.3822e-02, 9.8654e-03, 2.3669e-04, 3.1680e-02, 4.0063e-04, 6.3444e-04,\n",
      "        4.6150e-03, 6.7153e-02, 6.9753e-02, 1.4681e-03, 1.8485e-01, 5.6997e-05,\n",
      "        1.9155e-01, 2.8400e-02, 3.2128e-03, 4.0199e-04, 2.6429e-03, 7.9403e-04,\n",
      "        1.0674e-03, 1.3348e-05, 1.4957e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([6.1337e-04, 9.2416e-03, 9.5733e-04, 5.9728e-03, 5.2564e-06, 4.9022e-01,\n",
      "        1.3047e-03, 6.6238e-05, 3.1049e-02, 1.1890e-02, 1.0270e-03, 4.3563e-04,\n",
      "        1.9140e-02, 7.8804e-04, 1.5751e-05, 7.6494e-03, 3.8460e-01, 1.4981e-04,\n",
      "        2.9684e-02, 2.2002e-03, 1.2535e-03, 5.0899e-04, 6.3205e-04, 3.7137e-04,\n",
      "        2.0094e-04, 1.1084e-06, 1.7228e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.8759e-03, 3.5745e-01, 5.5765e-03, 4.2561e-05, 1.6558e-05, 1.3190e-01,\n",
      "        2.5273e-03, 8.5227e-06, 4.4967e-05, 4.1148e-01, 1.0335e-04, 1.8395e-06,\n",
      "        1.3102e-03, 3.8529e-03, 8.3905e-04, 5.1746e-02, 7.5573e-03, 3.6539e-06,\n",
      "        4.7626e-03, 8.5922e-03, 1.8011e-03, 1.0576e-03, 3.9157e-05, 7.3906e-04,\n",
      "        4.1936e-05, 4.6238e-03, 4.7988e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2319e-03, 9.5946e-04, 2.6559e-02, 2.8185e-02, 7.7111e-03, 1.2829e-03,\n",
      "        5.1782e-03, 7.9573e-04, 1.8647e-04, 4.9701e-02, 4.2662e-04, 5.3364e-04,\n",
      "        1.1953e-02, 1.2551e-02, 1.9019e-02, 5.9985e-03, 4.6354e-01, 7.6742e-05,\n",
      "        2.4697e-01, 7.9520e-02, 6.3095e-03, 2.1434e-03, 7.7716e-03, 9.6890e-03,\n",
      "        1.0072e-02, 2.4718e-04, 1.3945e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.5514e-01, 1.6663e-03, 7.7935e-04, 5.4938e-03, 7.6240e-05, 1.4410e-01,\n",
      "        2.6969e-04, 1.2632e-05, 1.0112e-02, 1.9661e-01, 1.1222e-05, 1.0268e-04,\n",
      "        1.3056e-03, 1.4508e-02, 1.7215e-04, 1.4453e-01, 2.9879e-02, 5.7807e-05,\n",
      "        1.9293e-03, 9.2063e-02, 8.9573e-02, 7.6520e-04, 2.4756e-05, 3.6719e-03,\n",
      "        5.3062e-05, 5.8772e-03, 1.2110e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.2259e-08, 4.6507e-02, 1.2084e-02, 2.5327e-02, 1.2281e-02, 9.4714e-03,\n",
      "        1.7380e-02, 3.4542e-03, 7.0794e-02, 1.6476e-01, 8.1464e-04, 5.1191e-04,\n",
      "        1.6375e-02, 1.9855e-02, 1.5133e-02, 1.5602e-01, 9.1281e-03, 6.5034e-04,\n",
      "        1.1132e-02, 3.0271e-02, 2.9151e-01, 9.4960e-03, 1.7835e-03, 7.2448e-02,\n",
      "        2.0680e-05, 2.6886e-03, 9.8769e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0873e-05, 3.4726e-02, 2.8946e-06, 5.1888e-07, 2.4917e-09, 4.9643e-02,\n",
      "        2.7686e-06, 8.0912e-07, 7.0945e-01, 1.0497e-01, 2.4103e-07, 3.6094e-06,\n",
      "        5.2551e-05, 7.5844e-05, 1.5021e-05, 9.6400e-02, 1.1619e-07, 1.0446e-06,\n",
      "        4.3744e-03, 5.3870e-06, 8.4418e-05, 1.8608e-05, 4.5654e-08, 8.0267e-05,\n",
      "        3.2488e-07, 8.0155e-05, 2.0823e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8863e-04, 1.2052e-01, 2.2324e-06, 4.1427e-07, 1.1797e-08, 1.7188e-01,\n",
      "        1.5441e-07, 4.7848e-08, 1.4396e-05, 3.3729e-01, 8.4052e-08, 1.8129e-08,\n",
      "        4.9608e-04, 2.3781e-05, 8.3258e-05, 3.3263e-01, 6.5279e-07, 9.1550e-08,\n",
      "        6.4821e-05, 4.0794e-05, 8.6040e-05, 7.0751e-04, 3.1848e-08, 2.0694e-05,\n",
      "        1.8587e-07, 3.5744e-02, 3.4672e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8518e-02, 6.3666e-03, 1.2221e-05, 5.2236e-03, 4.3024e-04, 2.6303e-03,\n",
      "        1.0827e-04, 3.0183e-04, 1.5210e-02, 2.4748e-03, 1.0042e-05, 3.5102e-05,\n",
      "        1.3658e-02, 2.0197e-03, 4.9044e-01, 3.4466e-05, 4.5068e-04, 1.6335e-05,\n",
      "        2.7296e-01, 1.5518e-03, 1.6666e-01, 2.6021e-05, 4.0388e-04, 3.5428e-04,\n",
      "        4.4740e-05, 2.9106e-05, 3.2658e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.6425e-01, 8.6946e-04, 4.6116e-07, 5.4494e-03, 1.7548e-03, 1.2789e-02,\n",
      "        3.1342e-05, 1.2883e-04, 5.2696e-04, 1.3386e-03, 4.4577e-06, 3.9780e-04,\n",
      "        2.7504e-04, 7.8082e-06, 8.2618e-06, 1.2268e-03, 2.3750e-05, 3.8774e-05,\n",
      "        2.4607e-06, 2.6361e-03, 7.8882e-03, 6.4102e-06, 1.0166e-05, 1.1207e-04,\n",
      "        1.5150e-06, 2.2026e-04, 5.4864e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.3758e-09, 1.6081e-01, 1.1747e-02, 1.4935e-02, 5.1165e-03, 2.7561e-02,\n",
      "        8.7771e-03, 7.0116e-03, 7.3735e-02, 1.1165e-01, 1.2942e-03, 2.4995e-03,\n",
      "        6.5873e-04, 1.1054e-02, 2.9350e-03, 7.7322e-02, 1.3818e-02, 8.2120e-04,\n",
      "        5.5963e-03, 2.6206e-02, 3.5733e-01, 5.6175e-03, 3.1924e-03, 6.1338e-02,\n",
      "        2.5341e-06, 8.8778e-03, 8.8718e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.3887e-06, 1.1009e-03, 9.3855e-07, 3.6495e-08, 1.5168e-08, 9.2214e-04,\n",
      "        1.9119e-05, 8.7490e-07, 9.3597e-01, 1.6385e-03, 1.4656e-07, 2.1930e-06,\n",
      "        3.1425e-05, 3.4619e-06, 1.1345e-06, 5.6028e-02, 2.0463e-07, 9.9550e-07,\n",
      "        2.3378e-03, 1.0883e-05, 8.1291e-07, 6.2871e-04, 7.6146e-08, 1.0881e-03,\n",
      "        2.4880e-08, 2.1054e-04, 2.2484e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.0686e-04, 1.0134e-01, 8.6311e-07, 7.9702e-10, 2.0250e-06, 7.5923e-01,\n",
      "        4.6054e-07, 1.3485e-07, 6.1316e-06, 4.6946e-02, 6.3663e-07, 2.2066e-07,\n",
      "        1.2155e-05, 1.3052e-05, 6.6579e-05, 6.1179e-02, 4.2263e-07, 9.8321e-08,\n",
      "        1.7799e-02, 1.2951e-04, 4.7988e-06, 1.2613e-02, 2.8512e-08, 8.1443e-05,\n",
      "        1.2775e-06, 4.6111e-04, 6.0783e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.5144e-03, 1.2663e-05, 2.0493e-05, 2.5810e-06, 1.3806e-04, 3.0340e-04,\n",
      "        7.2960e-06, 9.7731e-05, 9.2239e-05, 3.2099e-04, 2.8903e-06, 1.2970e-03,\n",
      "        4.3057e-04, 1.9890e-04, 8.2721e-05, 6.5354e-04, 4.4810e-05, 6.1941e-07,\n",
      "        2.0974e-02, 3.8924e-01, 6.8101e-05, 5.7218e-01, 4.4446e-04, 9.7834e-03,\n",
      "        8.8944e-04, 1.8007e-04, 2.1919e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.4666e-03, 1.0053e-04, 1.6224e-05, 6.4525e-04, 1.5151e-05, 9.5623e-01,\n",
      "        1.1925e-05, 9.3839e-05, 6.4325e-04, 1.1905e-02, 2.4143e-06, 2.7185e-03,\n",
      "        1.5239e-04, 5.3992e-04, 1.3361e-05, 6.1374e-03, 9.6428e-04, 1.8873e-05,\n",
      "        9.4306e-05, 4.0904e-03, 5.0907e-03, 2.1200e-04, 2.4009e-05, 3.4173e-04,\n",
      "        2.4478e-06, 4.6101e-04, 1.2870e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.9747e-01, 5.9179e-07, 1.0031e-05, 9.3863e-06, 1.3967e-04, 6.6152e-06,\n",
      "        1.3171e-04, 7.2426e-06, 4.2280e-06, 7.6527e-06, 1.0406e-07, 9.9286e-08,\n",
      "        9.0608e-04, 1.5952e-06, 3.9984e-05, 1.2472e-06, 8.4356e-07, 5.5961e-06,\n",
      "        1.1695e-05, 1.1767e-03, 4.8117e-06, 3.7894e-08, 4.3659e-05, 2.0827e-05,\n",
      "        1.5247e-06, 6.8702e-07, 1.6876e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.3562e-07, 6.2571e-02, 2.4235e-02, 2.6256e-02, 2.6216e-02, 4.2373e-02,\n",
      "        5.6147e-02, 1.3308e-02, 2.1425e-02, 1.5773e-01, 2.5813e-03, 3.8627e-03,\n",
      "        2.2284e-02, 1.8812e-02, 1.1235e-02, 8.5310e-02, 1.9365e-02, 2.1406e-03,\n",
      "        2.8267e-02, 1.2338e-01, 1.4571e-01, 1.3274e-02, 2.0257e-02, 7.0761e-02,\n",
      "        6.7821e-05, 2.0979e-03, 3.2772e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2357e-05, 6.6370e-02, 5.0327e-06, 7.1316e-07, 5.3945e-09, 8.7730e-02,\n",
      "        2.0793e-06, 1.4659e-06, 5.6912e-01, 1.3911e-01, 5.3763e-07, 6.7229e-06,\n",
      "        8.2025e-05, 1.1317e-04, 2.3372e-05, 1.3065e-01, 1.4144e-07, 9.2416e-07,\n",
      "        6.3421e-03, 1.7158e-05, 1.2981e-04, 3.8364e-05, 6.0976e-08, 1.1215e-04,\n",
      "        7.7460e-07, 1.0577e-04, 4.8809e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3246e-04, 1.0675e-01, 2.4807e-06, 3.3959e-07, 1.4862e-08, 1.7307e-01,\n",
      "        1.7813e-07, 6.3137e-08, 1.4989e-05, 3.4978e-01, 1.1264e-07, 3.2251e-08,\n",
      "        8.0319e-04, 2.3572e-05, 1.2673e-04, 3.3465e-01, 5.3086e-07, 7.9053e-08,\n",
      "        1.6779e-04, 8.0946e-05, 9.9947e-05, 8.8615e-04, 2.3021e-08, 2.0435e-05,\n",
      "        2.3889e-07, 3.3087e-02, 5.4272e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.1070e-01, 1.5516e-03, 2.0939e-05, 8.7296e-03, 1.3249e-04, 1.5904e-02,\n",
      "        2.8273e-05, 5.4540e-05, 6.9040e-04, 3.6784e-04, 4.1505e-06, 2.7726e-04,\n",
      "        2.0108e-01, 7.5363e-02, 8.9918e-03, 1.3479e-04, 6.6296e-03, 1.2730e-05,\n",
      "        2.8199e-03, 5.5174e-02, 1.1672e-03, 6.6358e-03, 1.1305e-03, 1.8812e-03,\n",
      "        3.7916e-04, 1.5794e-05, 1.2432e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.6412e-07, 1.7879e-01, 5.4473e-03, 4.8848e-02, 3.6480e-02, 2.2843e-02,\n",
      "        1.9029e-02, 1.7495e-02, 1.8913e-01, 7.6169e-02, 8.8849e-04, 9.6355e-02,\n",
      "        1.7556e-02, 5.1684e-02, 1.5187e-02, 4.0966e-02, 8.8354e-03, 6.1899e-04,\n",
      "        2.6786e-02, 3.6274e-02, 9.6768e-03, 1.1413e-02, 2.4111e-03, 8.6737e-02,\n",
      "        3.2220e-05, 3.1539e-04, 2.3721e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0532e-03, 8.4829e-02, 8.7473e-04, 8.6207e-03, 2.5324e-03, 6.9407e-04,\n",
      "        1.4096e-02, 3.1505e-03, 5.4191e-04, 5.9517e-04, 2.7366e-04, 1.9284e-05,\n",
      "        3.9062e-02, 7.7149e-02, 1.8878e-01, 3.3030e-04, 1.7953e-02, 1.6985e-02,\n",
      "        1.1237e-02, 7.2664e-02, 1.9291e-02, 1.6713e-02, 1.2016e-01, 3.3424e-03,\n",
      "        2.9551e-01, 3.4958e-03, 5.0487e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8320e-03, 8.0367e-02, 8.0934e-06, 1.7841e-01, 3.2566e-06, 4.2952e-02,\n",
      "        1.1699e-03, 8.3256e-04, 5.1755e-03, 1.2018e-01, 2.1735e-04, 1.4116e-03,\n",
      "        5.9836e-03, 8.7666e-03, 7.2626e-06, 7.7088e-03, 3.6597e-01, 7.0297e-04,\n",
      "        1.7323e-03, 3.5579e-03, 1.5318e-01, 1.8080e-02, 1.5786e-04, 1.2916e-03,\n",
      "        2.4249e-04, 3.3512e-05, 2.6442e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.5809e-05, 1.5850e-03, 1.7728e-04, 1.7123e-02, 3.4488e-02, 6.0487e-03,\n",
      "        4.1181e-03, 2.7903e-03, 7.9058e-06, 7.6126e-05, 8.2536e-06, 4.5279e-05,\n",
      "        1.8937e-03, 1.7662e-02, 2.4644e-03, 5.4086e-03, 5.2681e-04, 2.5244e-04,\n",
      "        5.3605e-03, 8.9738e-01, 1.2638e-03, 9.7620e-06, 9.8118e-04, 1.2668e-05,\n",
      "        1.5474e-04, 2.9169e-06, 1.2528e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0152e-02, 6.2467e-04, 2.3264e-04, 1.8617e-03, 1.0999e-05, 3.0694e-03,\n",
      "        5.0568e-03, 1.5456e-04, 1.5375e-03, 1.5540e-03, 1.1873e-06, 1.0886e-04,\n",
      "        1.3851e-05, 7.8160e-03, 1.8438e-03, 2.4350e-04, 2.4843e-03, 1.4092e-05,\n",
      "        1.8414e-05, 2.4972e-04, 9.5170e-01, 1.1088e-03, 9.4939e-07, 1.2458e-04,\n",
      "        4.6875e-07, 7.2588e-06, 7.8632e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.9507e-02, 2.3030e-02, 2.6996e-06, 5.3014e-06, 3.5768e-06, 6.5232e-01,\n",
      "        1.5885e-04, 1.5804e-06, 2.0005e-04, 3.8837e-02, 2.3651e-06, 7.9689e-07,\n",
      "        5.1283e-03, 2.2943e-04, 2.9883e-04, 5.6900e-02, 1.9077e-04, 8.8625e-06,\n",
      "        1.1639e-03, 1.9094e-01, 1.0447e-06, 4.8254e-04, 1.5785e-06, 1.8576e-04,\n",
      "        8.0156e-07, 3.9995e-04, 1.3927e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.9461e-04, 5.1024e-04, 5.1361e-04, 5.4879e-04, 1.2682e-01, 2.8523e-05,\n",
      "        3.0996e-03, 3.5991e-05, 2.0897e-06, 3.5662e-05, 1.6739e-06, 1.9826e-06,\n",
      "        1.1971e-04, 5.3685e-03, 8.3698e-01, 3.0680e-05, 3.4192e-03, 4.6419e-05,\n",
      "        1.4405e-02, 7.3558e-03, 1.7379e-04, 1.0917e-06, 2.2387e-04, 9.0597e-06,\n",
      "        4.8074e-05, 2.1277e-05, 5.6440e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.3386e-03, 1.4516e-02, 1.9478e-05, 7.8987e-01, 1.8185e-02, 9.2800e-03,\n",
      "        2.9964e-04, 3.3654e-03, 5.3325e-05, 5.3523e-03, 3.4837e-05, 1.4207e-03,\n",
      "        5.8177e-04, 1.1432e-04, 3.4903e-03, 4.8659e-04, 2.7108e-05, 1.0558e-04,\n",
      "        1.7060e-05, 1.0739e-02, 1.3083e-01, 4.4913e-03, 4.3331e-05, 2.1052e-04,\n",
      "        5.4907e-05, 4.6451e-05, 1.8299e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1896e-04, 1.1828e-02, 5.5146e-06, 8.4209e-06, 3.7298e-06, 9.3595e-01,\n",
      "        2.0102e-06, 5.7879e-06, 4.6352e-04, 2.0192e-02, 8.6304e-08, 2.6900e-05,\n",
      "        2.7101e-03, 1.0212e-05, 1.8858e-06, 3.9014e-04, 7.2391e-07, 1.2362e-05,\n",
      "        8.5125e-03, 3.3936e-04, 6.7879e-03, 1.7641e-03, 6.8249e-07, 3.9340e-06,\n",
      "        1.0249e-06, 1.0858e-02, 3.8892e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.8301e-01, 3.9281e-05, 3.7775e-05, 1.2386e-06, 1.8509e-03, 4.7516e-06,\n",
      "        1.9870e-04, 2.5691e-07, 1.3914e-07, 1.0464e-05, 2.1295e-08, 2.8312e-08,\n",
      "        2.5988e-05, 2.8956e-04, 5.1120e-05, 5.0744e-06, 6.1430e-06, 2.2133e-07,\n",
      "        4.7183e-05, 1.4369e-02, 1.4599e-06, 5.6001e-06, 6.3584e-06, 9.2181e-06,\n",
      "        3.1439e-06, 2.7322e-05, 5.0487e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.6665e-08, 1.7485e-01, 2.2211e-02, 1.3940e-02, 7.3453e-03, 1.7237e-02,\n",
      "        2.8981e-02, 2.7603e-03, 2.6767e-02, 1.0781e-01, 1.7048e-03, 5.9186e-04,\n",
      "        4.3961e-03, 1.6561e-02, 7.7614e-03, 3.3007e-01, 7.4983e-03, 9.7307e-04,\n",
      "        1.1544e-02, 1.8597e-02, 1.2093e-01, 9.1218e-03, 4.3842e-03, 6.0656e-02,\n",
      "        8.4258e-06, 3.2445e-03, 5.2401e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.8204e-05, 1.2734e-05, 6.3059e-03, 1.1351e-03, 2.3901e-04, 1.0212e-05,\n",
      "        8.5817e-01, 1.2596e-04, 5.0649e-05, 1.3186e-05, 9.5953e-06, 1.5099e-05,\n",
      "        1.0021e-03, 1.4750e-04, 5.3641e-02, 5.3509e-05, 6.8460e-03, 1.4714e-05,\n",
      "        4.4879e-02, 1.3000e-05, 5.2234e-03, 1.0898e-02, 3.1306e-03, 8.0264e-03,\n",
      "        7.8784e-06, 1.0012e-06, 3.0983e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9355e-01, 7.8266e-06, 6.9958e-06, 3.6726e-05, 1.2611e-05, 1.1550e-04,\n",
      "        3.8328e-03, 1.5285e-06, 1.1900e-06, 2.2567e-06, 4.9352e-06, 3.2346e-06,\n",
      "        9.4708e-05, 2.3206e-04, 4.2241e-07, 2.8875e-06, 7.5747e-05, 1.3372e-06,\n",
      "        2.4591e-05, 2.1819e-06, 1.9206e-03, 2.4787e-06, 3.7340e-05, 2.7435e-05,\n",
      "        1.8714e-07, 1.1642e-06, 6.6967e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.9027e-07, 1.2142e-01, 7.9770e-03, 3.0821e-02, 2.7084e-02, 5.4960e-02,\n",
      "        1.4015e-02, 2.1051e-02, 5.4348e-02, 5.7462e-02, 7.1414e-03, 9.6277e-03,\n",
      "        2.4616e-02, 6.6514e-02, 1.9121e-02, 3.4868e-02, 3.3906e-02, 4.4396e-04,\n",
      "        5.4089e-02, 4.2441e-02, 2.4174e-01, 4.3679e-03, 1.4320e-02, 5.1138e-02,\n",
      "        6.2909e-05, 6.3438e-03, 1.1908e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.4327e-03, 3.2731e-05, 8.2165e-05, 2.0624e-05, 3.8502e-02, 1.5281e-04,\n",
      "        7.5736e-03, 6.9260e-03, 2.2237e-04, 3.0586e-06, 2.7091e-06, 7.9457e-05,\n",
      "        1.0273e-02, 2.8411e-02, 3.4164e-01, 1.1320e-05, 1.5308e-04, 2.2581e-05,\n",
      "        5.7768e-03, 2.9011e-02, 5.2410e-01, 7.8112e-06, 1.7030e-04, 1.7110e-04,\n",
      "        2.0962e-04, 1.8445e-06, 1.7041e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.8680e-01, 7.2786e-05, 1.8580e-05, 2.3255e-04, 1.8719e-05, 4.4782e-04,\n",
      "        3.6003e-03, 8.8824e-06, 2.1291e-04, 2.6567e-04, 1.1914e-05, 1.7994e-05,\n",
      "        4.6632e-04, 5.1972e-04, 3.9612e-06, 1.7778e-06, 5.4570e-05, 1.5557e-05,\n",
      "        1.4881e-04, 5.0598e-01, 6.8927e-04, 2.1022e-04, 8.9024e-06, 1.6249e-04,\n",
      "        4.2626e-07, 2.3525e-05, 1.2719e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.0305e-07, 1.6319e-01, 2.3708e-02, 1.1968e-02, 1.7604e-02, 3.3013e-02,\n",
      "        6.3169e-03, 1.3715e-02, 1.0760e-01, 1.9550e-01, 2.6730e-03, 3.4980e-03,\n",
      "        1.6207e-02, 3.7917e-02, 1.8986e-02, 6.3733e-02, 1.1257e-02, 4.2450e-04,\n",
      "        3.7310e-02, 3.5096e-02, 4.9239e-02, 1.0083e-02, 5.6051e-03, 1.3352e-01,\n",
      "        3.0381e-06, 1.8063e-03, 2.0014e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "hy with an indescribable anguish when we <------ | ------>  suphos when those who existence of it r\n",
      "Epoch 20   Time 62.647    Train Loss: 1.195\n",
      "Softmaxed: tensor([9.4506e-02, 1.3015e-05, 2.6485e-02, 2.3364e-03, 3.8418e-02, 2.6926e-06,\n",
      "        2.3258e-03, 1.2572e-02, 8.9975e-06, 1.3940e-05, 4.0515e-05, 3.2858e-04,\n",
      "        1.1317e-01, 6.9959e-03, 6.3051e-01, 5.1642e-07, 7.6458e-03, 2.6135e-05,\n",
      "        1.4618e-02, 4.2187e-03, 4.0344e-02, 6.8089e-04, 4.2081e-03, 4.0871e-04,\n",
      "        1.0236e-04, 1.9762e-05, 7.5566e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.3407e-01, 3.6358e-04, 9.7243e-04, 3.5141e-03, 1.8708e-02, 8.4028e-04,\n",
      "        1.3968e-03, 1.1004e-04, 2.3378e-04, 7.1499e-03, 7.7230e-04, 3.8338e-04,\n",
      "        9.9881e-04, 1.7631e-03, 5.6873e-03, 2.8793e-02, 2.3833e-05, 7.2523e-05,\n",
      "        8.6624e-05, 3.1041e-02, 1.7444e-02, 6.9908e-05, 1.0901e-03, 2.7965e-02,\n",
      "        4.1717e-03, 1.2224e-02, 5.2189e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.9690e-08, 3.5738e-01, 1.0420e-02, 1.7851e-03, 2.4487e-03, 1.6212e-01,\n",
      "        3.2678e-03, 2.3883e-04, 1.9298e-02, 1.0670e-01, 1.7307e-03, 1.5548e-03,\n",
      "        1.4667e-03, 5.8135e-03, 4.5693e-03, 2.1566e-01, 2.5166e-02, 3.1041e-03,\n",
      "        1.6674e-02, 2.2752e-02, 4.4773e-03, 2.1455e-02, 1.8581e-03, 8.7564e-03,\n",
      "        3.0689e-05, 1.2437e-03, 2.3474e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.5482e-02, 6.4544e-05, 3.5923e-02, 5.7687e-02, 5.0412e-02, 9.5626e-04,\n",
      "        8.2580e-03, 1.2451e-01, 2.2855e-04, 2.2151e-02, 6.3174e-05, 3.9515e-03,\n",
      "        9.5780e-02, 2.8540e-02, 1.0089e-01, 1.2520e-04, 8.4081e-02, 1.3216e-04,\n",
      "        1.4386e-01, 4.1689e-02, 3.3956e-02, 1.1135e-02, 3.8804e-02, 5.8306e-02,\n",
      "        1.0460e-03, 2.1906e-02, 5.8802e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.5360e-05, 1.4914e-03, 1.1323e-03, 2.6412e-03, 2.1644e-03, 3.5697e-03,\n",
      "        9.4709e-04, 1.2257e-03, 2.9447e-05, 2.4181e-02, 2.9004e-04, 5.4477e-03,\n",
      "        2.5223e-01, 3.5245e-02, 1.2247e-04, 3.1438e-02, 1.7761e-03, 9.5277e-05,\n",
      "        2.3377e-02, 2.0383e-02, 2.9171e-01, 6.9222e-04, 3.1951e-03, 2.8918e-01,\n",
      "        7.6324e-04, 6.2061e-03, 3.9894e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.2212e-04, 9.6617e-01, 1.1808e-06, 2.6466e-06, 1.5430e-06, 1.4741e-02,\n",
      "        3.1469e-06, 5.2352e-06, 4.1491e-03, 2.3496e-03, 1.5463e-05, 1.5152e-04,\n",
      "        1.6128e-04, 8.9307e-05, 2.2062e-04, 5.0278e-03, 2.8621e-06, 1.9234e-06,\n",
      "        1.2933e-03, 1.8929e-03, 2.8824e-06, 1.4180e-03, 9.4180e-07, 1.9103e-04,\n",
      "        5.6989e-05, 1.8111e-03, 1.3406e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999996423721313\n",
      "Softmaxed: tensor([9.5686e-07, 3.7976e-07, 3.2543e-05, 4.8698e-05, 8.5227e-05, 5.0640e-07,\n",
      "        1.4037e-05, 2.5447e-04, 8.1061e-06, 2.9051e-04, 1.7829e-06, 1.6693e-04,\n",
      "        1.2942e-05, 6.0627e-05, 5.2830e-04, 1.4385e-06, 8.9357e-05, 1.4851e-06,\n",
      "        2.6141e-03, 1.4529e-03, 4.7246e-05, 8.9296e-05, 6.8200e-05, 5.0908e-06,\n",
      "        2.5198e-05, 9.9401e-01, 8.5013e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.3332e-03, 2.3909e-05, 3.7048e-04, 1.5478e-04, 1.2713e-03, 9.0315e-04,\n",
      "        8.2088e-05, 3.0949e-05, 1.7273e-04, 1.5909e-03, 8.4663e-06, 3.8380e-03,\n",
      "        1.0688e-04, 2.2076e-04, 6.9209e-04, 2.2155e-04, 9.0642e-05, 3.6726e-04,\n",
      "        1.7508e-04, 9.7927e-01, 2.8174e-04, 2.3106e-04, 4.4912e-04, 4.6283e-04,\n",
      "        4.1023e-05, 4.3735e-04, 1.7229e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([9.6700e-01, 8.7054e-05, 1.4483e-05, 1.8598e-03, 4.5031e-07, 3.1596e-04,\n",
      "        5.0944e-05, 2.7293e-05, 7.0237e-04, 2.4077e-03, 1.8778e-07, 8.9208e-04,\n",
      "        4.7822e-05, 2.2961e-03, 2.3524e-03, 2.0324e-03, 4.4530e-05, 6.1318e-05,\n",
      "        3.6235e-05, 6.9888e-05, 1.8918e-02, 1.2700e-04, 1.0363e-05, 1.0164e-04,\n",
      "        1.1235e-06, 5.3909e-04, 4.5714e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([7.0044e-08, 9.8702e-02, 8.8543e-02, 4.5806e-02, 3.1324e-02, 2.1290e-02,\n",
      "        2.6559e-02, 2.8594e-02, 7.1872e-02, 6.7398e-02, 2.9296e-03, 1.6995e-02,\n",
      "        3.9707e-02, 5.9520e-02, 2.0344e-02, 3.2405e-02, 7.4416e-02, 5.7388e-03,\n",
      "        2.3713e-02, 1.0229e-01, 8.0687e-02, 1.1548e-02, 4.2905e-03, 4.0962e-02,\n",
      "        1.2132e-05, 4.3195e-03, 3.7873e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0228e-01, 3.9071e-05, 7.3034e-02, 4.6578e-02, 1.9210e-02, 5.4782e-05,\n",
      "        1.0124e-02, 5.4013e-02, 2.6454e-04, 6.3928e-04, 3.0743e-05, 3.1596e-03,\n",
      "        1.2531e-01, 1.6588e-02, 1.5957e-01, 7.3829e-06, 3.5043e-02, 1.1378e-04,\n",
      "        1.0668e-01, 6.1465e-02, 5.0778e-02, 8.0268e-03, 6.4117e-03, 1.6901e-02,\n",
      "        6.1840e-04, 3.0212e-03, 3.2054e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.6088e-01, 4.2079e-04, 5.5732e-05, 6.6631e-04, 9.0747e-04, 8.6207e-04,\n",
      "        2.4693e-04, 3.5948e-04, 6.9206e-03, 9.4384e-04, 5.2198e-05, 1.4432e-04,\n",
      "        2.4428e-04, 5.0059e-04, 6.4348e-06, 3.0335e-03, 1.4673e-04, 4.5544e-04,\n",
      "        4.1924e-02, 3.7256e-03, 3.6923e-01, 1.3701e-04, 2.1571e-03, 5.8605e-03,\n",
      "        1.6466e-05, 6.5691e-05, 3.8267e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.4454e-08, 1.9468e-01, 2.8115e-02, 1.4740e-02, 5.4440e-02, 3.2829e-02,\n",
      "        1.0013e-02, 5.0642e-03, 6.8807e-02, 1.6111e-02, 2.0086e-03, 2.1715e-03,\n",
      "        1.3909e-01, 1.5393e-02, 2.6268e-03, 3.5079e-02, 7.3664e-02, 2.3765e-03,\n",
      "        7.4068e-03, 3.0372e-02, 2.3168e-01, 3.9276e-03, 2.3792e-03, 2.3896e-02,\n",
      "        1.0396e-05, 3.0737e-03, 4.1440e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.4710e-03, 1.3821e-01, 1.5182e-04, 4.1121e-02, 4.7971e-06, 1.6856e-01,\n",
      "        6.4719e-04, 3.6905e-04, 6.9259e-02, 4.6341e-02, 4.1186e-05, 1.1087e-02,\n",
      "        2.1561e-02, 7.3854e-03, 3.8494e-04, 9.1242e-02, 7.8382e-02, 2.6112e-03,\n",
      "        1.4169e-04, 1.5790e-04, 1.4111e-01, 1.3447e-01, 2.0900e-05, 4.9137e-03,\n",
      "        2.0583e-05, 3.7325e-02, 1.7126e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.9552e-05, 5.0830e-02, 1.6365e-05, 7.8365e-04, 1.9120e-08, 2.5611e-01,\n",
      "        1.8806e-05, 4.7631e-06, 3.0527e-02, 5.8758e-01, 3.7916e-06, 2.4543e-06,\n",
      "        7.4812e-05, 6.6853e-04, 7.3234e-06, 3.0448e-02, 3.1579e-03, 5.6750e-06,\n",
      "        3.3304e-02, 2.8359e-05, 7.6446e-05, 6.0041e-03, 3.0783e-05, 7.6107e-06,\n",
      "        6.9136e-05, 1.7038e-04, 2.3249e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.4237e-05, 5.2396e-03, 9.3837e-04, 3.0058e-02, 8.1641e-03, 1.1077e-02,\n",
      "        2.4164e-03, 2.4875e-03, 8.9982e-05, 1.5552e-03, 1.8968e-05, 3.1968e-04,\n",
      "        2.5641e-02, 4.1308e-04, 2.4346e-02, 1.7022e-03, 1.2500e-02, 2.5406e-05,\n",
      "        8.5391e-01, 2.0784e-03, 1.0183e-02, 3.1455e-04, 1.0717e-03, 1.1228e-05,\n",
      "        6.9315e-04, 1.4101e-06, 4.7325e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([6.4400e-04, 7.1181e-04, 2.6644e-04, 8.9775e-04, 2.6380e-05, 5.0450e-03,\n",
      "        1.9634e-03, 1.8949e-06, 1.6840e-04, 9.8022e-01, 2.5421e-06, 5.7721e-07,\n",
      "        1.0636e-04, 1.4965e-03, 2.7230e-04, 4.9002e-03, 7.7740e-05, 4.7690e-07,\n",
      "        1.6667e-04, 1.1867e-03, 1.4882e-03, 1.3871e-06, 1.0883e-05, 2.3307e-04,\n",
      "        5.8058e-06, 8.0917e-05, 2.3768e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.0331e-04, 2.1199e-05, 3.4083e-04, 1.0605e-03, 8.5152e-05, 8.0805e-05,\n",
      "        1.2176e-03, 1.6500e-05, 3.3818e-06, 1.2112e-04, 3.4874e-07, 7.2417e-06,\n",
      "        8.1763e-04, 3.4695e-06, 5.4889e-03, 5.0180e-03, 5.4201e-06, 9.7791e-07,\n",
      "        3.5714e-05, 7.4267e-04, 9.8431e-01, 1.5706e-05, 1.8968e-05, 1.8426e-05,\n",
      "        1.0119e-06, 2.5171e-07, 6.6541e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.7454e-01, 1.5433e-02, 2.7949e-04, 1.1069e-04, 5.4861e-06, 2.4126e-02,\n",
      "        2.8018e-03, 9.1516e-07, 5.9362e-04, 4.6651e-02, 7.6929e-06, 3.1545e-05,\n",
      "        2.8581e-04, 1.7903e-05, 4.6110e-05, 2.6865e-04, 3.9652e-05, 5.6538e-06,\n",
      "        7.9739e-06, 1.8200e-01, 1.4810e-03, 2.4084e-01, 4.8687e-06, 1.8207e-05,\n",
      "        8.3350e-07, 1.0398e-02, 2.2200e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.5788e-07, 1.3015e-01, 2.4020e-02, 1.2490e-02, 3.5028e-02, 4.3034e-02,\n",
      "        2.3359e-02, 3.3694e-03, 3.1200e-02, 1.7146e-01, 2.8883e-03, 2.5057e-03,\n",
      "        9.8078e-03, 4.3726e-02, 9.6118e-03, 1.0142e-01, 7.7784e-03, 2.0486e-03,\n",
      "        1.9565e-02, 6.3175e-02, 8.5767e-02, 1.8469e-02, 5.4380e-03, 1.4958e-01,\n",
      "        4.2940e-06, 4.0688e-03, 3.4943e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8773e-05, 9.8365e-03, 3.3528e-06, 7.9099e-08, 4.7069e-09, 4.6414e-03,\n",
      "        4.0404e-05, 4.8305e-07, 6.1221e-01, 4.7326e-03, 3.6980e-07, 2.0839e-06,\n",
      "        6.6906e-05, 5.9858e-06, 1.4306e-06, 3.5315e-01, 3.2202e-07, 1.0089e-06,\n",
      "        1.2398e-02, 5.6965e-06, 4.7615e-06, 2.1840e-03, 2.8737e-07, 5.2739e-04,\n",
      "        2.4574e-08, 1.4905e-04, 2.2863e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([9.8394e-01, 1.9512e-04, 3.1945e-05, 2.2724e-05, 2.7692e-04, 6.0451e-04,\n",
      "        7.7179e-05, 4.3872e-04, 6.5242e-05, 2.6273e-04, 2.6591e-06, 5.2539e-05,\n",
      "        1.3925e-03, 3.8841e-04, 7.8747e-04, 5.1493e-03, 3.8836e-05, 5.2259e-07,\n",
      "        4.6966e-04, 7.0795e-04, 2.5031e-05, 2.6485e-03, 6.4311e-05, 2.2785e-03,\n",
      "        7.1538e-05, 1.2763e-06, 1.3434e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.8098e-07, 4.4626e-02, 6.7733e-02, 2.7791e-02, 4.5794e-02, 1.5458e-02,\n",
      "        4.5354e-02, 1.0627e-02, 3.0847e-02, 3.2126e-02, 1.5534e-03, 3.3308e-03,\n",
      "        2.9543e-02, 2.9891e-02, 9.0449e-03, 2.0586e-02, 5.4963e-02, 1.1413e-03,\n",
      "        1.4462e-02, 7.3365e-02, 3.5302e-01, 1.1003e-02, 4.2339e-03, 7.1126e-02,\n",
      "        1.5419e-05, 2.3546e-03, 9.3840e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.8863e-05, 1.3977e-02, 2.5800e-06, 1.0109e-07, 2.4787e-08, 7.5191e-03,\n",
      "        1.8633e-05, 5.5820e-06, 8.5070e-01, 3.5779e-03, 6.0669e-07, 3.2903e-05,\n",
      "        1.7897e-04, 2.3604e-05, 1.0261e-06, 3.6368e-02, 3.6630e-07, 1.5475e-06,\n",
      "        7.8006e-02, 1.9406e-05, 2.4870e-06, 6.1957e-03, 6.2684e-07, 3.2439e-03,\n",
      "        1.1012e-07, 1.0321e-04, 1.2732e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([1.4010e-05, 2.8277e-02, 6.7915e-08, 8.2849e-10, 2.6808e-08, 9.0404e-01,\n",
      "        1.2856e-07, 1.3423e-07, 4.0031e-06, 5.3696e-02, 2.7041e-07, 1.2786e-07,\n",
      "        4.3129e-06, 7.9540e-06, 1.1861e-05, 1.0989e-02, 9.2149e-08, 2.2350e-08,\n",
      "        1.9017e-03, 8.9585e-06, 2.3192e-06, 8.7363e-04, 2.3334e-09, 2.4773e-05,\n",
      "        2.2935e-07, 1.4121e-04, 3.4520e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.3840e-01, 6.6001e-05, 3.2337e-06, 3.3746e-06, 3.6168e-06, 1.9989e-03,\n",
      "        5.0369e-05, 2.5218e-04, 3.5283e-03, 1.0673e-01, 1.3730e-05, 2.8358e-05,\n",
      "        5.4559e-04, 6.9683e-02, 9.8322e-03, 3.1013e-04, 3.0883e-04, 2.0749e-06,\n",
      "        2.6590e-02, 2.9275e-02, 5.4777e-04, 3.9966e-06, 3.2906e-05, 1.4720e-03,\n",
      "        3.9716e-05, 1.0222e-02, 5.6340e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.0696e-07, 3.6762e-02, 3.4275e-02, 7.2343e-02, 4.4264e-02, 5.4871e-02,\n",
      "        4.3751e-02, 3.0683e-02, 5.6978e-02, 5.7510e-02, 5.0802e-03, 2.8333e-03,\n",
      "        3.9427e-02, 6.3224e-02, 1.9366e-02, 6.7356e-02, 7.3139e-02, 6.6636e-03,\n",
      "        3.5809e-02, 1.1511e-01, 2.4912e-02, 3.1110e-02, 1.7802e-02, 6.4579e-02,\n",
      "        2.5957e-05, 2.0856e-03, 3.9349e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.4057e-03, 1.3118e-04, 7.2663e-02, 1.0725e-01, 6.7423e-02, 9.9546e-05,\n",
      "        6.6522e-03, 1.0683e-01, 4.0037e-04, 4.7924e-03, 3.7686e-05, 1.4595e-03,\n",
      "        4.3287e-02, 4.6530e-02, 9.9965e-02, 6.1967e-06, 9.4753e-02, 2.9263e-04,\n",
      "        1.9386e-01, 5.6265e-02, 2.8071e-02, 2.6347e-02, 1.3295e-02, 1.8341e-02,\n",
      "        8.5451e-04, 7.9145e-03, 6.5315e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.7896e-02, 7.2805e-03, 5.4058e-03, 2.5686e-01, 1.6353e-04, 2.6712e-03,\n",
      "        1.0286e-03, 1.2839e-03, 3.0417e-03, 1.4627e-02, 1.7800e-05, 5.1103e-02,\n",
      "        1.2431e-04, 1.1810e-02, 9.0542e-05, 5.7976e-04, 2.0177e-01, 8.6832e-04,\n",
      "        9.6329e-04, 1.8348e-01, 2.0296e-01, 1.7379e-03, 5.5786e-04, 3.3223e-03,\n",
      "        4.5592e-05, 1.9136e-04, 1.1323e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.5091e-05, 1.8758e-02, 3.2142e-06, 2.1213e-05, 1.3555e-06, 7.1661e-01,\n",
      "        1.8462e-06, 2.3157e-05, 1.6882e-02, 1.1109e-01, 4.4273e-06, 2.8751e-03,\n",
      "        3.7577e-04, 7.3022e-07, 1.7407e-06, 3.6658e-02, 1.1892e-05, 1.5949e-04,\n",
      "        3.3427e-02, 2.1364e-04, 4.1405e-05, 6.1984e-02, 2.5477e-05, 1.5729e-05,\n",
      "        9.4285e-06, 7.9537e-04, 2.1652e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.4069e-03, 4.4978e-02, 1.7625e-03, 1.3967e-03, 1.4264e-03, 8.8527e-04,\n",
      "        1.1999e-02, 2.4552e-04, 3.4242e-06, 2.5920e-03, 3.1542e-05, 6.3474e-05,\n",
      "        1.3159e-04, 1.9708e-03, 8.1462e-01, 2.1774e-04, 4.3866e-02, 9.3186e-04,\n",
      "        3.5000e-02, 1.5345e-02, 1.5971e-02, 6.6900e-04, 8.7486e-04, 5.5794e-04,\n",
      "        1.0299e-03, 1.2517e-05, 7.1947e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.5251e-03, 1.3824e-04, 6.2322e-05, 1.8704e-03, 4.3854e-06, 2.8008e-04,\n",
      "        6.6349e-04, 9.9133e-07, 7.5847e-04, 6.4064e-03, 4.9723e-07, 4.0182e-05,\n",
      "        7.7578e-06, 7.3470e-03, 1.2369e-04, 9.7168e-05, 1.4884e-02, 4.3632e-05,\n",
      "        1.6608e-05, 9.4142e-01, 1.5272e-02, 2.4024e-04, 2.1321e-06, 7.7544e-04,\n",
      "        5.0209e-07, 1.3420e-05, 2.4300e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.2576e-01, 1.0397e-01, 4.2345e-05, 6.6157e-05, 1.9697e-06, 1.0879e-01,\n",
      "        4.3009e-04, 2.0424e-06, 5.1060e-05, 3.3255e-01, 2.8097e-07, 3.0350e-06,\n",
      "        6.9995e-03, 2.2997e-03, 6.4447e-04, 1.3537e-02, 2.9754e-04, 7.0647e-06,\n",
      "        1.0842e-05, 2.3871e-03, 8.9997e-04, 9.0820e-04, 4.0696e-07, 2.6980e-04,\n",
      "        1.1504e-07, 5.9931e-05, 7.0953e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.4346e-08, 2.4380e-01, 1.3215e-02, 9.6090e-03, 9.4940e-03, 3.2819e-03,\n",
      "        1.7620e-02, 4.5453e-03, 2.1608e-02, 9.1087e-02, 1.1509e-03, 4.6884e-04,\n",
      "        3.6738e-03, 2.5492e-02, 9.5413e-03, 2.9334e-01, 1.0032e-02, 1.7475e-03,\n",
      "        2.2998e-02, 2.9580e-02, 1.2253e-01, 1.8349e-02, 5.4945e-03, 4.0759e-02,\n",
      "        1.1069e-05, 5.3270e-04, 3.8592e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.1149e-02, 2.1965e-04, 1.3278e-04, 3.4839e-05, 5.5765e-03, 7.3295e-05,\n",
      "        3.4898e-02, 6.6860e-04, 1.5791e-04, 3.2550e-06, 1.1303e-06, 1.6313e-06,\n",
      "        1.6091e-03, 1.2560e-02, 4.3857e-01, 2.1884e-04, 4.9206e-04, 3.9363e-05,\n",
      "        4.2000e-04, 2.3910e-01, 2.3328e-01, 8.7291e-06, 5.7021e-04, 1.6896e-04,\n",
      "        4.3687e-05, 2.5017e-07, 1.4655e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.6985e-01, 7.4524e-03, 2.0504e-04, 3.7862e-02, 6.8690e-02, 7.3078e-04,\n",
      "        8.6223e-03, 1.1073e-03, 4.8309e-04, 1.2794e-04, 4.9812e-03, 1.8483e-05,\n",
      "        4.2402e-04, 4.7291e-04, 1.4879e-03, 1.8131e-04, 4.8206e-05, 6.0013e-04,\n",
      "        9.1871e-05, 2.0271e-02, 4.8984e-02, 1.1549e-03, 2.5476e-02, 3.7648e-04,\n",
      "        2.8873e-04, 6.6152e-06, 6.3923e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0458e-08, 1.2162e-01, 1.5832e-02, 2.1937e-02, 1.8573e-02, 4.5296e-02,\n",
      "        9.4801e-03, 8.2498e-03, 3.4276e-02, 4.1964e-02, 2.9241e-03, 1.2918e-04,\n",
      "        1.5770e-02, 3.3927e-02, 7.0333e-03, 2.3537e-02, 2.3335e-02, 3.6984e-03,\n",
      "        4.0657e-02, 5.9443e-02, 3.9664e-01, 1.2335e-02, 8.5573e-03, 5.3875e-02,\n",
      "        4.6004e-05, 8.0858e-04, 5.9660e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.8261e-06, 3.7857e-02, 3.9014e-06, 1.8805e-06, 5.5814e-09, 4.5575e-02,\n",
      "        9.1157e-07, 1.6750e-06, 7.5038e-01, 8.7547e-02, 4.9589e-07, 3.8402e-05,\n",
      "        4.1991e-05, 2.0673e-04, 5.6168e-05, 5.8855e-02, 2.1968e-07, 2.6402e-06,\n",
      "        1.8670e-02, 7.9166e-06, 5.0558e-04, 5.0029e-05, 5.3978e-08, 1.4090e-04,\n",
      "        1.0231e-06, 3.6727e-05, 8.8547e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([4.2641e-04, 1.4877e-01, 2.7344e-06, 7.4932e-07, 2.4851e-08, 3.5434e-02,\n",
      "        1.9759e-07, 6.1906e-08, 1.0196e-05, 6.9222e-01, 9.6816e-08, 1.6354e-07,\n",
      "        3.7320e-04, 2.6653e-05, 2.1386e-04, 1.1358e-01, 9.5215e-07, 9.7913e-08,\n",
      "        7.9570e-05, 3.0447e-05, 2.3318e-04, 2.0974e-04, 1.9033e-08, 2.1885e-05,\n",
      "        1.3236e-07, 8.3622e-03, 6.4078e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9300e-04, 4.1245e-05, 8.3841e-06, 9.5168e-01, 6.2966e-05, 2.7647e-05,\n",
      "        5.9498e-05, 5.5424e-04, 5.0273e-04, 6.6534e-08, 1.6992e-07, 2.6990e-06,\n",
      "        3.9114e-02, 1.0111e-03, 8.7602e-04, 8.7191e-06, 4.3735e-05, 5.3506e-06,\n",
      "        1.1912e-05, 2.4499e-03, 2.9656e-03, 3.0607e-07, 1.0441e-05, 2.7502e-06,\n",
      "        5.2443e-06, 4.4107e-08, 3.6105e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "gin to give you my friends as far as i a <------ | ------> n always at spirit to the ascess in whic\n",
      "Epoch 21   Time 63.158    Train Loss: 1.189\n",
      "Softmaxed: tensor([7.9049e-06, 6.6401e-02, 7.0073e-06, 1.1069e-06, 2.2074e-08, 5.2756e-02,\n",
      "        2.2071e-07, 2.9475e-06, 2.9800e-01, 3.7185e-01, 3.0951e-06, 7.8987e-05,\n",
      "        1.2219e-04, 3.4484e-04, 2.1714e-05, 1.9909e-01, 2.3484e-07, 4.7021e-07,\n",
      "        1.0602e-02, 3.8683e-06, 4.4099e-04, 9.7960e-05, 6.5493e-08, 9.1507e-05,\n",
      "        2.4962e-06, 6.3969e-05, 1.3564e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.0932e-03, 1.4360e-03, 4.3064e-05, 1.8791e-03, 5.5786e-04, 7.5390e-04,\n",
      "        4.8620e-06, 2.2761e-04, 1.6781e-03, 4.9958e-04, 2.9609e-05, 2.0064e-03,\n",
      "        5.5800e-03, 1.3577e-01, 2.0298e-02, 3.8615e-04, 4.0605e-04, 9.3799e-06,\n",
      "        6.4440e-01, 7.9683e-03, 3.1698e-03, 1.6657e-01, 9.5365e-04, 1.8497e-03,\n",
      "        8.0189e-04, 5.5311e-06, 6.2413e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.6206e-04, 8.2000e-01, 2.1490e-03, 2.2793e-04, 5.6862e-04, 1.4570e-01,\n",
      "        1.3916e-05, 1.4865e-06, 2.7528e-04, 1.9125e-03, 1.9714e-05, 2.6030e-05,\n",
      "        5.0135e-03, 1.8669e-03, 3.5720e-04, 2.4260e-04, 9.8907e-03, 4.6998e-05,\n",
      "        8.9446e-04, 8.5168e-03, 1.2315e-04, 5.8759e-04, 2.3087e-05, 3.5602e-05,\n",
      "        5.2108e-06, 3.7979e-05, 8.9433e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.4917e-03, 1.7250e-01, 2.2494e-04, 6.4928e-03, 1.0959e-05, 1.3508e-01,\n",
      "        1.3293e-04, 7.5728e-05, 1.7294e-02, 9.6070e-03, 1.0527e-05, 6.9620e-04,\n",
      "        8.4932e-04, 2.5698e-03, 1.1190e-03, 4.7579e-02, 7.8813e-04, 9.6206e-05,\n",
      "        4.9008e-05, 1.4057e-04, 5.9343e-01, 1.0687e-03, 6.9052e-07, 2.7332e-03,\n",
      "        9.8764e-06, 8.1929e-04, 1.3477e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.5524e-01, 1.4814e-02, 2.2019e-06, 1.1089e-05, 6.0195e-07, 4.2259e-03,\n",
      "        5.8191e-05, 3.2937e-07, 3.1562e-03, 4.9565e-03, 3.8530e-06, 1.3892e-06,\n",
      "        5.1048e-03, 1.8358e-05, 2.8365e-06, 2.0101e-03, 6.4286e-06, 3.0124e-06,\n",
      "        2.0050e-04, 1.5905e-03, 2.0086e-05, 8.2314e-03, 2.5202e-07, 1.6536e-04,\n",
      "        6.0888e-07, 1.7312e-04, 3.6974e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.0206e-08, 5.6483e-02, 3.9428e-02, 4.6847e-02, 3.3158e-02, 2.4080e-02,\n",
      "        3.5190e-02, 8.5885e-03, 6.6743e-02, 1.2721e-01, 3.1519e-03, 1.2302e-03,\n",
      "        9.1533e-03, 2.4784e-02, 2.2896e-02, 2.3204e-02, 1.7839e-02, 1.9919e-03,\n",
      "        1.7121e-02, 5.9165e-02, 2.9194e-01, 7.4043e-03, 2.1268e-03, 7.6652e-02,\n",
      "        2.8999e-06, 3.5696e-03, 3.6631e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.9610e-04, 4.0004e-01, 1.3926e-04, 8.8246e-08, 2.1554e-08, 3.1966e-01,\n",
      "        5.0780e-06, 1.5423e-07, 1.2970e-05, 5.0792e-02, 6.2641e-07, 1.8265e-08,\n",
      "        1.8927e-06, 2.8136e-05, 1.2254e-05, 5.0806e-02, 8.6464e-04, 1.3745e-06,\n",
      "        4.3120e-05, 8.8588e-05, 6.8939e-08, 1.4059e-01, 8.5586e-07, 1.9515e-05,\n",
      "        5.2837e-07, 3.6691e-02, 1.4388e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.8810e-02, 1.3728e-01, 9.2610e-04, 9.9006e-03, 4.0383e-02, 1.2948e-03,\n",
      "        8.8733e-05, 2.7063e-03, 6.9736e-04, 6.0564e-04, 1.6003e-04, 1.6665e-04,\n",
      "        9.7147e-03, 1.4556e-02, 3.0514e-01, 2.7761e-04, 9.5653e-04, 7.5330e-04,\n",
      "        3.7884e-02, 6.1191e-03, 3.2801e-01, 9.6645e-05, 4.2186e-04, 1.2232e-04,\n",
      "        2.3865e-03, 2.1402e-04, 3.2855e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.1288e-01, 1.0385e-03, 4.1744e-06, 3.1540e-03, 5.9523e-03, 1.3393e-03,\n",
      "        2.7779e-05, 7.8527e-04, 7.0597e-04, 8.8039e-04, 6.8976e-05, 1.4395e-04,\n",
      "        1.8125e-04, 3.3637e-05, 7.4088e-04, 2.5393e-03, 8.3597e-06, 4.4912e-04,\n",
      "        1.0856e-04, 4.0863e-02, 3.2710e-01, 3.7295e-04, 4.8507e-05, 1.1478e-04,\n",
      "        2.9469e-05, 2.1884e-04, 2.0564e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3799e-08, 9.2199e-02, 1.1869e-02, 2.7318e-02, 2.3922e-02, 8.9976e-03,\n",
      "        1.4169e-02, 5.0627e-03, 7.2241e-02, 1.7157e-01, 1.8161e-03, 1.9872e-03,\n",
      "        2.4827e-02, 1.9406e-02, 1.3175e-02, 2.3227e-01, 1.6248e-02, 1.3458e-03,\n",
      "        8.2412e-03, 4.6813e-02, 1.0054e-01, 2.6147e-02, 1.8199e-03, 7.2423e-02,\n",
      "        4.4080e-06, 5.5211e-03, 6.1403e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1443e-05, 1.8948e-01, 7.1306e-07, 7.6227e-05, 1.5207e-07, 1.3099e-01,\n",
      "        3.8779e-06, 1.0499e-05, 1.3029e-04, 7.1879e-03, 3.5367e-06, 1.2398e-06,\n",
      "        8.2856e-05, 2.0155e-07, 1.2287e-05, 6.6987e-01, 4.3939e-08, 1.8784e-06,\n",
      "        2.0489e-04, 6.6362e-08, 3.5615e-05, 1.6170e-03, 4.8669e-06, 2.1734e-04,\n",
      "        2.1431e-06, 6.0765e-05, 8.6981e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.2466e-01, 5.2257e-05, 1.9454e-02, 1.2507e-03, 7.4028e-05, 1.9764e-05,\n",
      "        9.2737e-04, 1.5432e-04, 1.1287e-04, 2.8106e-03, 1.5968e-05, 3.0287e-04,\n",
      "        7.2986e-05, 4.1609e-03, 4.6254e-03, 1.7356e-04, 7.0318e-04, 5.3443e-06,\n",
      "        4.0514e-02, 1.6900e-04, 6.4147e-01, 3.9053e-03, 1.8956e-03, 1.5193e-01,\n",
      "        4.7261e-04, 3.8649e-05, 2.5939e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.4706e-01, 7.0228e-04, 9.8305e-06, 6.0299e-07, 6.0846e-05, 2.8306e-03,\n",
      "        5.8654e-05, 2.0624e-07, 2.3113e-01, 5.8730e-03, 1.4710e-05, 1.9109e-05,\n",
      "        7.7847e-04, 1.2032e-04, 1.2138e-04, 5.4364e-03, 1.6107e-05, 5.4107e-05,\n",
      "        2.8979e-04, 3.1139e-03, 9.0803e-04, 3.5566e-04, 1.9859e-05, 8.4546e-04,\n",
      "        6.2483e-07, 5.8159e-05, 1.2603e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.9169e-07, 1.1355e-01, 1.1544e-01, 3.6002e-02, 4.4772e-02, 5.2036e-02,\n",
      "        4.8696e-02, 6.5338e-03, 6.6909e-02, 3.3505e-02, 5.4011e-03, 2.1180e-02,\n",
      "        3.1027e-02, 1.2848e-02, 5.3695e-03, 8.1448e-02, 4.9315e-02, 3.1942e-03,\n",
      "        2.3639e-02, 6.9424e-02, 1.4477e-01, 7.2380e-03, 7.1194e-03, 1.5226e-02,\n",
      "        1.3391e-05, 5.2891e-03, 5.5302e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9034e-05, 3.3461e-01, 1.8213e-05, 8.9057e-08, 1.8161e-08, 1.9342e-01,\n",
      "        9.3417e-06, 6.7171e-07, 4.8498e-06, 3.8066e-01, 2.2770e-07, 1.3194e-08,\n",
      "        6.4993e-05, 1.8986e-05, 8.0570e-06, 7.6527e-02, 1.9083e-05, 5.3237e-07,\n",
      "        3.9186e-04, 9.7481e-06, 5.2595e-06, 1.3280e-02, 6.1320e-07, 1.1100e-04,\n",
      "        2.1987e-07, 8.1984e-04, 5.9893e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.0759e-04, 7.8100e-03, 4.3931e-03, 2.1867e-03, 1.3588e-03, 4.2998e-03,\n",
      "        3.8379e-04, 4.4155e-04, 2.1508e-04, 2.4683e-03, 2.6667e-05, 5.6399e-05,\n",
      "        2.3748e-02, 1.1164e-01, 5.7204e-02, 1.4507e-02, 2.7235e-02, 3.5081e-06,\n",
      "        1.2145e-02, 3.7881e-03, 4.1107e-02, 1.9764e-02, 6.7509e-03, 6.5612e-01,\n",
      "        1.3197e-03, 1.2854e-04, 3.9377e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.1424e-02, 2.7507e-02, 2.0333e-05, 1.2381e-02, 6.8820e-03, 2.1318e-01,\n",
      "        3.9464e-06, 1.7307e-02, 1.6454e-02, 2.4067e-02, 5.3570e-04, 1.3262e-03,\n",
      "        6.5401e-03, 1.6580e-04, 1.9927e-03, 6.4032e-01, 4.2110e-05, 1.8776e-04,\n",
      "        8.0643e-05, 1.8761e-03, 1.0549e-02, 1.8042e-03, 1.0482e-04, 3.9603e-03,\n",
      "        8.8875e-04, 3.7234e-04, 2.7178e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.2878e-02, 1.2813e-03, 5.0430e-03, 2.8233e-03, 9.7483e-04, 4.7729e-04,\n",
      "        7.7294e-05, 1.2411e-03, 2.0786e-04, 4.0756e-03, 4.9312e-05, 3.7570e-04,\n",
      "        4.8777e-03, 1.8536e-02, 4.3653e-04, 4.4686e-03, 4.4394e-03, 1.4618e-05,\n",
      "        1.5113e-01, 2.7929e-04, 1.2248e-02, 6.8032e-01, 2.8589e-03, 8.6678e-02,\n",
      "        3.9747e-03, 4.5703e-05, 1.9135e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.7865e-03, 1.5206e-03, 4.9388e-03, 2.2079e-03, 6.6432e-04, 1.1901e-04,\n",
      "        2.8780e-05, 1.7132e-02, 4.0584e-05, 1.8048e-03, 6.7836e-07, 2.9427e-05,\n",
      "        1.5845e-02, 2.3416e-02, 1.4728e-02, 4.3855e-04, 2.0356e-04, 3.7054e-07,\n",
      "        9.0164e-01, 7.0479e-03, 2.2000e-03, 1.2961e-05, 2.7259e-06, 1.3764e-04,\n",
      "        2.0969e-05, 1.6505e-06, 3.4727e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.5699e-01, 6.3652e-03, 3.2745e-03, 6.7481e-04, 7.1067e-03, 1.0359e-01,\n",
      "        1.8199e-03, 1.2302e-04, 3.2194e-04, 1.8145e-02, 1.1338e-06, 6.1054e-06,\n",
      "        8.6268e-04, 1.5578e-02, 2.7450e-03, 3.0072e-04, 5.2241e-05, 4.6060e-07,\n",
      "        9.4544e-04, 7.8240e-02, 2.2764e-03, 7.1734e-06, 2.6869e-06, 1.3109e-04,\n",
      "        1.2947e-06, 4.3536e-04, 2.4222e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.6788e-01, 6.0806e-05, 4.6491e-06, 4.8370e-06, 4.8777e-07, 1.2866e-02,\n",
      "        1.2939e-04, 7.6724e-07, 2.3008e-04, 1.6534e-02, 8.9176e-08, 9.2488e-07,\n",
      "        3.0842e-04, 1.5041e-04, 8.8166e-06, 8.5757e-04, 1.5716e-05, 2.1823e-07,\n",
      "        5.6088e-07, 3.4482e-04, 5.0286e-04, 1.2858e-05, 1.8188e-08, 5.7030e-06,\n",
      "        3.2691e-08, 8.4761e-05, 2.9319e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.7607e-08, 1.9022e-01, 2.9012e-02, 1.0277e-02, 1.5989e-02, 1.2862e-02,\n",
      "        7.6659e-02, 6.0663e-03, 2.6768e-02, 1.3217e-01, 3.1006e-03, 4.7953e-04,\n",
      "        8.6739e-03, 1.1353e-02, 5.2141e-03, 1.5332e-01, 7.9229e-03, 1.2398e-03,\n",
      "        1.1886e-02, 4.2168e-02, 1.6287e-01, 1.2666e-02, 7.7640e-03, 6.9679e-02,\n",
      "        4.9737e-06, 1.6058e-03, 2.6043e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.3225e-05, 8.5973e-06, 4.5249e-03, 1.0144e-03, 2.7881e-04, 6.1172e-06,\n",
      "        8.6586e-01, 1.0864e-04, 3.7547e-05, 1.1133e-05, 9.2084e-06, 2.3300e-05,\n",
      "        8.3866e-04, 1.3468e-04, 5.4482e-02, 4.4089e-05, 4.0047e-03, 1.6399e-05,\n",
      "        4.0126e-02, 1.3176e-05, 4.9513e-03, 1.2906e-02, 2.9442e-03, 7.6117e-03,\n",
      "        7.1717e-06, 1.5455e-06, 3.5790e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9593e-01, 2.5803e-06, 4.2845e-06, 2.1061e-05, 9.8520e-06, 4.4721e-05,\n",
      "        2.0715e-03, 1.5518e-06, 5.6249e-07, 6.0060e-07, 2.5953e-06, 2.1236e-06,\n",
      "        1.9972e-05, 1.6045e-04, 2.2472e-07, 7.3038e-07, 2.7167e-05, 6.5613e-07,\n",
      "        1.0439e-05, 8.8536e-07, 1.6380e-03, 1.2978e-06, 3.4491e-05, 1.0533e-05,\n",
      "        1.0152e-07, 5.0785e-07, 5.3235e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.0009e-07, 8.2907e-02, 1.8989e-02, 3.9918e-02, 3.9220e-02, 5.7975e-02,\n",
      "        2.4430e-02, 3.1128e-02, 5.1612e-02, 5.0874e-02, 1.2897e-02, 8.6944e-03,\n",
      "        2.3596e-02, 6.3779e-02, 2.0516e-02, 3.1039e-02, 4.0323e-02, 9.4763e-04,\n",
      "        7.0636e-02, 4.2070e-02, 2.0106e-01, 4.1076e-03, 2.6975e-02, 4.7064e-02,\n",
      "        6.3234e-05, 9.0633e-03, 1.2059e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.4522e-01, 1.3661e-05, 9.0951e-03, 1.5713e-02, 5.4310e-02, 5.4276e-05,\n",
      "        6.1693e-03, 1.0570e-02, 2.4116e-04, 4.7905e-04, 5.5777e-05, 9.6786e-04,\n",
      "        3.7412e-01, 9.8614e-03, 1.4742e-01, 1.5341e-06, 8.4870e-03, 3.0616e-05,\n",
      "        2.8900e-02, 1.4571e-02, 4.2493e-02, 1.6379e-02, 5.6878e-03, 7.6048e-03,\n",
      "        5.0072e-04, 9.9048e-04, 6.7746e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.0594e-08, 1.1092e-03, 7.9647e-02, 7.8237e-02, 2.3566e-02, 2.0738e-03,\n",
      "        4.5385e-02, 7.0080e-02, 3.9606e-02, 1.0872e-03, 4.3769e-03, 3.4201e-03,\n",
      "        4.6670e-02, 6.8196e-02, 1.0210e-01, 3.0528e-03, 1.0222e-01, 9.1484e-03,\n",
      "        8.9970e-02, 1.1245e-01, 5.9789e-02, 1.9599e-03, 2.3094e-02, 3.2532e-02,\n",
      "        1.6102e-04, 4.5190e-05, 3.4238e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.5643e-05, 7.7661e-02, 2.0365e-05, 1.2925e-06, 4.2143e-07, 2.5260e-01,\n",
      "        1.9075e-05, 5.2885e-06, 1.0731e-01, 2.0587e-02, 2.5081e-05, 1.2081e-06,\n",
      "        8.7503e-02, 6.1018e-06, 1.3791e-04, 1.7919e-01, 1.6055e-03, 1.3251e-06,\n",
      "        2.3902e-01, 2.6876e-03, 1.9542e-03, 2.8748e-02, 1.2094e-05, 7.3518e-04,\n",
      "        4.4172e-05, 8.6000e-05, 1.0879e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.9220e-06, 1.0378e-05, 2.7162e-04, 3.3902e-03, 2.7462e-04, 7.3671e-06,\n",
      "        2.0642e-04, 1.9433e-04, 1.9522e-05, 1.4457e-01, 3.9493e-04, 6.7004e-04,\n",
      "        2.0371e-02, 4.9790e-05, 2.5530e-02, 2.5637e-05, 5.3886e-03, 1.3957e-06,\n",
      "        3.6328e-01, 3.3269e-01, 9.3634e-02, 3.8622e-04, 1.9056e-04, 2.7217e-04,\n",
      "        1.2982e-04, 7.3627e-03, 6.7598e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.9232e-04, 3.0318e-02, 2.9539e-03, 1.0177e-02, 2.0802e-02, 3.9200e-02,\n",
      "        1.3670e-03, 3.4624e-03, 5.2337e-04, 1.0629e-01, 5.8425e-05, 1.5164e-02,\n",
      "        1.7092e-03, 2.5102e-03, 7.2975e-03, 1.6592e-03, 9.9893e-03, 1.3794e-05,\n",
      "        1.0439e-02, 2.2320e-03, 7.2933e-01, 4.5909e-05, 1.4545e-04, 2.9560e-04,\n",
      "        6.4130e-05, 3.6985e-03, 6.3998e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.1647e-01, 9.7855e-03, 1.9579e-04, 3.5258e-06, 2.0868e-04, 2.0635e-02,\n",
      "        5.2549e-03, 4.5852e-06, 7.1735e-03, 4.5404e-01, 1.0079e-05, 5.9600e-05,\n",
      "        3.4579e-02, 2.5459e-04, 2.5790e-04, 2.7459e-02, 6.7780e-05, 1.8699e-05,\n",
      "        2.7053e-03, 1.5401e-02, 4.2362e-04, 2.2581e-02, 7.3192e-06, 7.5251e-04,\n",
      "        3.2617e-06, 8.1593e-02, 5.0966e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.4708e-03, 1.1660e-02, 5.2478e-03, 2.9540e-01, 7.3857e-03, 3.0462e-03,\n",
      "        1.1635e-01, 3.8430e-04, 3.2320e-05, 1.4135e-04, 3.2351e-05, 6.2103e-06,\n",
      "        6.5894e-03, 1.5103e-04, 4.2846e-01, 6.6681e-02, 3.0153e-03, 2.3922e-03,\n",
      "        2.6642e-03, 1.0718e-02, 2.9925e-03, 1.0111e-04, 3.3368e-02, 2.6561e-04,\n",
      "        2.7047e-04, 3.6968e-07, 1.1639e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.9877e-03, 1.0102e-02, 1.2554e-05, 2.5092e-04, 1.5653e-06, 1.1285e-02,\n",
      "        4.9750e-03, 4.2888e-06, 3.7900e-06, 8.3463e-01, 2.1302e-06, 8.9359e-06,\n",
      "        2.0110e-03, 7.6555e-06, 1.1410e-04, 1.0135e-02, 7.4309e-07, 4.8789e-05,\n",
      "        3.0083e-04, 2.4147e-04, 2.0090e-04, 1.0652e-01, 1.2764e-05, 1.6458e-04,\n",
      "        2.0816e-05, 1.5944e-02, 7.5103e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.8511e-03, 2.1153e-02, 1.4089e-03, 4.9298e-01, 2.6820e-03, 3.4358e-01,\n",
      "        3.5005e-02, 1.5100e-03, 2.0254e-05, 1.4040e-05, 7.1336e-06, 3.4981e-04,\n",
      "        1.6824e-02, 7.6819e-03, 5.0541e-03, 8.6873e-04, 4.3242e-04, 1.2462e-03,\n",
      "        2.0960e-06, 2.1230e-02, 1.1275e-02, 2.4613e-04, 2.6919e-02, 4.2770e-05,\n",
      "        1.4449e-04, 1.9815e-06, 1.4663e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([8.5511e-03, 8.6972e-05, 1.4405e-05, 1.1603e-04, 8.0535e-01, 6.4021e-05,\n",
      "        9.0890e-03, 6.2499e-05, 2.0433e-06, 9.7043e-06, 3.8979e-06, 1.3361e-05,\n",
      "        2.5522e-04, 4.3716e-03, 1.1568e-02, 1.4096e-06, 1.6380e-04, 1.0398e-04,\n",
      "        1.8854e-03, 1.5503e-01, 5.8417e-04, 3.3076e-05, 2.3535e-03, 1.7017e-04,\n",
      "        9.4400e-05, 4.3395e-06, 1.0811e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9912e-01, 5.9541e-06, 1.0496e-07, 1.4382e-07, 1.4961e-06, 6.0733e-05,\n",
      "        1.8023e-05, 5.6874e-06, 5.3241e-07, 7.6745e-06, 2.0495e-09, 2.4679e-07,\n",
      "        7.8014e-06, 3.8986e-05, 1.0999e-05, 1.6989e-05, 5.2924e-08, 3.3280e-07,\n",
      "        2.2093e-07, 5.6074e-04, 2.3983e-05, 1.1004e-04, 8.8464e-08, 3.8277e-06,\n",
      "        5.7201e-08, 1.5087e-06, 1.4228e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([1.2057e-07, 1.5994e-01, 5.9734e-02, 2.2305e-02, 1.8067e-02, 1.5320e-02,\n",
      "        8.0395e-02, 7.6232e-03, 5.4484e-02, 1.0017e-01, 3.4233e-03, 1.1698e-03,\n",
      "        1.0951e-03, 1.9962e-02, 4.0866e-02, 3.2808e-02, 2.4753e-02, 1.4640e-03,\n",
      "        3.6489e-02, 5.6196e-02, 1.6129e-01, 3.3845e-03, 1.0319e-02, 8.4503e-02,\n",
      "        4.1962e-06, 4.1267e-03, 9.8522e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.0215e-08, 8.4991e-02, 7.9277e-06, 3.3158e-07, 2.3071e-07, 7.2190e-01,\n",
      "        7.4087e-07, 4.3999e-05, 1.5088e-04, 3.5782e-02, 4.5622e-07, 9.3788e-08,\n",
      "        6.5539e-05, 7.4287e-07, 1.2772e-04, 3.7153e-02, 1.8003e-07, 1.9492e-06,\n",
      "        4.1359e-06, 1.0462e-06, 1.1783e-07, 1.1807e-01, 2.3477e-06, 1.3425e-05,\n",
      "        9.7094e-07, 1.6729e-03, 9.0090e-09], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.0198e-04, 1.8083e-01, 6.6810e-03, 6.7049e-02, 3.2343e-03, 5.3583e-04,\n",
      "        7.8165e-02, 6.4376e-02, 9.8694e-04, 1.1056e-03, 4.8641e-03, 2.6020e-05,\n",
      "        1.5970e-01, 1.5836e-02, 1.3417e-02, 4.3810e-04, 5.5978e-02, 4.5531e-02,\n",
      "        2.1222e-03, 1.6444e-01, 1.3457e-02, 5.6393e-04, 1.1711e-01, 2.0913e-03,\n",
      "        2.8556e-04, 2.4479e-04, 2.7034e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.3302e-10, 6.1465e-07, 1.0278e-06, 4.7261e-06, 5.1859e-08, 6.5697e-08,\n",
      "        9.0083e-08, 1.9900e-08, 1.7263e-09, 4.7077e-05, 3.9270e-08, 5.8423e-08,\n",
      "        1.5813e-06, 6.8375e-07, 4.5652e-09, 1.2661e-06, 2.7725e-05, 7.9118e-10,\n",
      "        4.6423e-06, 4.6486e-07, 5.3682e-07, 9.9991e-01, 1.9982e-06, 8.1817e-08,\n",
      "        2.8441e-08, 1.6658e-08, 1.4035e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "not without some danger get an idea of w <------ | ------> omst men not honours of a partified requ\n",
      "Epoch 22   Time 61.611    Train Loss: 1.183\n",
      "Softmaxed: tensor([6.8502e-01, 1.3022e-03, 1.0098e-03, 1.1006e-02, 8.2717e-02, 3.3636e-04,\n",
      "        1.4648e-03, 3.1237e-04, 5.6486e-05, 1.2558e-02, 1.0189e-03, 8.7829e-05,\n",
      "        2.2182e-03, 1.5564e-03, 2.0945e-03, 5.4753e-02, 1.8531e-05, 9.4478e-05,\n",
      "        3.6156e-05, 7.2442e-03, 2.0745e-02, 5.4412e-05, 2.4669e-03, 8.3581e-03,\n",
      "        3.9766e-03, 9.9443e-02, 4.9701e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.2487e-08, 4.6909e-01, 4.0014e-03, 1.9372e-03, 1.3827e-03, 2.0033e-01,\n",
      "        1.2552e-03, 2.0137e-04, 3.8828e-03, 9.6309e-02, 1.2189e-03, 8.1157e-04,\n",
      "        3.1427e-03, 2.0949e-03, 3.1898e-03, 1.5593e-01, 1.6035e-02, 1.8269e-03,\n",
      "        4.3320e-03, 1.1040e-02, 4.2099e-03, 1.3579e-02, 1.1304e-03, 2.1672e-03,\n",
      "        2.0024e-05, 8.7443e-04, 8.3328e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.9409e-05, 5.0681e-05, 6.3452e-02, 1.1886e-02, 1.6157e-02, 5.2775e-03,\n",
      "        2.5672e-02, 3.8407e-03, 2.5608e-04, 7.7079e-05, 1.1246e-03, 2.6921e-03,\n",
      "        8.1542e-02, 1.0521e-03, 1.8848e-01, 2.6434e-03, 1.1487e-01, 6.7764e-05,\n",
      "        1.5517e-01, 9.8854e-05, 1.0272e-01, 4.1248e-02, 3.9141e-02, 1.4188e-01,\n",
      "        4.2450e-04, 6.1029e-05, 9.1199e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.6620e-04, 3.7867e-03, 3.0001e-05, 1.0704e-02, 8.7208e-03, 8.1577e-03,\n",
      "        1.4701e-04, 2.7571e-04, 9.1822e-01, 4.1389e-03, 1.6811e-04, 5.0879e-04,\n",
      "        3.6663e-04, 3.7560e-04, 4.2305e-05, 3.8292e-05, 3.2067e-03, 2.9987e-04,\n",
      "        2.6339e-02, 6.2739e-03, 2.7820e-03, 1.3120e-04, 7.6600e-05, 3.5192e-03,\n",
      "        8.3739e-06, 7.1891e-04, 7.9552e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.1580e-04, 5.9813e-03, 2.2601e-07, 8.2247e-08, 3.2575e-07, 9.9116e-01,\n",
      "        4.1543e-07, 6.7019e-06, 2.4035e-07, 1.4542e-03, 5.2256e-07, 2.6622e-08,\n",
      "        4.7709e-06, 7.3405e-06, 8.1078e-06, 3.9801e-04, 3.3513e-07, 3.9648e-08,\n",
      "        1.0428e-04, 4.6661e-05, 6.7773e-07, 2.3871e-04, 1.1170e-07, 4.1365e-06,\n",
      "        1.6148e-07, 3.6421e-04, 1.8094e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.5880e-04, 1.7436e-04, 9.6110e-06, 1.8700e-03, 3.1599e-04, 2.1497e-04,\n",
      "        2.7374e-05, 1.5316e-04, 1.0927e-04, 4.6994e-05, 1.3632e-06, 2.3618e-06,\n",
      "        1.8762e-04, 1.7324e-03, 1.6887e-03, 8.0722e-05, 1.2187e-04, 6.0294e-06,\n",
      "        9.8533e-01, 6.0197e-03, 6.9580e-04, 5.6385e-06, 6.6203e-05, 2.4417e-05,\n",
      "        1.0786e-04, 1.1238e-04, 3.1736e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8367e-01, 2.6862e-04, 8.6255e-05, 2.6638e-03, 4.7077e-03, 1.5971e-02,\n",
      "        5.6181e-04, 7.7696e-05, 1.6882e-04, 2.6687e-03, 2.5440e-06, 1.1720e-04,\n",
      "        8.4650e-04, 3.6998e-04, 5.0695e-04, 2.0473e-05, 1.1621e-05, 3.7062e-06,\n",
      "        2.8505e-05, 7.8605e-01, 2.6852e-04, 3.2032e-07, 7.1126e-05, 2.9815e-04,\n",
      "        9.3737e-06, 5.3895e-04, 2.0184e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.3943e-01, 1.0963e-03, 8.7753e-04, 1.3102e-03, 9.7258e-07, 2.1974e-02,\n",
      "        6.2164e-04, 1.9876e-06, 2.9452e-03, 4.7038e-03, 8.5035e-07, 2.3172e-05,\n",
      "        1.6488e-05, 1.3159e-03, 4.9625e-05, 1.5018e-02, 2.3321e-03, 9.9950e-06,\n",
      "        1.0048e-04, 6.0448e-04, 6.8836e-03, 1.3895e-04, 4.6976e-06, 4.3792e-04,\n",
      "        1.3916e-06, 8.8841e-05, 1.3327e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.7852e-08, 2.4030e-01, 1.1803e-02, 2.0453e-02, 9.7179e-03, 1.9884e-02,\n",
      "        5.9537e-02, 3.3799e-03, 3.7182e-02, 6.9198e-02, 7.8202e-04, 6.4393e-04,\n",
      "        1.2113e-02, 3.2999e-02, 1.0918e-02, 1.9897e-01, 2.0586e-02, 3.7839e-04,\n",
      "        1.1274e-02, 6.0117e-02, 9.3731e-02, 7.1499e-03, 2.7777e-03, 7.1819e-02,\n",
      "        7.2769e-06, 4.2780e-03, 5.1665e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.8533e-05, 1.2415e-02, 2.7617e-06, 5.1581e-08, 1.2531e-08, 3.8726e-03,\n",
      "        4.1160e-05, 5.9663e-07, 6.7995e-01, 4.3693e-03, 3.3241e-07, 1.6206e-06,\n",
      "        1.4243e-04, 4.7813e-06, 3.1820e-06, 2.7362e-01, 2.2962e-07, 8.9809e-07,\n",
      "        2.2024e-02, 8.3568e-06, 3.3524e-06, 1.9954e-03, 1.1806e-07, 1.0769e-03,\n",
      "        4.2703e-08, 4.0713e-04, 4.7201e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([4.9718e-05, 1.3079e-01, 4.9950e-07, 4.6941e-10, 1.6399e-07, 7.6041e-01,\n",
      "        1.8715e-07, 1.7936e-07, 3.1100e-06, 7.8391e-02, 1.8295e-07, 8.6773e-08,\n",
      "        7.8043e-06, 1.3279e-05, 5.2552e-05, 1.0686e-02, 4.9962e-07, 1.9906e-08,\n",
      "        1.4603e-02, 4.7948e-05, 1.9958e-06, 4.4612e-03, 2.9910e-09, 3.7587e-05,\n",
      "        4.2779e-07, 4.4543e-04, 5.3122e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.6089e-01, 3.0657e-05, 1.1114e-05, 1.8322e-06, 3.8579e-06, 1.2029e-03,\n",
      "        3.4803e-05, 2.0260e-04, 1.1751e-03, 3.8049e-02, 7.6675e-06, 1.0774e-05,\n",
      "        1.4685e-04, 5.2182e-02, 1.1221e-02, 2.1383e-04, 2.2070e-04, 5.8105e-07,\n",
      "        1.4060e-01, 9.9094e-03, 4.1894e-04, 3.3215e-06, 2.0166e-05, 6.1242e-04,\n",
      "        2.5589e-05, 8.2758e-02, 4.0236e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.0210e-07, 5.8622e-02, 4.5255e-02, 7.3636e-02, 6.7893e-02, 3.4042e-02,\n",
      "        4.2000e-02, 5.0075e-02, 4.5478e-02, 4.0964e-02, 4.1230e-03, 1.7134e-03,\n",
      "        2.6302e-02, 5.9700e-02, 2.4392e-02, 5.7601e-02, 6.7545e-02, 5.7393e-03,\n",
      "        3.9135e-02, 1.3008e-01, 3.9152e-02, 2.1311e-02, 2.4705e-02, 3.7316e-02,\n",
      "        2.4282e-05, 3.1567e-03, 4.0477e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.4447e-06, 1.0579e-01, 6.5423e-06, 1.2251e-07, 3.2892e-08, 6.7868e-02,\n",
      "        2.6318e-05, 1.8500e-06, 1.9342e-01, 1.2177e-01, 8.9703e-07, 2.2169e-06,\n",
      "        2.1322e-04, 5.3593e-06, 1.4927e-05, 5.7725e-02, 2.5892e-06, 2.4245e-06,\n",
      "        3.7657e-01, 5.0616e-05, 4.2821e-06, 7.0110e-03, 8.6042e-07, 4.7960e-03,\n",
      "        4.6078e-07, 6.4716e-02, 6.6540e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.5537e-04, 2.9289e-05, 3.7396e-02, 1.8279e-02, 1.5368e-02, 8.9441e-05,\n",
      "        4.4149e-03, 3.7107e-03, 4.0299e-04, 7.2259e-02, 4.3207e-04, 6.3515e-02,\n",
      "        2.1704e-02, 7.8443e-03, 5.7149e-02, 3.6984e-04, 1.2878e-02, 1.7083e-04,\n",
      "        1.2862e-01, 4.4887e-01, 9.5314e-02, 2.1865e-03, 1.7966e-04, 1.4452e-03,\n",
      "        2.5874e-04, 5.8448e-03, 1.1083e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.0654e-04, 2.1485e-02, 5.0513e-03, 4.0474e-03, 7.5265e-01, 4.6518e-02,\n",
      "        1.2790e-03, 3.6418e-03, 1.6593e-03, 6.0322e-02, 1.2862e-05, 4.7062e-02,\n",
      "        1.6907e-03, 6.5459e-03, 1.4852e-02, 3.3360e-04, 1.1690e-03, 1.3464e-05,\n",
      "        5.5259e-04, 3.6260e-03, 2.3413e-02, 1.9298e-04, 1.0761e-04, 2.0632e-04,\n",
      "        1.7260e-04, 2.5799e-03, 9.3171e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.0320e-01, 6.1698e-02, 1.3456e-04, 1.1531e-04, 1.2469e-04, 1.5748e-02,\n",
      "        1.7766e-03, 4.3963e-04, 1.0065e-04, 4.7176e-01, 1.3314e-05, 2.7134e-06,\n",
      "        3.9769e-02, 5.7957e-04, 4.5521e-02, 2.9488e-02, 6.3297e-06, 5.5134e-05,\n",
      "        4.9594e-05, 1.1573e-01, 2.1410e-05, 1.1287e-02, 6.0887e-05, 1.7681e-03,\n",
      "        5.2492e-05, 4.8263e-04, 5.8971e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.5944e-08, 2.3273e-01, 3.8729e-02, 5.1662e-02, 7.9649e-02, 1.5253e-02,\n",
      "        3.2391e-02, 5.9733e-03, 2.9522e-02, 7.6011e-02, 3.5753e-03, 8.3953e-04,\n",
      "        5.1021e-03, 3.0644e-02, 1.1615e-02, 8.7542e-02, 3.8677e-02, 5.4996e-03,\n",
      "        1.3676e-02, 1.3122e-01, 5.2344e-02, 8.5322e-03, 6.6928e-03, 4.0104e-02,\n",
      "        9.4591e-06, 1.9202e-03, 9.0753e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.5773e-03, 7.0722e-05, 7.0473e-05, 2.2376e-05, 5.1483e-03, 3.2765e-05,\n",
      "        1.3943e-02, 8.3541e-04, 6.2223e-05, 2.1448e-06, 1.4366e-06, 1.2236e-06,\n",
      "        1.5380e-03, 2.0094e-02, 7.9536e-01, 4.6544e-05, 1.8027e-04, 5.4318e-05,\n",
      "        4.5428e-04, 9.9843e-02, 5.7171e-02, 2.7421e-06, 2.7045e-04, 1.6947e-04,\n",
      "        4.6156e-05, 4.3749e-07, 8.3369e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8950e-01, 9.3625e-03, 3.4864e-04, 5.2125e-02, 1.9118e-01, 1.3978e-03,\n",
      "        2.8275e-02, 7.6285e-03, 1.6591e-03, 5.5332e-04, 9.1114e-03, 4.6879e-05,\n",
      "        1.1746e-03, 1.7070e-03, 8.9050e-03, 4.0721e-04, 6.1986e-05, 1.3111e-03,\n",
      "        6.7771e-04, 9.2320e-02, 1.7350e-01, 1.1579e-03, 2.5360e-02, 1.2839e-03,\n",
      "        8.8523e-04, 6.1109e-05, 1.4687e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.7021e-05, 8.2618e-03, 1.1924e-06, 1.5689e-07, 2.8532e-07, 2.4555e-01,\n",
      "        1.9046e-06, 2.8369e-06, 3.7958e-04, 1.9482e-02, 2.0245e-06, 4.1750e-08,\n",
      "        5.4909e-03, 5.6300e-05, 8.8371e-07, 6.4037e-01, 2.0220e-07, 3.3747e-06,\n",
      "        5.4038e-02, 6.0432e-04, 2.5082e-05, 2.4648e-02, 1.3879e-06, 7.3651e-04,\n",
      "        3.1066e-07, 3.1645e-04, 8.6325e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.1288e-01, 1.6643e-04, 2.2116e-04, 4.3950e-03, 4.3232e-03, 5.5403e-05,\n",
      "        2.9570e-04, 6.9803e-03, 4.2325e-05, 5.8022e-04, 7.1858e-04, 1.4760e-04,\n",
      "        5.2964e-02, 5.5003e-03, 3.5689e-03, 1.4247e-02, 3.9686e-04, 1.2544e-04,\n",
      "        1.7682e-02, 3.3865e-02, 1.5384e-03, 6.9543e-03, 9.3094e-04, 6.8660e-03,\n",
      "        2.4541e-02, 4.1647e-06, 9.9328e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([3.6053e-08, 1.3504e-01, 2.8302e-02, 1.3327e-01, 5.1154e-02, 2.4037e-02,\n",
      "        1.3670e-02, 2.4011e-02, 4.0832e-02, 2.5831e-02, 8.8422e-04, 7.6586e-03,\n",
      "        3.9494e-02, 1.9870e-02, 6.4308e-03, 1.3196e-02, 3.2752e-02, 5.3676e-04,\n",
      "        1.1307e-02, 4.0506e-02, 3.0370e-01, 6.1463e-03, 2.2556e-03, 3.7531e-02,\n",
      "        3.6815e-05, 1.4805e-03, 7.2477e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([5.7437e-05, 8.1705e-05, 2.0136e-02, 5.7327e-03, 2.6749e-03, 5.2986e-04,\n",
      "        1.1628e-01, 1.9659e-03, 1.0223e-04, 2.7611e-04, 6.7559e-05, 4.0984e-04,\n",
      "        2.8826e-02, 6.4609e-04, 5.6815e-01, 3.2095e-04, 2.1291e-02, 3.6338e-05,\n",
      "        8.5571e-02, 3.9867e-06, 4.6669e-02, 5.4273e-02, 3.2187e-02, 1.3560e-02,\n",
      "        8.0354e-05, 3.3307e-05, 4.1549e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.8075e-02, 1.9300e-04, 1.6104e-05, 4.3861e-02, 5.2548e-04, 7.3980e-01,\n",
      "        1.0605e-05, 5.7490e-04, 2.4688e-05, 1.2322e-04, 1.3818e-05, 4.2879e-06,\n",
      "        1.4459e-01, 1.0978e-05, 2.8396e-07, 8.4707e-04, 3.9401e-06, 4.1616e-06,\n",
      "        1.4826e-04, 3.8335e-04, 6.2979e-04, 8.7607e-05, 4.0308e-05, 2.5478e-05,\n",
      "        2.5491e-06, 1.4704e-06, 6.6680e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.2454e-01, 2.5426e-04, 3.9385e-06, 5.5043e-06, 1.4792e-05, 1.5215e-04,\n",
      "        1.3016e-04, 6.2299e-05, 2.1021e-04, 4.6227e-05, 2.8338e-06, 2.2708e-06,\n",
      "        6.9806e-04, 9.8773e-05, 1.8624e-05, 7.5019e-05, 4.0145e-06, 5.8437e-06,\n",
      "        5.2040e-04, 7.1675e-02, 5.5741e-05, 8.7695e-06, 8.0647e-05, 3.0265e-04,\n",
      "        1.1258e-04, 8.9977e-04, 1.7140e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([7.4452e-07, 3.4598e-02, 7.8648e-03, 5.9782e-02, 3.7209e-02, 1.6015e-02,\n",
      "        5.0780e-02, 1.9322e-02, 5.4211e-02, 8.0715e-02, 4.3622e-04, 1.0507e-03,\n",
      "        9.4127e-03, 7.2680e-02, 7.0160e-03, 3.7415e-02, 2.8103e-02, 1.0245e-03,\n",
      "        1.0516e-02, 2.5460e-01, 9.2680e-02, 7.5489e-03, 2.6099e-02, 9.0322e-02,\n",
      "        1.4573e-05, 5.3629e-04, 4.5489e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.6047e-04, 3.0525e-01, 2.9466e-04, 6.2160e-09, 6.2484e-08, 7.3262e-02,\n",
      "        5.3067e-06, 5.2494e-08, 1.4319e-05, 3.7571e-02, 6.5912e-07, 1.3581e-08,\n",
      "        1.2299e-06, 3.9521e-05, 1.4682e-05, 1.4077e-01, 1.1435e-03, 8.6949e-07,\n",
      "        1.7253e-04, 3.4055e-04, 2.5615e-08, 4.0127e-01, 3.2440e-06, 4.2781e-05,\n",
      "        1.2819e-06, 3.9540e-02, 1.4269e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.5147e-05, 5.6764e-04, 1.1194e-03, 1.5404e-01, 4.7317e-03, 2.0875e-04,\n",
      "        4.3617e-05, 3.1323e-05, 1.5634e-05, 7.4976e-04, 3.9107e-05, 1.2671e-05,\n",
      "        3.5809e-02, 7.4532e-04, 7.9607e-03, 3.8688e-04, 7.8195e-04, 2.9313e-06,\n",
      "        8.2924e-03, 7.6942e-01, 1.0666e-02, 1.6594e-06, 1.8298e-07, 2.1433e-04,\n",
      "        6.2564e-04, 1.4744e-04, 3.3692e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.8325e-04, 9.3839e-05, 2.9237e-05, 4.3706e-04, 2.1337e-04, 1.3105e-03,\n",
      "        3.6166e-06, 4.4717e-05, 9.6597e-01, 6.8403e-05, 3.4975e-05, 3.3911e-03,\n",
      "        1.6115e-03, 5.8002e-07, 4.0655e-05, 7.1278e-05, 2.5412e-07, 1.4033e-05,\n",
      "        2.8717e-04, 2.1196e-04, 2.5243e-02, 2.1789e-04, 1.1834e-07, 1.6373e-06,\n",
      "        7.8118e-06, 3.9507e-06, 1.0536e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9395e-01, 2.0943e-05, 1.7541e-05, 7.2786e-08, 1.5726e-07, 1.5750e-03,\n",
      "        4.7175e-06, 6.3794e-07, 1.2690e-06, 2.5716e-03, 3.6982e-08, 1.4709e-08,\n",
      "        7.0919e-05, 1.8423e-05, 5.1789e-05, 2.9174e-04, 4.0138e-07, 1.8274e-08,\n",
      "        2.2865e-04, 4.8596e-04, 2.4016e-04, 4.3794e-05, 1.6207e-08, 1.3462e-05,\n",
      "        2.6253e-08, 4.0853e-04, 1.3435e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.9462e-08, 3.5928e-01, 3.0385e-02, 6.6819e-02, 3.5718e-02, 1.9351e-02,\n",
      "        2.3620e-02, 1.0250e-02, 4.2616e-02, 6.1311e-02, 2.5800e-03, 1.1532e-03,\n",
      "        2.0829e-02, 4.6343e-02, 1.2521e-02, 7.7797e-02, 2.6230e-02, 1.3392e-03,\n",
      "        8.9620e-03, 6.5745e-02, 4.8326e-02, 5.5304e-03, 1.2232e-03, 2.8493e-02,\n",
      "        6.7444e-06, 3.5546e-03, 1.0839e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.1395e-06, 3.5308e-01, 2.3435e-06, 8.0292e-08, 1.1187e-06, 6.2749e-02,\n",
      "        5.1673e-05, 7.5939e-06, 2.2689e-06, 2.5890e-01, 7.7445e-07, 4.2603e-06,\n",
      "        2.6715e-05, 1.6366e-06, 1.8659e-07, 3.1252e-01, 2.1308e-06, 7.9441e-07,\n",
      "        2.8671e-05, 2.1570e-05, 9.8550e-08, 9.6224e-03, 1.8803e-05, 1.3511e-04,\n",
      "        2.4014e-06, 2.8220e-03, 9.1903e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.6334e-06, 2.1994e-02, 6.1442e-03, 8.8535e-03, 3.0480e-02, 1.2423e-02,\n",
      "        1.1282e-01, 1.0081e-01, 2.4601e-05, 9.4025e-05, 1.7650e-04, 3.8394e-01,\n",
      "        2.2423e-04, 3.9483e-02, 9.0756e-03, 7.4313e-04, 1.4789e-02, 7.0110e-04,\n",
      "        1.1139e-03, 1.7939e-03, 9.4087e-02, 5.1892e-05, 1.5452e-01, 1.3504e-04,\n",
      "        5.2702e-03, 3.9030e-06, 2.3658e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.9008e-05, 5.0071e-04, 4.3628e-05, 4.8536e-05, 1.4841e-06, 9.7353e-01,\n",
      "        5.8934e-04, 4.8161e-06, 1.8310e-05, 6.5226e-04, 6.7440e-07, 9.0183e-04,\n",
      "        5.1396e-05, 1.1837e-07, 9.7813e-07, 8.5552e-05, 4.4168e-05, 3.7021e-07,\n",
      "        3.8519e-05, 1.0319e-05, 2.3387e-02, 3.8617e-05, 6.3124e-06, 2.9093e-06,\n",
      "        4.1105e-07, 1.3771e-06, 3.7702e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.8960e-01, 2.8619e-05, 6.3889e-06, 1.4932e-05, 1.2895e-04, 1.7733e-05,\n",
      "        8.2809e-04, 2.4198e-06, 3.5313e-06, 1.1262e-03, 7.7205e-08, 3.7810e-07,\n",
      "        9.4912e-04, 6.3121e-06, 1.4374e-04, 6.5907e-06, 2.3692e-06, 1.3297e-06,\n",
      "        4.3918e-04, 3.9600e-03, 1.8474e-03, 2.0427e-07, 1.0034e-05, 8.6309e-04,\n",
      "        3.2910e-07, 1.5539e-05, 4.2110e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.1667e-08, 2.5017e-01, 2.9341e-02, 1.1780e-02, 1.2788e-02, 3.5568e-02,\n",
      "        2.5046e-02, 1.1822e-02, 2.8627e-02, 1.3846e-01, 1.8678e-03, 5.9950e-04,\n",
      "        2.7398e-03, 1.4812e-02, 7.4828e-03, 1.0157e-01, 1.8711e-02, 1.1516e-03,\n",
      "        2.4764e-02, 3.9920e-02, 1.9094e-01, 5.7361e-03, 5.3277e-03, 3.5085e-02,\n",
      "        4.7414e-06, 5.6535e-03, 3.8756e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.3415e-04, 4.5623e-02, 1.1235e-03, 4.2812e-03, 5.4242e-03, 6.7241e-04,\n",
      "        2.6598e-02, 3.4533e-03, 1.3917e-03, 1.1849e-03, 2.6631e-04, 7.5616e-06,\n",
      "        4.8613e-02, 1.9863e-02, 1.1836e-01, 1.0894e-03, 5.1244e-03, 1.7010e-02,\n",
      "        1.2269e-02, 6.3358e-02, 1.6772e-02, 4.7244e-02, 3.8567e-01, 2.6254e-03,\n",
      "        1.6326e-01, 8.0565e-03, 2.2669e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.7513e-03, 4.4935e-03, 7.9940e-03, 6.2227e-03, 3.5798e-04, 5.2366e-02,\n",
      "        7.2054e-03, 8.8493e-04, 2.6589e-03, 1.9329e-03, 6.2011e-05, 2.1198e-05,\n",
      "        7.5109e-04, 1.2481e-03, 1.7494e-03, 9.6980e-03, 1.1941e-03, 2.0430e-04,\n",
      "        8.4819e-01, 7.8987e-03, 3.8887e-03, 3.2811e-03, 1.7557e-02, 1.3913e-03,\n",
      "        3.5309e-04, 1.4286e-02, 3.5925e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([5.6989e-03, 5.9660e-02, 4.7590e-03, 2.1123e-04, 4.7899e-06, 7.6859e-02,\n",
      "        3.3622e-04, 5.0042e-05, 9.2402e-06, 9.5573e-02, 3.4546e-05, 1.5822e-07,\n",
      "        9.5431e-04, 1.1065e-03, 3.0302e-04, 7.4085e-01, 1.0222e-03, 2.1811e-05,\n",
      "        3.5918e-05, 7.8443e-04, 2.6559e-03, 6.1421e-03, 1.0372e-04, 6.2355e-04,\n",
      "        1.0275e-05, 2.0260e-03, 1.6177e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "nscious opposed to the instinctive in an <------ | ------>  others the tard into one much life erho\n",
      "Epoch 23   Time 61.867    Train Loss: 1.176\n",
      "Softmaxed: tensor([8.5530e-03, 5.5261e-02, 8.6448e-05, 6.8143e-03, 1.2838e-01, 2.0114e-03,\n",
      "        1.7873e-03, 7.1288e-02, 8.4362e-02, 9.4663e-03, 1.4000e-02, 3.0698e-02,\n",
      "        6.3943e-02, 1.5930e-04, 3.2397e-03, 3.1667e-02, 3.1458e-04, 1.1287e-02,\n",
      "        3.0957e-03, 3.5229e-02, 4.2305e-01, 6.7477e-03, 1.8298e-03, 3.8554e-03,\n",
      "        2.0403e-03, 7.1754e-04, 1.2050e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.0058e-02, 1.6908e-02, 7.1093e-05, 6.7002e-05, 3.8779e-05, 1.1160e-01,\n",
      "        1.3211e-04, 2.0212e-04, 7.3501e-05, 4.4547e-01, 4.9105e-05, 4.9731e-07,\n",
      "        3.8581e-02, 5.7913e-04, 1.2170e-02, 2.1701e-03, 1.8957e-03, 5.2415e-05,\n",
      "        2.2488e-03, 2.0331e-01, 5.0620e-03, 2.2296e-03, 2.0374e-06, 1.2668e-01,\n",
      "        6.7223e-05, 5.5698e-05, 2.1563e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([1.9631e-01, 1.5785e-03, 2.6336e-04, 4.8147e-03, 6.1524e-07, 4.2269e-02,\n",
      "        8.5014e-04, 6.6453e-05, 2.5979e-01, 2.0728e-01, 1.2584e-05, 4.1332e-04,\n",
      "        1.3309e-04, 5.0214e-02, 2.4160e-04, 1.4493e-02, 6.3293e-02, 8.8620e-04,\n",
      "        3.6944e-04, 1.9392e-03, 1.4256e-01, 3.1958e-03, 7.5299e-07, 8.0783e-03,\n",
      "        1.6921e-05, 8.4932e-04, 8.5696e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.0914e-01, 5.4264e-02, 1.9949e-04, 1.6013e-06, 1.6028e-06, 7.2244e-03,\n",
      "        3.5307e-03, 1.4467e-06, 1.3317e-02, 1.5901e-01, 4.8355e-06, 1.4301e-06,\n",
      "        4.7205e-04, 4.4014e-04, 1.7514e-04, 2.7418e-02, 1.7515e-04, 4.6874e-05,\n",
      "        1.8780e-01, 8.6719e-03, 1.7086e-05, 2.3421e-02, 4.8094e-06, 1.4662e-03,\n",
      "        8.3011e-07, 2.9359e-03, 2.6077e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.6208e-04, 7.6279e-06, 3.3928e-01, 2.5309e-02, 3.8163e-04, 3.3560e-06,\n",
      "        3.1579e-03, 7.8118e-04, 1.2005e-06, 3.4394e-03, 7.2992e-06, 1.7186e-05,\n",
      "        7.5735e-03, 5.0331e-03, 4.5632e-01, 1.1000e-04, 9.7415e-03, 2.5104e-05,\n",
      "        9.0082e-03, 3.2676e-04, 1.3498e-01, 8.9288e-04, 2.6686e-03, 4.6831e-05,\n",
      "        1.2115e-05, 3.2730e-05, 7.2084e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.8254e-03, 3.3375e-02, 3.0056e-05, 8.0595e-05, 6.7774e-05, 1.1002e-01,\n",
      "        7.9805e-05, 9.9037e-07, 2.8344e-03, 8.3428e-01, 1.5291e-06, 5.1243e-05,\n",
      "        6.4464e-05, 1.0241e-04, 6.3282e-03, 7.9855e-03, 1.6899e-05, 1.9031e-04,\n",
      "        1.1448e-04, 1.5825e-03, 1.3048e-04, 2.1721e-04, 4.6369e-06, 3.7059e-05,\n",
      "        1.4383e-07, 5.4520e-04, 3.1566e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998211860657\n",
      "Softmaxed: tensor([6.8979e-04, 7.5182e-03, 1.6612e-03, 7.7922e-03, 2.7181e-03, 4.9694e-03,\n",
      "        6.2290e-04, 2.7473e-05, 1.9721e-05, 1.8462e-06, 5.7988e-06, 2.4793e-06,\n",
      "        1.7490e-04, 2.0577e-03, 5.8291e-02, 8.6411e-01, 1.1129e-04, 1.4376e-04,\n",
      "        6.5782e-05, 6.3334e-03, 4.6078e-04, 8.1413e-06, 4.1783e-02, 2.1339e-05,\n",
      "        1.3253e-05, 1.0733e-07, 3.9201e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.0656e-05, 1.9533e-07, 1.5273e-07, 6.3453e-07, 1.8462e-05, 7.8668e-09,\n",
      "        4.0790e-06, 1.8411e-06, 6.5645e-10, 3.0203e-08, 9.0820e-09, 5.0338e-07,\n",
      "        2.5620e-05, 4.1765e-05, 9.9970e-01, 1.6897e-08, 3.8342e-06, 1.3353e-07,\n",
      "        2.7536e-05, 6.8876e-05, 9.1598e-06, 2.5493e-05, 7.1739e-08, 5.5547e-08,\n",
      "        9.1971e-07, 9.2545e-10, 1.2258e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3592e-01, 4.0911e-03, 9.9776e-08, 1.1436e-05, 1.0885e-03, 3.0436e-04,\n",
      "        3.6961e-06, 1.8691e-07, 7.5862e-07, 6.9053e-05, 3.2930e-08, 2.3933e-07,\n",
      "        1.9661e-05, 3.5041e-05, 1.1654e-05, 5.4551e-05, 2.5894e-07, 1.1670e-06,\n",
      "        1.9547e-07, 5.5834e-01, 1.8442e-05, 1.3340e-06, 3.0716e-08, 2.3321e-06,\n",
      "        2.7990e-07, 2.2240e-05, 9.1113e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9886e-01, 1.2776e-04, 1.8108e-06, 4.2573e-06, 1.5886e-07, 2.5776e-04,\n",
      "        6.9048e-05, 1.1340e-08, 6.6350e-05, 1.0635e-04, 2.0929e-07, 8.7531e-07,\n",
      "        1.3975e-05, 1.5814e-04, 1.0709e-05, 1.0703e-04, 5.3783e-06, 1.4059e-07,\n",
      "        5.9292e-07, 3.9255e-05, 7.7711e-05, 6.4951e-05, 1.9359e-07, 1.6604e-05,\n",
      "        1.4211e-08, 1.4252e-05, 1.4610e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([6.0508e-08, 2.0609e-01, 1.7658e-02, 1.0349e-02, 4.0384e-03, 6.4612e-03,\n",
      "        4.6630e-02, 2.3191e-03, 4.9611e-02, 1.1821e-01, 1.2483e-03, 3.1980e-04,\n",
      "        2.1160e-03, 2.5997e-03, 2.9228e-03, 1.6980e-01, 6.9681e-03, 7.1103e-04,\n",
      "        2.7004e-03, 8.4685e-02, 1.3633e-01, 6.0781e-03, 2.9691e-03, 1.1746e-01,\n",
      "        2.6946e-06, 1.7154e-03, 1.2762e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.0339e-02, 1.2014e-04, 8.3643e-05, 2.7743e-05, 5.6035e-03, 3.1853e-05,\n",
      "        2.6312e-02, 2.2062e-04, 1.0985e-04, 8.5378e-07, 6.1753e-07, 1.3019e-06,\n",
      "        3.1589e-04, 7.5174e-03, 7.4446e-01, 6.6950e-05, 2.6485e-04, 2.0032e-05,\n",
      "        2.3105e-04, 5.7993e-02, 1.3571e-01, 3.2244e-06, 4.7950e-04, 6.0227e-05,\n",
      "        2.7698e-05, 1.2368e-07, 1.0247e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.8254e-01, 4.8145e-03, 9.3109e-05, 1.7296e-02, 3.7419e-02, 4.9490e-04,\n",
      "        3.4484e-03, 4.6972e-04, 3.6425e-04, 5.6607e-05, 1.6342e-03, 1.1089e-05,\n",
      "        1.8391e-04, 2.0343e-04, 9.5533e-04, 7.7651e-05, 1.7823e-05, 1.7411e-04,\n",
      "        4.4506e-05, 1.4967e-02, 2.4999e-02, 6.4014e-04, 8.7620e-03, 1.8806e-04,\n",
      "        1.3654e-04, 4.3837e-06, 2.8895e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.2761e-04, 5.5100e-01, 2.4942e-02, 5.0349e-03, 4.2068e-04, 3.2036e-02,\n",
      "        8.5580e-05, 7.9580e-03, 6.4479e-06, 1.6818e-03, 3.4047e-06, 1.3582e-06,\n",
      "        1.3754e-02, 2.4384e-02, 3.4755e-04, 3.2236e-03, 1.5127e-01, 3.6017e-05,\n",
      "        3.3922e-02, 1.4594e-02, 1.3310e-01, 4.0654e-04, 2.6724e-05, 8.6600e-04,\n",
      "        7.4613e-04, 8.6896e-06, 2.0662e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0193e-03, 1.4689e-02, 6.5055e-04, 7.8285e-04, 3.3270e-05, 1.5934e-03,\n",
      "        2.2990e-04, 6.0380e-04, 2.1981e-03, 2.1844e-02, 7.2967e-05, 6.6186e-05,\n",
      "        1.5977e-02, 3.5989e-03, 1.9188e-05, 2.2310e-03, 1.3909e-02, 1.0249e-05,\n",
      "        4.2042e-03, 6.6015e-05, 9.0368e-01, 1.1699e-02, 1.0957e-05, 2.1379e-05,\n",
      "        5.2778e-05, 7.3078e-04, 5.7378e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.1930e-01, 1.8690e-02, 9.3703e-06, 2.6047e-05, 1.3092e-07, 3.3233e-02,\n",
      "        4.9060e-04, 2.3181e-06, 2.7712e-03, 7.4478e-01, 2.4047e-06, 1.2728e-07,\n",
      "        1.1637e-03, 3.3319e-05, 2.6767e-06, 5.1910e-03, 3.9802e-06, 3.0565e-06,\n",
      "        5.0974e-04, 4.7652e-03, 1.0219e-04, 2.7011e-03, 6.6525e-07, 5.4248e-04,\n",
      "        5.6958e-07, 6.5660e-02, 9.6576e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.3278e-03, 3.0352e-02, 3.6719e-02, 8.7799e-02, 3.4370e-03, 8.2705e-03,\n",
      "        1.6398e-02, 1.1079e-02, 7.3268e-04, 1.0297e-04, 3.2202e-05, 5.0459e-05,\n",
      "        9.2902e-03, 1.2145e-02, 9.3820e-02, 6.3261e-01, 5.9975e-03, 6.7155e-04,\n",
      "        3.0208e-03, 4.8168e-03, 5.4527e-03, 5.2915e-05, 3.4641e-02, 4.4639e-05,\n",
      "        1.1271e-04, 1.4712e-07, 1.0200e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.4847e-04, 5.3568e-03, 8.3839e-05, 1.7355e-06, 1.0211e-05, 3.1705e-03,\n",
      "        1.6790e-06, 5.3882e-04, 2.6614e-06, 3.5055e-02, 7.8977e-06, 9.7843e-06,\n",
      "        9.3182e-01, 2.1918e-04, 2.3404e-03, 4.6150e-03, 5.8526e-06, 2.0405e-06,\n",
      "        6.5229e-03, 2.7324e-03, 2.2040e-04, 6.0010e-03, 2.3270e-07, 1.5605e-06,\n",
      "        2.7497e-05, 5.0328e-04, 4.4002e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.1725e-05, 2.0158e-03, 3.5192e-06, 6.1602e-07, 4.1329e-06, 8.6679e-01,\n",
      "        1.2478e-06, 2.0425e-08, 6.7643e-08, 1.9833e-02, 1.0446e-07, 2.4341e-08,\n",
      "        2.3736e-04, 1.5144e-05, 8.6340e-06, 1.2223e-03, 9.7393e-08, 4.1673e-08,\n",
      "        5.6926e-07, 2.8431e-04, 2.5321e-06, 1.9625e-04, 3.5845e-07, 2.0476e-06,\n",
      "        6.3861e-08, 1.0936e-01, 7.2484e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9739e-01, 1.1939e-05, 8.6821e-07, 4.5484e-07, 1.8233e-04, 2.8733e-06,\n",
      "        8.5766e-07, 3.4680e-07, 2.8036e-08, 9.9423e-07, 3.5200e-09, 1.8521e-08,\n",
      "        1.2032e-05, 4.4020e-06, 2.2851e-04, 1.5726e-06, 5.5050e-08, 1.6815e-08,\n",
      "        1.2745e-06, 2.1504e-03, 6.0827e-06, 1.5631e-06, 3.1383e-07, 6.2001e-07,\n",
      "        6.4543e-07, 3.1927e-07, 6.3947e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.3744e-08, 1.6456e-01, 4.1803e-02, 2.7131e-02, 3.0328e-02, 4.4620e-02,\n",
      "        4.5630e-02, 8.6664e-03, 4.2233e-02, 7.9436e-02, 2.7771e-03, 2.2609e-03,\n",
      "        6.7661e-03, 2.6345e-02, 1.3820e-02, 7.8961e-02, 1.7227e-02, 1.3385e-03,\n",
      "        1.4113e-02, 3.6982e-02, 2.5580e-01, 9.2159e-03, 3.5195e-03, 4.2096e-02,\n",
      "        5.4433e-06, 4.2794e-03, 8.8021e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.5072e-05, 1.1394e-02, 3.3402e-06, 5.1805e-08, 1.8282e-08, 5.9053e-03,\n",
      "        3.3886e-05, 9.7925e-07, 3.8530e-01, 1.9845e-02, 3.2641e-07, 5.9346e-07,\n",
      "        1.2520e-04, 7.1353e-06, 4.3213e-06, 5.5335e-01, 8.8296e-08, 8.6231e-07,\n",
      "        1.7330e-02, 1.9119e-05, 1.8561e-06, 1.7573e-03, 8.0611e-08, 2.8125e-03,\n",
      "        4.0196e-08, 2.0784e-03, 3.7694e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.3564e-01, 4.3817e-04, 3.5193e-05, 1.4948e-05, 2.9706e-03, 2.0103e-03,\n",
      "        1.1690e-04, 4.9629e-03, 4.1197e-04, 5.9143e-04, 1.0213e-05, 3.1513e-04,\n",
      "        1.9402e-03, 5.5799e-04, 1.2124e-03, 3.1894e-02, 1.6733e-05, 1.3826e-06,\n",
      "        1.7258e-03, 2.7820e-04, 3.4252e-05, 3.9783e-03, 1.7569e-04, 1.0281e-02,\n",
      "        3.8346e-04, 2.9318e-06, 3.1060e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.8875e-07, 4.6151e-02, 7.2690e-02, 4.1590e-02, 5.1490e-02, 2.7181e-02,\n",
      "        2.6773e-02, 2.9248e-02, 5.6042e-02, 3.7922e-02, 4.1716e-03, 5.5693e-03,\n",
      "        2.1815e-02, 5.9655e-02, 9.7221e-03, 2.0927e-02, 5.1586e-02, 1.3409e-03,\n",
      "        2.4490e-02, 1.1130e-01, 2.3369e-01, 6.3644e-03, 3.4937e-03, 5.0792e-02,\n",
      "        4.5085e-05, 5.9227e-03, 1.9529e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([3.5083e-05, 1.9104e-02, 4.6410e-06, 4.3529e-07, 6.3485e-08, 3.1814e-02,\n",
      "        3.4719e-05, 3.8156e-05, 8.5040e-01, 2.8086e-03, 2.0967e-06, 8.4432e-05,\n",
      "        3.8798e-04, 1.0660e-04, 3.1496e-06, 1.5222e-02, 7.6190e-07, 2.1464e-06,\n",
      "        5.1193e-02, 5.6547e-05, 4.7332e-06, 1.9330e-02, 1.3798e-06, 9.1543e-03,\n",
      "        3.3917e-07, 2.0240e-04, 2.9441e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.9682e-06, 3.5033e-02, 1.0047e-07, 9.6043e-10, 2.7377e-08, 8.5908e-01,\n",
      "        2.6180e-07, 3.7839e-07, 2.6769e-06, 8.8047e-02, 4.5291e-07, 1.5456e-07,\n",
      "        1.0767e-06, 1.7158e-05, 8.9801e-06, 1.6007e-02, 1.3551e-07, 3.9654e-08,\n",
      "        7.9630e-04, 4.3471e-06, 1.9481e-06, 6.1518e-04, 2.6150e-09, 5.6627e-05,\n",
      "        3.0256e-07, 3.2020e-04, 3.6188e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([6.9408e-01, 1.0631e-04, 7.9445e-06, 3.4975e-06, 7.2652e-06, 2.4908e-03,\n",
      "        5.6975e-05, 8.8579e-04, 3.8988e-03, 1.0358e-01, 2.6015e-05, 2.8399e-05,\n",
      "        2.3407e-04, 8.3232e-02, 1.2902e-02, 9.0214e-04, 6.0233e-04, 5.2540e-06,\n",
      "        3.7090e-02, 3.7626e-02, 5.8557e-04, 4.5692e-06, 8.3683e-05, 3.0270e-03,\n",
      "        9.3213e-05, 1.8367e-02, 7.8307e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([1.4578e-03, 1.8273e-06, 1.3120e-04, 6.8306e-05, 2.8388e-04, 6.3788e-05,\n",
      "        1.1971e-04, 1.3703e-03, 5.9220e-05, 7.6357e-07, 5.8846e-07, 3.3474e-06,\n",
      "        1.2183e-03, 1.5183e-04, 3.9741e-03, 7.6865e-06, 1.2120e-05, 1.3064e-07,\n",
      "        9.8614e-01, 4.5002e-03, 8.6903e-05, 3.8526e-06, 2.9729e-05, 4.7337e-06,\n",
      "        7.4396e-06, 7.8679e-08, 3.0120e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9764e-01, 2.4589e-06, 7.6962e-07, 8.5128e-06, 2.2915e-05, 2.2166e-04,\n",
      "        1.4045e-05, 2.8106e-06, 3.8932e-05, 5.0468e-06, 7.1156e-08, 4.3189e-06,\n",
      "        1.9207e-05, 3.2876e-04, 7.1304e-06, 1.0626e-05, 5.3399e-08, 9.5127e-08,\n",
      "        9.6705e-05, 1.5605e-03, 1.5696e-06, 1.4686e-07, 2.0877e-06, 7.0529e-06,\n",
      "        6.3801e-07, 1.5546e-06, 2.5432e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([5.5348e-07, 4.5018e-02, 3.8739e-02, 7.3586e-02, 3.8329e-02, 3.4340e-02,\n",
      "        9.8521e-02, 4.2631e-02, 3.0245e-02, 5.1620e-02, 1.1760e-02, 1.4730e-02,\n",
      "        1.7564e-02, 5.9480e-02, 6.1422e-02, 4.6098e-02, 6.6981e-02, 3.1754e-03,\n",
      "        3.8326e-02, 1.0902e-01, 1.0928e-02, 1.7928e-02, 2.9797e-02, 5.6756e-02,\n",
      "        3.0608e-05, 2.8688e-03, 1.0868e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.8101e-05, 2.3461e-01, 4.0691e-04, 6.5482e-03, 4.0025e-03, 1.6624e-03,\n",
      "        1.0812e-02, 8.5279e-03, 3.5102e-04, 2.3315e-03, 1.8779e-04, 3.6213e-05,\n",
      "        3.4535e-02, 8.8500e-02, 1.6137e-01, 1.1781e-03, 6.0459e-03, 5.5871e-03,\n",
      "        1.1748e-02, 4.7145e-02, 1.3197e-02, 3.3318e-02, 3.1658e-02, 5.8907e-03,\n",
      "        2.4776e-01, 4.2498e-02, 5.8304e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8222e-04, 2.3965e-07, 2.5480e-04, 6.4172e-02, 2.5723e-03, 3.4887e-05,\n",
      "        3.6105e-04, 1.3540e-02, 4.1096e-05, 1.5976e-04, 1.6464e-04, 2.1206e-03,\n",
      "        8.9755e-03, 3.5493e-03, 4.0735e-04, 1.0412e-06, 6.6911e-03, 1.0251e-04,\n",
      "        7.1872e-01, 1.5649e-01, 1.6510e-02, 1.7896e-03, 2.3856e-03, 1.7931e-04,\n",
      "        3.1125e-04, 1.9163e-04, 9.2639e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2392e-01, 8.1169e-04, 7.7102e-03, 3.4883e-03, 3.5565e-04, 9.9082e-03,\n",
      "        1.5147e-02, 1.1934e-03, 9.3024e-04, 7.6727e-03, 2.3008e-05, 2.0810e-03,\n",
      "        6.8394e-02, 5.7348e-02, 1.2946e-01, 3.1820e-03, 7.3060e-03, 1.2125e-05,\n",
      "        1.1501e-02, 1.2592e-01, 3.0487e-01, 1.4486e-04, 9.0572e-04, 1.5290e-02,\n",
      "        2.8804e-04, 2.0439e-03, 9.4703e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.7575e-01, 2.2039e-04, 8.6266e-05, 5.0976e-05, 2.9495e-07, 1.0885e-04,\n",
      "        9.5775e-05, 1.9221e-06, 5.2581e-03, 9.0647e-04, 1.4972e-07, 1.6325e-05,\n",
      "        2.6603e-05, 1.4451e-03, 1.8897e-04, 8.1280e-04, 6.8447e-05, 6.0864e-06,\n",
      "        9.2653e-05, 4.3611e-04, 1.3962e-02, 9.7061e-05, 6.2518e-08, 6.4806e-06,\n",
      "        1.1802e-07, 3.5656e-04, 1.4781e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([4.1321e-08, 2.6368e-01, 1.7789e-02, 1.1754e-02, 1.2173e-02, 1.4430e-02,\n",
      "        8.5069e-02, 6.4711e-03, 4.6015e-02, 8.2267e-02, 2.6728e-03, 1.0028e-03,\n",
      "        1.3275e-02, 1.7626e-02, 1.1515e-02, 9.9944e-02, 1.1617e-02, 7.7958e-04,\n",
      "        6.7789e-03, 2.6215e-02, 1.9170e-01, 6.9172e-03, 3.0955e-03, 6.6492e-02,\n",
      "        3.2114e-06, 6.9779e-04, 1.4370e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.5023e-02, 1.9129e-05, 1.5475e-02, 1.7260e-02, 3.0201e-03, 4.3745e-06,\n",
      "        1.0252e-02, 9.4193e-03, 1.2394e-04, 2.4173e-04, 6.8173e-06, 6.7478e-05,\n",
      "        3.0370e-02, 6.5399e-03, 5.8214e-01, 6.2652e-06, 3.9413e-03, 2.4274e-05,\n",
      "        5.5248e-02, 1.2555e-01, 4.1036e-02, 7.8401e-04, 6.2361e-04, 2.6568e-03,\n",
      "        8.9531e-05, 7.5056e-05, 9.7709e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([6.1127e-02, 7.9008e-04, 4.1733e-05, 7.8303e-04, 9.2094e-01, 3.8199e-05,\n",
      "        3.5892e-05, 8.2159e-05, 1.2960e-05, 4.1888e-04, 2.1426e-04, 3.6037e-04,\n",
      "        9.3602e-04, 6.7011e-05, 2.2974e-04, 3.9097e-03, 5.3025e-07, 6.3251e-06,\n",
      "        5.2410e-06, 6.2457e-04, 2.2830e-03, 4.4200e-06, 7.5746e-04, 3.8567e-04,\n",
      "        7.9164e-04, 5.1452e-03, 7.8544e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9985e-01, 4.2000e-06, 5.7180e-08, 3.5284e-09, 1.7013e-07, 1.4525e-06,\n",
      "        1.1669e-06, 8.8365e-07, 6.9069e-08, 4.3654e-05, 2.8424e-08, 6.2915e-08,\n",
      "        4.0410e-05, 4.0702e-06, 1.9333e-05, 4.4674e-06, 4.5994e-08, 1.8720e-08,\n",
      "        6.9438e-07, 1.4894e-06, 2.9883e-07, 2.0249e-07, 2.2904e-08, 2.2465e-05,\n",
      "        7.1088e-07, 8.1705e-06, 5.6367e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.6902e-07, 8.1596e-02, 2.5254e-02, 6.3813e-02, 6.4249e-02, 5.3046e-02,\n",
      "        4.1796e-02, 1.7104e-02, 5.2091e-02, 9.8343e-02, 5.7382e-03, 4.8896e-03,\n",
      "        1.7505e-02, 4.0963e-02, 3.6092e-02, 2.0883e-02, 4.7495e-02, 2.1248e-03,\n",
      "        3.5709e-02, 7.6131e-02, 1.4748e-01, 6.7327e-03, 1.0166e-02, 4.9760e-02,\n",
      "        2.2006e-05, 9.4629e-04, 7.6477e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.1193e-05, 1.1232e-01, 1.8818e-05, 8.7821e-07, 1.8032e-08, 3.1827e-01,\n",
      "        9.0345e-07, 3.4774e-06, 2.2760e-01, 2.3512e-01, 1.4870e-06, 2.4110e-05,\n",
      "        5.6917e-05, 4.9314e-04, 5.8890e-05, 9.8282e-02, 2.1094e-07, 1.0351e-06,\n",
      "        7.2821e-03, 1.7607e-05, 1.0455e-04, 4.9746e-05, 5.3150e-08, 1.3315e-04,\n",
      "        3.3925e-06, 1.3812e-04, 5.1372e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      " is as error but which is merely the syn <------ | ------> kstations inuptible to their ears and wo\n",
      "Epoch 24   Time 61.692    Train Loss: 1.171\n",
      "Softmaxed: tensor([3.4578e-05, 8.3939e-04, 5.4872e-04, 1.6367e-03, 4.3428e-02, 2.4805e-05,\n",
      "        9.7096e-05, 2.8546e-03, 2.1472e-04, 1.3826e-04, 7.6752e-05, 1.5750e-04,\n",
      "        2.6443e-02, 1.3260e-02, 7.8728e-04, 4.3127e-03, 2.1039e-04, 3.1848e-05,\n",
      "        4.7292e-01, 3.9095e-01, 1.6255e-02, 7.1779e-03, 7.4257e-03, 8.3538e-03,\n",
      "        1.0931e-03, 1.7427e-04, 5.4966e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.1141e-05, 3.3832e-01, 6.1196e-04, 6.8750e-05, 9.0575e-04, 5.8198e-01,\n",
      "        4.5355e-05, 3.1876e-04, 2.2221e-05, 1.3745e-03, 4.9875e-06, 6.9437e-04,\n",
      "        8.1442e-04, 5.5478e-04, 1.4857e-02, 8.7186e-05, 2.1121e-04, 6.1573e-06,\n",
      "        3.8764e-02, 9.6236e-04, 1.8592e-02, 5.9442e-04, 2.9208e-05, 2.1297e-05,\n",
      "        2.1563e-05, 1.1163e-04, 3.8825e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([9.6322e-05, 9.3037e-06, 1.5233e-04, 2.8107e-04, 4.0327e-04, 4.6393e-07,\n",
      "        2.7236e-07, 2.1625e-05, 5.6732e-08, 5.3092e-05, 3.6739e-06, 3.0216e-07,\n",
      "        9.9575e-01, 2.7605e-05, 4.8553e-04, 2.0272e-06, 2.1182e-05, 1.2476e-06,\n",
      "        9.0907e-06, 2.3477e-04, 2.3024e-03, 1.0474e-04, 2.6101e-05, 1.5666e-06,\n",
      "        6.1769e-06, 2.6017e-06, 5.3891e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.8383e-01, 1.2838e-04, 7.2254e-04, 1.0438e-04, 8.7058e-06, 5.6705e-04,\n",
      "        8.3515e-04, 3.2276e-06, 2.5172e-06, 7.0045e-01, 1.0211e-06, 1.2248e-06,\n",
      "        1.6561e-02, 7.8186e-04, 4.0066e-04, 2.9051e-03, 2.7927e-04, 2.6983e-06,\n",
      "        1.1163e-03, 8.7758e-02, 1.1420e-03, 4.9884e-04, 2.1721e-04, 7.6477e-04,\n",
      "        1.0510e-05, 8.7777e-04, 2.9383e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.1632e-04, 6.3022e-03, 2.6424e-04, 1.9822e-03, 1.0219e-04, 1.4279e-03,\n",
      "        3.8320e-03, 9.5052e-05, 2.7976e-05, 2.8652e-05, 7.0242e-07, 1.0089e-05,\n",
      "        8.1457e-04, 3.6431e-06, 3.2722e-03, 1.1659e-03, 9.3870e-05, 7.8392e-05,\n",
      "        7.2851e-05, 8.7603e-02, 8.6128e-01, 5.4947e-06, 3.5187e-04, 2.8889e-05,\n",
      "        2.8276e-05, 1.1472e-04, 3.0700e-02], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([1.2707e-04, 1.9146e-03, 2.9550e-06, 1.2597e-07, 4.3443e-08, 1.2120e-04,\n",
      "        1.0575e-05, 9.8311e-07, 4.1939e-06, 5.7039e-02, 4.0280e-08, 1.1943e-07,\n",
      "        6.3116e-06, 2.2449e-07, 2.8584e-06, 4.3906e-05, 3.8423e-08, 3.1766e-08,\n",
      "        3.8212e-06, 3.8681e-04, 7.6232e-06, 1.2708e-03, 1.6589e-08, 3.1918e-07,\n",
      "        3.4471e-08, 9.3906e-01, 8.1594e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([9.9970e-01, 2.1282e-06, 5.9828e-07, 4.1089e-07, 6.2555e-08, 7.9814e-07,\n",
      "        2.2121e-06, 9.6642e-09, 4.8547e-08, 4.4158e-05, 1.5211e-09, 3.1503e-10,\n",
      "        1.1456e-05, 6.6769e-06, 8.8122e-06, 3.1682e-05, 1.3573e-07, 4.7566e-09,\n",
      "        3.9981e-06, 1.8658e-04, 8.6760e-07, 1.8882e-06, 3.4172e-08, 8.7280e-07,\n",
      "        5.0933e-09, 2.1113e-08, 1.4263e-09], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.4626e-08, 1.7554e-01, 4.2279e-02, 2.3781e-02, 8.3957e-03, 3.5692e-02,\n",
      "        3.3604e-02, 2.4657e-03, 1.7758e-02, 1.6230e-01, 2.4064e-03, 3.2191e-04,\n",
      "        2.1355e-02, 3.1604e-02, 2.2090e-02, 1.5930e-01, 7.2604e-03, 4.8581e-04,\n",
      "        2.1407e-02, 2.9325e-02, 1.2524e-01, 5.6119e-03, 3.1044e-03, 6.4741e-02,\n",
      "        4.2552e-06, 3.8798e-03, 4.9108e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([2.1714e-06, 2.5233e-01, 7.3439e-07, 9.9187e-08, 5.9319e-07, 2.3399e-01,\n",
      "        7.2699e-05, 2.4252e-06, 7.5516e-06, 2.6701e-01, 7.2490e-07, 1.0610e-05,\n",
      "        1.0226e-04, 4.1690e-07, 1.2266e-07, 2.3330e-01, 1.4880e-06, 8.4584e-07,\n",
      "        6.4797e-05, 1.3339e-05, 1.0275e-07, 9.4646e-03, 4.0065e-05, 1.5548e-04,\n",
      "        1.0387e-06, 3.4278e-03, 8.2900e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.4742e-02, 2.3462e-04, 7.3999e-02, 1.4828e-01, 9.2247e-04, 1.2885e-03,\n",
      "        5.8271e-03, 1.0670e-02, 1.0728e-04, 4.2403e-02, 1.9098e-03, 1.0591e-02,\n",
      "        6.0950e-03, 3.1096e-02, 7.3451e-02, 1.3058e-04, 8.4058e-03, 3.9289e-04,\n",
      "        9.2757e-03, 1.2035e-01, 1.9806e-01, 9.0356e-02, 1.2666e-02, 7.8962e-02,\n",
      "        3.0229e-03, 1.2699e-02, 4.0637e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.1005e-02, 5.7578e-03, 4.9586e-05, 2.5095e-02, 1.0354e-04, 3.9673e-02,\n",
      "        7.7925e-03, 1.0671e-03, 8.3125e-02, 2.3800e-01, 1.1650e-04, 2.7996e-02,\n",
      "        3.7192e-03, 1.0848e-03, 7.9378e-05, 1.8699e-02, 1.1356e-02, 3.7699e-04,\n",
      "        1.0173e-03, 1.2560e-01, 7.2310e-02, 2.7019e-01, 3.2410e-04, 1.4262e-03,\n",
      "        7.2365e-05, 1.3893e-02, 7.0709e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([2.5142e-04, 7.0854e-02, 2.1176e-04, 5.5168e-03, 9.9537e-03, 7.0301e-03,\n",
      "        1.1869e-03, 3.9617e-01, 1.3299e-05, 1.0492e-02, 1.1157e-05, 2.4836e-05,\n",
      "        2.9897e-01, 6.5757e-03, 1.5603e-03, 9.1980e-04, 2.3872e-03, 5.9816e-06,\n",
      "        1.5539e-01, 3.0622e-02, 9.3389e-04, 3.0332e-04, 2.4475e-05, 1.9192e-04,\n",
      "        3.3764e-04, 3.6982e-05, 2.6742e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3714e-03, 4.8264e-01, 3.4996e-03, 8.4372e-05, 3.5708e-02, 1.8590e-01,\n",
      "        6.9304e-04, 1.0866e-01, 1.2540e-02, 9.7427e-02, 2.6662e-04, 4.7108e-05,\n",
      "        2.6409e-02, 2.8425e-03, 3.4983e-03, 5.3903e-03, 4.7336e-05, 4.5786e-05,\n",
      "        5.6176e-03, 6.9119e-03, 9.5271e-04, 1.0594e-02, 1.1126e-04, 4.9779e-04,\n",
      "        1.6095e-04, 5.9953e-03, 8.4496e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.1275e-02, 4.4885e-02, 1.0362e-03, 4.3091e-05, 1.1188e-03, 1.6504e-01,\n",
      "        5.1024e-03, 5.3972e-06, 3.3421e-05, 2.0012e-02, 7.8087e-06, 1.2851e-07,\n",
      "        6.3685e-03, 6.6098e-04, 2.6412e-03, 1.1481e-01, 7.7183e-05, 4.8490e-06,\n",
      "        2.1191e-03, 6.9713e-02, 4.9556e-01, 1.1234e-02, 3.8350e-04, 4.0068e-04,\n",
      "        7.4129e-05, 1.7354e-02, 3.5521e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.1999e-03, 1.6333e-03, 1.8108e-03, 1.0499e-03, 2.3567e-03, 2.2520e-04,\n",
      "        7.8502e-04, 1.5881e-04, 5.9492e-06, 3.0477e-04, 3.7781e-05, 2.2105e-05,\n",
      "        1.3051e-01, 1.0168e-02, 6.3999e-03, 1.7988e-03, 4.8852e-02, 1.1027e-05,\n",
      "        5.4810e-02, 1.0574e-02, 5.8136e-02, 6.4417e-01, 1.6435e-02, 2.3236e-03,\n",
      "        1.8033e-03, 1.6699e-05, 3.9922e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.4276e-05, 5.0077e-01, 1.1021e-04, 7.0649e-06, 1.2474e-03, 1.6471e-01,\n",
      "        2.7008e-04, 2.9209e-06, 9.7973e-06, 1.1364e-02, 1.4050e-06, 2.0710e-07,\n",
      "        2.3145e-03, 2.1467e-04, 3.3724e-04, 3.0201e-01, 2.2914e-05, 1.3852e-05,\n",
      "        1.7887e-06, 7.0782e-03, 1.9600e-04, 3.1167e-03, 1.5942e-04, 2.0246e-04,\n",
      "        9.0605e-06, 5.7706e-03, 2.1618e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([8.1864e-03, 2.9788e-04, 2.6887e-04, 5.0609e-04, 1.0101e-02, 2.8478e-03,\n",
      "        6.4578e-04, 5.7873e-01, 1.4017e-04, 2.9862e-04, 1.9001e-04, 1.9943e-04,\n",
      "        8.9851e-03, 7.2665e-03, 5.6375e-04, 7.5756e-02, 3.3358e-03, 4.2082e-04,\n",
      "        4.0525e-03, 6.5005e-02, 8.4688e-02, 3.7659e-03, 5.3071e-02, 7.3296e-02,\n",
      "        1.5910e-02, 2.1305e-04, 1.2592e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.5355e-03, 6.0405e-04, 1.9898e-04, 1.1622e-06, 3.4420e-04, 2.6553e-03,\n",
      "        3.7085e-04, 1.7823e-06, 2.4672e-03, 1.6926e-01, 5.9466e-06, 8.7546e-06,\n",
      "        4.5216e-05, 1.4039e-04, 4.5277e-06, 1.8656e-01, 6.9529e-06, 8.5303e-06,\n",
      "        4.5189e-04, 5.3520e-03, 1.3018e-03, 2.8668e-04, 9.4197e-05, 2.2179e-04,\n",
      "        1.6558e-06, 6.2150e-01, 5.6325e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([9.9943e-01, 9.3622e-06, 3.2715e-06, 2.3989e-07, 8.0344e-08, 5.4960e-06,\n",
      "        1.8156e-06, 2.1738e-07, 1.6737e-07, 1.7160e-05, 7.3931e-09, 1.2778e-09,\n",
      "        9.5292e-06, 6.0845e-05, 1.0802e-04, 1.0595e-04, 6.3651e-06, 1.1355e-07,\n",
      "        5.0811e-06, 2.3096e-04, 4.0146e-06, 4.5735e-06, 5.9089e-07, 4.0048e-07,\n",
      "        1.0045e-07, 1.0862e-08, 1.3165e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([2.3398e-08, 1.9916e-01, 1.7620e-02, 2.3482e-02, 1.1217e-02, 1.5394e-02,\n",
      "        1.6959e-02, 7.4447e-03, 3.5995e-02, 1.4192e-01, 1.5800e-03, 1.1055e-03,\n",
      "        1.7715e-02, 7.4138e-02, 2.2475e-02, 1.3815e-01, 3.1186e-02, 7.6656e-04,\n",
      "        2.0739e-02, 5.1549e-02, 1.0974e-01, 1.1523e-02, 2.5057e-03, 4.6290e-02,\n",
      "        3.5083e-06, 1.3201e-03, 2.7636e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.1458e-02, 1.4931e-04, 8.1576e-05, 3.5103e-05, 8.7156e-03, 9.2884e-05,\n",
      "        1.8196e-02, 5.1401e-04, 1.6099e-04, 1.9920e-06, 1.2564e-06, 1.2220e-06,\n",
      "        2.5393e-03, 2.7277e-02, 3.2397e-01, 1.2128e-04, 5.2280e-04, 5.0541e-05,\n",
      "        3.0853e-04, 3.5383e-01, 2.3148e-01, 2.8681e-06, 3.3404e-04, 1.1995e-04,\n",
      "        3.5087e-05, 1.6018e-07, 6.3143e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([7.6211e-01, 4.3260e-03, 1.4683e-04, 2.9613e-02, 5.4706e-02, 4.7045e-04,\n",
      "        7.7615e-03, 1.0026e-03, 6.5122e-04, 8.0215e-05, 3.5457e-03, 1.8956e-05,\n",
      "        5.0068e-04, 3.9092e-04, 2.7396e-03, 1.1850e-04, 3.4909e-05, 5.0608e-04,\n",
      "        1.3530e-04, 4.8296e-02, 6.6627e-02, 7.3374e-04, 1.4943e-02, 2.6959e-04,\n",
      "        2.6683e-04, 5.2215e-06, 3.9683e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0743e-08, 1.0074e-01, 1.3032e-02, 3.2227e-02, 1.5301e-02, 4.4169e-02,\n",
      "        9.2589e-03, 9.5512e-03, 3.0175e-02, 2.9630e-02, 2.7077e-03, 1.1855e-04,\n",
      "        1.3474e-02, 3.4570e-02, 5.8333e-03, 1.9549e-02, 2.1449e-02, 2.5753e-03,\n",
      "        4.3058e-02, 6.4028e-02, 4.4935e-01, 6.8872e-03, 8.3084e-03, 4.3406e-02,\n",
      "        2.9167e-05, 4.9404e-04, 7.7381e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([8.8879e-08, 7.4099e-04, 7.2176e-08, 9.5228e-09, 1.3005e-09, 5.9209e-04,\n",
      "        6.0629e-07, 1.1311e-06, 9.9233e-01, 5.3725e-04, 4.1718e-08, 1.1208e-06,\n",
      "        1.1948e-05, 7.8844e-07, 5.1333e-08, 2.0077e-03, 2.0449e-08, 5.6180e-07,\n",
      "        3.0471e-03, 1.6013e-06, 5.7204e-07, 2.3059e-04, 1.9430e-08, 4.6316e-04,\n",
      "        3.6602e-09, 3.4167e-05, 2.0492e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([2.8769e-07, 2.7878e-01, 5.4472e-05, 1.3406e-07, 8.2467e-06, 4.6201e-02,\n",
      "        2.1623e-07, 4.3188e-06, 1.0521e-05, 2.9540e-02, 1.1896e-05, 1.9286e-05,\n",
      "        4.6030e-06, 1.5454e-05, 4.6020e-06, 1.4652e-02, 1.1489e-06, 6.7343e-07,\n",
      "        1.9968e-04, 4.5452e-07, 3.0874e-06, 6.2959e-01, 1.8353e-07, 6.9418e-06,\n",
      "        5.4768e-06, 8.8452e-04, 6.4139e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.4425e-04, 7.1709e-05, 5.9864e-03, 2.6908e-02, 1.9991e-01, 4.9409e-03,\n",
      "        9.3297e-04, 1.1024e-01, 1.1073e-05, 1.4839e-01, 1.3962e-03, 8.8249e-04,\n",
      "        5.2696e-03, 1.6586e-02, 1.0352e-01, 6.8889e-05, 4.1072e-04, 1.0422e-04,\n",
      "        1.9328e-03, 1.2917e-02, 5.4963e-02, 4.5832e-03, 1.7735e-01, 1.0607e-03,\n",
      "        7.6021e-04, 1.1912e-01, 1.4454e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "Softmaxed: tensor([3.1616e-05, 2.4062e-03, 1.6623e-04, 2.9439e-02, 5.4289e-04, 5.9840e-01,\n",
      "        8.5069e-05, 1.9374e-03, 2.0252e-02, 8.9179e-02, 6.7055e-05, 1.2346e-01,\n",
      "        2.0838e-02, 2.2328e-04, 1.8289e-04, 2.0206e-02, 2.8837e-05, 6.9614e-04,\n",
      "        4.8650e-03, 1.6373e-04, 6.7382e-02, 1.5733e-02, 6.8378e-05, 2.1054e-04,\n",
      "        5.9263e-06, 3.3229e-03, 1.0606e-04], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([3.3707e-02, 1.7427e-02, 5.8867e-05, 2.2827e-05, 4.1316e-07, 5.4635e-01,\n",
      "        2.1802e-03, 3.0697e-06, 1.9868e-04, 2.6392e-01, 3.0455e-06, 1.5317e-05,\n",
      "        8.7847e-02, 1.2662e-04, 5.7299e-06, 1.9910e-02, 1.0153e-05, 7.5802e-06,\n",
      "        2.5753e-03, 1.5441e-02, 1.8632e-05, 5.1060e-03, 2.1210e-06, 1.5491e-03,\n",
      "        7.5916e-07, 3.4786e-03, 4.0671e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([4.7465e-04, 9.3425e-03, 1.8929e-06, 2.1903e-07, 3.7928e-07, 2.2188e-01,\n",
      "        8.5877e-05, 1.9634e-08, 7.8672e-08, 5.2023e-03, 7.0101e-07, 2.9610e-07,\n",
      "        1.9198e-04, 1.2572e-05, 1.9944e-06, 4.6610e-02, 1.7026e-07, 9.4576e-08,\n",
      "        5.3417e-06, 6.4265e-06, 2.1401e-06, 1.1700e-03, 3.4454e-05, 5.6138e-06,\n",
      "        2.2896e-07, 7.1497e-01, 5.5644e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([9.9894e-01, 4.0128e-06, 4.1152e-06, 7.0157e-07, 7.4178e-08, 3.9493e-06,\n",
      "        7.8323e-06, 3.8068e-07, 2.4168e-07, 2.2298e-04, 1.3639e-07, 1.3453e-07,\n",
      "        1.3032e-04, 2.1934e-05, 1.2324e-04, 3.6423e-05, 3.6998e-06, 3.2972e-08,\n",
      "        9.3034e-06, 2.8227e-04, 1.9550e-06, 1.3110e-04, 4.0405e-07, 3.0489e-05,\n",
      "        1.6600e-06, 3.8682e-05, 6.4670e-07], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.000000238418579\n",
      "Softmaxed: tensor([4.9320e-08, 2.2111e-01, 5.3277e-02, 1.5116e-02, 3.5662e-02, 5.9068e-02,\n",
      "        2.0271e-02, 1.7749e-02, 8.3891e-03, 6.4750e-02, 1.7836e-03, 1.9577e-03,\n",
      "        5.0887e-02, 7.3548e-02, 3.2522e-02, 3.4267e-02, 2.6336e-02, 4.7499e-04,\n",
      "        9.0741e-02, 4.3640e-02, 8.6195e-02, 1.9724e-02, 4.0237e-03, 3.5790e-02,\n",
      "        1.4415e-05, 2.6643e-03, 3.7000e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([2.2260e-08, 6.0223e-02, 1.1026e-05, 2.6456e-07, 4.8999e-08, 7.8654e-01,\n",
      "        2.5542e-07, 4.6293e-06, 6.7872e-05, 4.2981e-02, 2.0270e-07, 4.4954e-08,\n",
      "        2.1527e-05, 3.2866e-07, 1.0120e-04, 4.9626e-02, 5.6749e-08, 2.7147e-07,\n",
      "        3.8760e-06, 4.1225e-07, 6.4783e-08, 5.9817e-02, 4.7905e-07, 1.5436e-05,\n",
      "        4.5424e-07, 5.8205e-04, 7.4568e-09], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([5.7232e-04, 1.8545e-01, 7.1335e-03, 4.4641e-02, 1.8766e-03, 2.3119e-04,\n",
      "        4.2964e-02, 9.8133e-02, 6.4999e-04, 1.6812e-03, 4.0371e-03, 1.7756e-05,\n",
      "        3.5948e-01, 3.6171e-02, 2.0167e-02, 8.1559e-04, 1.9722e-02, 1.7755e-02,\n",
      "        5.1298e-03, 9.5439e-02, 1.9273e-02, 4.4702e-04, 3.6175e-02, 1.6131e-03,\n",
      "        2.0917e-04, 1.9749e-04, 2.1767e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([2.9647e-07, 9.3585e-01, 9.8043e-06, 1.0799e-06, 2.6374e-05, 1.7494e-03,\n",
      "        5.8179e-07, 3.1821e-05, 2.7906e-04, 2.0252e-03, 1.1222e-05, 4.7248e-07,\n",
      "        1.2416e-02, 7.0596e-05, 5.6264e-05, 5.0119e-03, 2.1031e-05, 3.6014e-07,\n",
      "        2.5380e-02, 3.7255e-05, 1.2382e-06, 1.6989e-02, 1.6294e-06, 2.2646e-05,\n",
      "        1.2169e-06, 3.0348e-07, 2.8005e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0\n",
      "Softmaxed: tensor([1.0016e-07, 4.7420e-06, 1.8867e-04, 1.3645e-04, 1.6314e-04, 1.9124e-06,\n",
      "        1.2957e-06, 3.6489e-04, 4.8326e-07, 8.5273e-03, 1.2156e-06, 1.8610e-05,\n",
      "        4.0210e-03, 1.5757e-04, 1.2879e-04, 1.4876e-06, 5.9910e-05, 1.0553e-07,\n",
      "        9.8471e-01, 7.8873e-04, 4.0463e-05, 6.0274e-04, 8.5242e-06, 2.9746e-07,\n",
      "        9.7608e-06, 5.1707e-05, 1.4522e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([3.3930e-03, 5.8424e-03, 2.7214e-03, 1.8816e-03, 9.4035e-01, 4.3887e-04,\n",
      "        1.8622e-04, 7.5219e-04, 2.4846e-05, 3.5650e-03, 1.1863e-06, 4.8357e-04,\n",
      "        1.8175e-02, 3.0865e-03, 8.7434e-04, 1.3821e-04, 7.6203e-05, 1.5383e-06,\n",
      "        2.3135e-04, 5.5913e-03, 1.1995e-02, 3.4695e-05, 4.0781e-05, 1.3075e-05,\n",
      "        4.2239e-05, 5.2351e-05, 9.3135e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([4.5347e-01, 2.3146e-02, 4.8657e-05, 9.1368e-05, 1.6183e-04, 3.3112e-01,\n",
      "        4.9141e-04, 1.3724e-03, 2.0512e-05, 5.7010e-02, 1.9630e-06, 2.6818e-06,\n",
      "        1.1907e-02, 4.9140e-04, 8.1720e-03, 1.3544e-02, 4.2498e-06, 1.4838e-05,\n",
      "        1.0768e-04, 9.4880e-02, 1.0666e-05, 3.7698e-03, 4.0963e-06, 5.0744e-05,\n",
      "        1.7452e-05, 7.7454e-05, 8.3527e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([6.3294e-04, 8.4181e-03, 1.0438e-04, 8.9459e-03, 1.2509e-04, 6.2344e-05,\n",
      "        1.1335e-03, 6.2043e-04, 6.5986e-05, 4.5656e-06, 1.1089e-06, 5.8107e-06,\n",
      "        1.5078e-04, 7.1242e-05, 9.4331e-01, 8.6340e-05, 3.3424e-04, 3.8526e-05,\n",
      "        8.4787e-05, 1.0597e-03, 2.6282e-02, 1.7257e-05, 3.1298e-04, 5.8146e-06,\n",
      "        5.9304e-05, 1.7251e-07, 8.0631e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999998807907104\n",
      "Softmaxed: tensor([6.9511e-05, 1.3552e-01, 2.3410e-06, 1.0336e-06, 2.4895e-07, 5.2480e-01,\n",
      "        2.3601e-05, 1.7460e-06, 3.6135e-06, 3.3409e-01, 4.9583e-07, 1.4934e-06,\n",
      "        5.7265e-05, 4.1683e-05, 2.1141e-04, 5.0994e-05, 9.7118e-05, 7.0976e-06,\n",
      "        1.0848e-05, 4.6334e-04, 1.2456e-06, 2.4234e-03, 9.4104e-08, 1.6433e-06,\n",
      "        7.8371e-07, 2.1188e-03, 1.2644e-06], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 0.9999999403953552\n",
      "Softmaxed: tensor([7.8695e-01, 5.8842e-04, 6.0596e-05, 1.6734e-05, 1.6986e-01, 5.1454e-06,\n",
      "        9.6919e-05, 8.8780e-07, 1.8195e-07, 6.0818e-06, 1.1366e-07, 5.0478e-08,\n",
      "        3.3309e-03, 7.6214e-05, 3.2844e-02, 7.0149e-06, 3.5008e-06, 8.9902e-07,\n",
      "        6.0623e-05, 6.0610e-03, 1.8291e-05, 1.4903e-07, 4.1984e-06, 6.9779e-07,\n",
      "        9.6186e-07, 1.3411e-06, 6.5931e-08], grad_fn=<SoftmaxBackward0>)\n",
      "Softmaxed sum: 1.0000001192092896\n",
      "at the more profoundly man thinks the mo <------ | ------> rality laxugholoty in tractly regardize \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [22], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(answers, y_b)\n\u001B[0;32m     11\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m---> 13\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     15\u001B[0m train_passed \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\ItAcademy\\venv\\lib\\site-packages\\torch\\_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[0;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[1;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\ItAcademy\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(100):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_b, y_b in data:\n",
    "        optimizer.zero_grad()\n",
    "        answers = model(X_b)\n",
    "        loss = criterion(answers, y_b)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}   Time {:.3f}    Train Loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "    model.eval()\n",
    "    generate_text()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}